{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:47:15.459545Z",
     "start_time": "2019-11-14T21:47:04.972398Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://rasbt.github.io/mlxtend/user_guide/data/loadlocal_mnist/\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "!curl -O http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "!gunzip t*-ubyte.gz\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:00:54.759123Z",
     "start_time": "2019-11-15T19:00:54.751984Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.data import loadlocal_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:00:55.407071Z",
     "start_time": "2019-11-15T19:00:55.339776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 60000 x 784\n"
     ]
    }
   ],
   "source": [
    "''''\n",
    "group member 1: Andrei Ilic\n",
    "group member 2: Georgy Antonov\n",
    "\n",
    "'''\n",
    "\n",
    "# Provide paths to the local MNIST dataset\n",
    "train_im_path  = '/Users/GA/Documents/Tübingen/DNNs/Homework/Code/mnist/train-images-idx3-ubyte'\n",
    "train_lab_path = '/Users/GA/Documents/Tübingen/DNNs/Homework/Code/mnist/train-labels-idx1-ubyte'\n",
    "test_im_path   = '/Users/GA/Documents/Tübingen/DNNs/Homework/Code/mnist/t10k-images-idx3-ubyte'\n",
    "test_lab_path  = '/Users/GA/Documents/Tübingen/DNNs/Homework/Code/mnist/t10k-labels-idx1-ubyte'\n",
    "\n",
    "# Load \n",
    "X_train, y_train = loadlocal_mnist(\n",
    "                    images_path=train_im_path, \n",
    "                    labels_path=train_lab_path)\n",
    "\n",
    "X_test, y_test = loadlocal_mnist(\n",
    "                   images_path=test_im_path, \n",
    "                   labels_path=test_lab_path)\n",
    "\n",
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:00:56.373164Z",
     "start_time": "2019-11-15T19:00:55.863059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shapes:\n",
      "(50000, 784) (10000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# split eval data from train data:\n",
    "eval_data_size = 10000\n",
    "train_data_size = 50000\n",
    "test_data_size = 10000\n",
    "\n",
    "X_eval = X_train[0:10000, :]\n",
    "y_eval = y_train[0:10000]\n",
    "X_train = X_train[10000:, :]\n",
    "y_train = y_train[10000:]\n",
    "\n",
    "# Datatype float allows you to subtract images (is otherwise uint8)\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "print(\"x shapes:\")\n",
    "print(X_train.shape, X_eval.shape, X_test.shape)\n",
    "# normalize train data from range 0 to 255 to range 0 to 1\n",
    "X_train = X_train / 255\n",
    "X_eval = X_eval / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:00:56.839990Z",
     "start_time": "2019-11-15T19:00:56.758300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shapes:\n",
      "(50000, 10) (10000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# transform to y to one hot encoded vectors:\n",
    "# each row is one y vector\n",
    "def make_one_hot(v):\n",
    "    \"\"\"\n",
    "    :param v: vector of the length of the dataset containing class labels from 0 to 9\n",
    "    :return: a matrix of dim(length dataset,10), where the index of the corresponding label is set to one.\n",
    "    \"\"\"\n",
    "    num_samples = len(v)\n",
    "    num_labels  = len(np.unique(v))\n",
    "    \n",
    "    tmp = np.zeros((num_samples, num_labels))\n",
    "    for i in range(len(v)):\n",
    "        idx = int(v[i])\n",
    "        tmp[i][idx] = 1\n",
    "    v_one_hot = tmp\n",
    "    return v_one_hot\n",
    "\n",
    "y_train = make_one_hot(y_train)\n",
    "y_eval = make_one_hot(y_eval)\n",
    "y_test = make_one_hot(y_test)\n",
    "print(\"y shapes:\")\n",
    "print(y_train.shape, y_eval.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:27:37.370556Z",
     "start_time": "2019-11-15T19:27:37.349811Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO for task d adapt the following parameters to achieve better results\n",
    "batch_size = 250\n",
    "epochs = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "# usually one would use a random weight initialization, but for reproducible results we use fixed weights\n",
    "# Don't change these parameters\n",
    "W = np.ones((784, 10)) * 0.01\n",
    "b = np.ones((10)) * 0.01\n",
    "\n",
    "# b = np.repeat(b, batch_size, axis=0).reshape(10, batch_size)\n",
    "\n",
    "def get_next_batch(iteration, batch_size, data, label):\n",
    "    X = data[iteration * batch_size:(iteration + 1) * batch_size, :]\n",
    "    y = label[iteration * batch_size:(iteration + 1) * batch_size, :]\n",
    "    return X, y\n",
    "\n",
    "def get_loss(y_hat, y):\n",
    "    \"\"\"\n",
    "    :param y_hat: dim(batch_size,10)\n",
    "    :param y: dim(batch_size,10)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    batch_size = y_hat.shape[0]\n",
    "    l = 0\n",
    "    for row_y, row_y_hat in zip(y, y_hat):\n",
    "    # TODO calc the loss:\n",
    "        l += np.inner((row_y-row_y_hat), (row_y-row_y_hat))\n",
    "    return l / batch_size\n",
    "\n",
    "def get_accuracy(y_hat, y):\n",
    "    \"\"\"\n",
    "    the accuracy for one image is one if the maximum of y_hat has the same index as the 1 in y\n",
    "    :param y_hat:  dim(batch_size,10)\n",
    "    :param y: dim(batch_size,10)\n",
    "    :return: mean accuracy\n",
    "    \"\"\"\n",
    "    batch_size = y_hat.shape[0]\n",
    "    acc = 0\n",
    "    for row_y, row_y_hat in zip(y, y_hat):\n",
    "    # TODO calc the accuracy:\n",
    "        if np.argmax(row_y) == np.argmax(row_y_hat):\n",
    "            acc += 1\n",
    "        \n",
    "    return acc / batch_size\n",
    "\n",
    "def do_network_inference(x, W, b):  # over whole batch\n",
    "    \"\"\"\n",
    "    :param x: dim(batchsize,784)\n",
    "    :return: dim(batchsize,10)\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    b = np.repeat(b, batch_size, axis=0).reshape(10, batch_size)\n",
    "    # TODO calculate y_hat without using a loop, note that the numpy vector addition has some special features that can be used.\n",
    "    wx = np.matmul(np.transpose(W), np.transpose(x))\n",
    "    y_hat = np.add(wx, b)\n",
    "    return np.transpose(y_hat)\n",
    "\n",
    "def get_delta_weights(y_hat, y, x_batch):\n",
    "    \"\"\"\n",
    "    :param y_hat:  dim(batchsize,10)\n",
    "    :param y:  dim(batchsize,10)\n",
    "    :param x_batch: dim(batchsize,784)\n",
    "    :return: dim(784,10)\n",
    "    \"\"\"\n",
    "    # TODO calculate delta_w with a sum over outer products\n",
    "    batch_size = x_batch.shape[0]\n",
    "    \n",
    "    delta_w = np.zeros((10, 784))\n",
    "    for row_y, row_y_hat, row_x_batch in zip(y, y_hat, x_batch):\n",
    "        tmp = np.outer(2*(row_y_hat - row_y), row_x_batch)\n",
    "        delta_w = np.add(delta_w, tmp)\n",
    "        \n",
    "    return np.transpose(delta_w) / batch_size\n",
    "\n",
    "def get_delta_biases(y_hat, y):\n",
    "    \"\"\"\n",
    "    :param y_hat:  dim(batchsize,10)\n",
    "    :param y:  dim(batchsize,10)\n",
    "    :return:  dim(10)\n",
    "    \"\"\"\n",
    "    delta_b = np.zeros(10)\n",
    "    batch_size = y.shape[0]\n",
    "    # TODO calculate delta_b\n",
    "    for row_y, row_y_hat in zip(y, y_hat):\n",
    "        delta_b = np.add(delta_b, 2*(row_y_hat - row_y))\n",
    "    \n",
    "    return delta_b / batch_size\n",
    "\n",
    "def do_parameter_update(delta_w, delta_b, W, b, eta):\n",
    "    \"\"\"\n",
    "    :param delta_w: dim(748,10)\n",
    "    :param delta_b: dim(10)\n",
    "    :param W: dim(748,10)\n",
    "    :param b: dim(10)\n",
    "    \"\"\"\n",
    "    # TODO update W and b\n",
    "    W -= eta*delta_w\n",
    "    b -= eta*delta_b\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:28:24.824572Z",
     "start_time": "2019-11-15T19:27:38.639464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t iteration 0 \t train loss: 12.858318\n",
      "epoch: 0 \t iteration 1 \t train loss: 1.137029\n",
      "epoch: 0 \t iteration 2 \t train loss: 0.937766\n",
      "epoch: 0 \t iteration 3 \t train loss: 0.898327\n",
      "epoch: 0 \t iteration 4 \t train loss: 0.870438\n",
      "epoch: 0 \t iteration 5 \t train loss: 0.816914\n",
      "epoch: 0 \t iteration 6 \t train loss: 0.796826\n",
      "epoch: 0 \t iteration 7 \t train loss: 0.769603\n",
      "epoch: 0 \t iteration 8 \t train loss: 0.722546\n",
      "epoch: 0 \t iteration 9 \t train loss: 0.741529\n",
      "epoch: 0 \t iteration 10 \t train loss: 0.721879\n",
      "epoch: 0 \t iteration 11 \t train loss: 0.710371\n",
      "epoch: 0 \t iteration 12 \t train loss: 0.680874\n",
      "epoch: 0 \t iteration 13 \t train loss: 0.661204\n",
      "epoch: 0 \t iteration 14 \t train loss: 0.649937\n",
      "epoch: 0 \t iteration 15 \t train loss: 0.663157\n",
      "epoch: 0 \t iteration 16 \t train loss: 0.687830\n",
      "epoch: 0 \t iteration 17 \t train loss: 0.665813\n",
      "epoch: 0 \t iteration 18 \t train loss: 0.710971\n",
      "epoch: 0 \t iteration 19 \t train loss: 0.636546\n",
      "epoch: 0 \t iteration 20 \t train loss: 0.589696\n",
      "epoch: 0 \t iteration 21 \t train loss: 0.575563\n",
      "epoch: 0 \t iteration 22 \t train loss: 0.583816\n",
      "epoch: 0 \t iteration 23 \t train loss: 0.606979\n",
      "epoch: 0 \t iteration 24 \t train loss: 0.596013\n",
      "epoch: 0 \t iteration 25 \t train loss: 0.563476\n",
      "epoch: 0 \t iteration 26 \t train loss: 0.544876\n",
      "epoch: 0 \t iteration 27 \t train loss: 0.621457\n",
      "epoch: 0 \t iteration 28 \t train loss: 0.583892\n",
      "epoch: 0 \t iteration 29 \t train loss: 0.539854\n",
      "epoch: 0 \t iteration 30 \t train loss: 0.628990\n",
      "epoch: 0 \t iteration 31 \t train loss: 0.566325\n",
      "epoch: 0 \t iteration 32 \t train loss: 0.535861\n",
      "epoch: 0 \t iteration 33 \t train loss: 0.538799\n",
      "epoch: 0 \t iteration 34 \t train loss: 0.541895\n",
      "epoch: 0 \t iteration 35 \t train loss: 0.495365\n",
      "epoch: 0 \t iteration 36 \t train loss: 0.557211\n",
      "epoch: 0 \t iteration 37 \t train loss: 0.523168\n",
      "epoch: 0 \t iteration 38 \t train loss: 0.498089\n",
      "epoch: 0 \t iteration 39 \t train loss: 0.533265\n",
      "epoch: 0 \t iteration 40 \t train loss: 0.560583\n",
      "epoch: 0 \t iteration 41 \t train loss: 0.506819\n",
      "epoch: 0 \t iteration 42 \t train loss: 0.497343\n",
      "epoch: 0 \t iteration 43 \t train loss: 0.546490\n",
      "epoch: 0 \t iteration 44 \t train loss: 0.485604\n",
      "epoch: 0 \t iteration 45 \t train loss: 0.529918\n",
      "epoch: 0 \t iteration 46 \t train loss: 0.511349\n",
      "epoch: 0 \t iteration 47 \t train loss: 0.441512\n",
      "epoch: 0 \t iteration 48 \t train loss: 0.543058\n",
      "epoch: 0 \t iteration 49 \t train loss: 0.507158\n",
      "epoch: 0 \t iteration 50 \t train loss: 0.579581\n",
      "epoch: 0 \t iteration 51 \t train loss: 0.473872\n",
      "epoch: 0 \t iteration 52 \t train loss: 0.508340\n",
      "epoch: 0 \t iteration 53 \t train loss: 0.475345\n",
      "epoch: 0 \t iteration 54 \t train loss: 0.516107\n",
      "epoch: 0 \t iteration 55 \t train loss: 0.505963\n",
      "epoch: 0 \t iteration 56 \t train loss: 0.490034\n",
      "epoch: 0 \t iteration 57 \t train loss: 0.494673\n",
      "epoch: 0 \t iteration 58 \t train loss: 0.510374\n",
      "epoch: 0 \t iteration 59 \t train loss: 0.521498\n",
      "epoch: 0 \t iteration 60 \t train loss: 0.459922\n",
      "epoch: 0 \t iteration 61 \t train loss: 0.464968\n",
      "epoch: 0 \t iteration 62 \t train loss: 0.456694\n",
      "epoch: 0 \t iteration 63 \t train loss: 0.483611\n",
      "epoch: 0 \t iteration 64 \t train loss: 0.456394\n",
      "epoch: 0 \t iteration 65 \t train loss: 0.512376\n",
      "epoch: 0 \t iteration 66 \t train loss: 0.529265\n",
      "epoch: 0 \t iteration 67 \t train loss: 0.477028\n",
      "epoch: 0 \t iteration 68 \t train loss: 0.508487\n",
      "epoch: 0 \t iteration 69 \t train loss: 0.514244\n",
      "epoch: 0 \t iteration 70 \t train loss: 0.468742\n",
      "epoch: 0 \t iteration 71 \t train loss: 0.452945\n",
      "epoch: 0 \t iteration 72 \t train loss: 0.428296\n",
      "epoch: 0 \t iteration 73 \t train loss: 0.489235\n",
      "epoch: 0 \t iteration 74 \t train loss: 0.491259\n",
      "epoch: 0 \t iteration 75 \t train loss: 0.463500\n",
      "epoch: 0 \t iteration 76 \t train loss: 0.514808\n",
      "epoch: 0 \t iteration 77 \t train loss: 0.448035\n",
      "epoch: 0 \t iteration 78 \t train loss: 0.484414\n",
      "epoch: 0 \t iteration 79 \t train loss: 0.541692\n",
      "epoch: 0 \t iteration 80 \t train loss: 0.528068\n",
      "epoch: 0 \t iteration 81 \t train loss: 0.473052\n",
      "epoch: 0 \t iteration 82 \t train loss: 0.517691\n",
      "epoch: 0 \t iteration 83 \t train loss: 0.485504\n",
      "epoch: 0 \t iteration 84 \t train loss: 0.466934\n",
      "epoch: 0 \t iteration 85 \t train loss: 0.541611\n",
      "epoch: 0 \t iteration 86 \t train loss: 0.519696\n",
      "epoch: 0 \t iteration 87 \t train loss: 0.477742\n",
      "epoch: 0 \t iteration 88 \t train loss: 0.504504\n",
      "epoch: 0 \t iteration 89 \t train loss: 0.550321\n",
      "epoch: 0 \t iteration 90 \t train loss: 0.473533\n",
      "epoch: 0 \t iteration 91 \t train loss: 0.454188\n",
      "epoch: 0 \t iteration 92 \t train loss: 0.499862\n",
      "epoch: 0 \t iteration 93 \t train loss: 0.470398\n",
      "epoch: 0 \t iteration 94 \t train loss: 0.430702\n",
      "epoch: 0 \t iteration 95 \t train loss: 0.415423\n",
      "epoch: 0 \t iteration 96 \t train loss: 0.449842\n",
      "epoch: 0 \t iteration 97 \t train loss: 0.442923\n",
      "epoch: 0 \t iteration 98 \t train loss: 0.496072\n",
      "epoch: 0 \t iteration 99 \t train loss: 0.493718\n",
      "epoch: 0 \t iteration 100 \t train loss: 0.464403\n",
      "epoch: 0 \t iteration 101 \t train loss: 0.452327\n",
      "epoch: 0 \t iteration 102 \t train loss: 0.453275\n",
      "epoch: 0 \t iteration 103 \t train loss: 0.458797\n",
      "epoch: 0 \t iteration 104 \t train loss: 0.485254\n",
      "epoch: 0 \t iteration 105 \t train loss: 0.469962\n",
      "epoch: 0 \t iteration 106 \t train loss: 0.413132\n",
      "epoch: 0 \t iteration 107 \t train loss: 0.450122\n",
      "epoch: 0 \t iteration 108 \t train loss: 0.476030\n",
      "epoch: 0 \t iteration 109 \t train loss: 0.521713\n",
      "epoch: 0 \t iteration 110 \t train loss: 0.463933\n",
      "epoch: 0 \t iteration 111 \t train loss: 0.464634\n",
      "epoch: 0 \t iteration 112 \t train loss: 0.436698\n",
      "epoch: 0 \t iteration 113 \t train loss: 0.459531\n",
      "epoch: 0 \t iteration 114 \t train loss: 0.470379\n",
      "epoch: 0 \t iteration 115 \t train loss: 0.409025\n",
      "epoch: 0 \t iteration 116 \t train loss: 0.387850\n",
      "epoch: 0 \t iteration 117 \t train loss: 0.520231\n",
      "epoch: 0 \t iteration 118 \t train loss: 0.487692\n",
      "epoch: 0 \t iteration 119 \t train loss: 0.503681\n",
      "epoch: 0 \t iteration 120 \t train loss: 0.432776\n",
      "epoch: 0 \t iteration 121 \t train loss: 0.458663\n",
      "epoch: 0 \t iteration 122 \t train loss: 0.456906\n",
      "epoch: 0 \t iteration 123 \t train loss: 0.412084\n",
      "epoch: 0 \t iteration 124 \t train loss: 0.465177\n",
      "epoch: 0 \t iteration 125 \t train loss: 0.528601\n",
      "epoch: 0 \t iteration 126 \t train loss: 0.476523\n",
      "epoch: 0 \t iteration 127 \t train loss: 0.462607\n",
      "epoch: 0 \t iteration 128 \t train loss: 0.478008\n",
      "epoch: 0 \t iteration 129 \t train loss: 0.511656\n",
      "epoch: 0 \t iteration 130 \t train loss: 0.456556\n",
      "epoch: 0 \t iteration 131 \t train loss: 0.458624\n",
      "epoch: 0 \t iteration 132 \t train loss: 0.471977\n",
      "epoch: 0 \t iteration 133 \t train loss: 0.393163\n",
      "epoch: 0 \t iteration 134 \t train loss: 0.430490\n",
      "epoch: 0 \t iteration 135 \t train loss: 0.456400\n",
      "epoch: 0 \t iteration 136 \t train loss: 0.467706\n",
      "epoch: 0 \t iteration 137 \t train loss: 0.484261\n",
      "epoch: 0 \t iteration 138 \t train loss: 0.401864\n",
      "epoch: 0 \t iteration 139 \t train loss: 0.479776\n",
      "epoch: 0 \t iteration 140 \t train loss: 0.474440\n",
      "epoch: 0 \t iteration 141 \t train loss: 0.445266\n",
      "epoch: 0 \t iteration 142 \t train loss: 0.454086\n",
      "epoch: 0 \t iteration 143 \t train loss: 0.485390\n",
      "epoch: 0 \t iteration 144 \t train loss: 0.473319\n",
      "epoch: 0 \t iteration 145 \t train loss: 0.480165\n",
      "epoch: 0 \t iteration 146 \t train loss: 0.429731\n",
      "epoch: 0 \t iteration 147 \t train loss: 0.395685\n",
      "epoch: 0 \t iteration 148 \t train loss: 0.434262\n",
      "epoch: 0 \t iteration 149 \t train loss: 0.497558\n",
      "epoch: 0 \t iteration 150 \t train loss: 0.477999\n",
      "epoch: 0 \t iteration 151 \t train loss: 0.430696\n",
      "epoch: 0 \t iteration 152 \t train loss: 0.398619\n",
      "epoch: 0 \t iteration 153 \t train loss: 0.419768\n",
      "epoch: 0 \t iteration 154 \t train loss: 0.424270\n",
      "epoch: 0 \t iteration 155 \t train loss: 0.464711\n",
      "epoch: 0 \t iteration 156 \t train loss: 0.516737\n",
      "epoch: 0 \t iteration 157 \t train loss: 0.427972\n",
      "epoch: 0 \t iteration 158 \t train loss: 0.531230\n",
      "epoch: 0 \t iteration 159 \t train loss: 0.488727\n",
      "epoch: 0 \t iteration 160 \t train loss: 0.435626\n",
      "epoch: 0 \t iteration 161 \t train loss: 0.474766\n",
      "epoch: 0 \t iteration 162 \t train loss: 0.472934\n",
      "epoch: 0 \t iteration 163 \t train loss: 0.420352\n",
      "epoch: 0 \t iteration 164 \t train loss: 0.428137\n",
      "epoch: 0 \t iteration 165 \t train loss: 0.417499\n",
      "epoch: 0 \t iteration 166 \t train loss: 0.401055\n",
      "epoch: 0 \t iteration 167 \t train loss: 0.426560\n",
      "epoch: 0 \t iteration 168 \t train loss: 0.512520\n",
      "epoch: 0 \t iteration 169 \t train loss: 0.402732\n",
      "epoch: 0 \t iteration 170 \t train loss: 0.407529\n",
      "epoch: 0 \t iteration 171 \t train loss: 0.479664\n",
      "epoch: 0 \t iteration 172 \t train loss: 0.434277\n",
      "epoch: 0 \t iteration 173 \t train loss: 0.395201\n",
      "epoch: 0 \t iteration 174 \t train loss: 0.439516\n",
      "epoch: 0 \t iteration 175 \t train loss: 0.428043\n",
      "epoch: 0 \t iteration 176 \t train loss: 0.450142\n",
      "epoch: 0 \t iteration 177 \t train loss: 0.426190\n",
      "epoch: 0 \t iteration 178 \t train loss: 0.398754\n",
      "epoch: 0 \t iteration 179 \t train loss: 0.481780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t iteration 180 \t train loss: 0.397791\n",
      "epoch: 0 \t iteration 181 \t train loss: 0.415779\n",
      "epoch: 0 \t iteration 182 \t train loss: 0.438276\n",
      "epoch: 0 \t iteration 183 \t train loss: 0.373765\n",
      "epoch: 0 \t iteration 184 \t train loss: 0.422086\n",
      "epoch: 0 \t iteration 185 \t train loss: 0.459127\n",
      "epoch: 0 \t iteration 186 \t train loss: 0.406609\n",
      "epoch: 0 \t iteration 187 \t train loss: 0.388443\n",
      "epoch: 0 \t iteration 188 \t train loss: 0.416045\n",
      "epoch: 0 \t iteration 189 \t train loss: 0.454152\n",
      "epoch: 0 \t iteration 190 \t train loss: 0.465271\n",
      "epoch: 0 \t iteration 191 \t train loss: 0.390171\n",
      "epoch: 0 \t iteration 192 \t train loss: 0.357300\n",
      "epoch: 0 \t iteration 193 \t train loss: 0.380567\n",
      "epoch: 0 \t iteration 194 \t train loss: 0.385620\n",
      "epoch: 0 \t iteration 195 \t train loss: 0.327925\n",
      "epoch: 0 \t iteration 196 \t train loss: 0.301683\n",
      "epoch: 0 \t iteration 197 \t train loss: 0.467017\n",
      "epoch: 0 \t iteration 198 \t train loss: 0.419627\n",
      "epoch: 0 \t iteration 199 \t train loss: 0.385540\n",
      "epoch:0 \t mean train loss: 0.562375 \t mean train acc: 0.812800\n",
      "epoch: 0 \t iteration 0 \t eval loss: 0.415174\n",
      "epoch: 0 \t iteration 1 \t eval loss: 0.390878\n",
      "epoch: 0 \t iteration 2 \t eval loss: 0.485976\n",
      "epoch: 0 \t iteration 3 \t eval loss: 0.444317\n",
      "epoch: 0 \t iteration 4 \t eval loss: 0.486073\n",
      "epoch: 0 \t iteration 5 \t eval loss: 0.445740\n",
      "epoch: 0 \t iteration 6 \t eval loss: 0.399588\n",
      "epoch: 0 \t iteration 7 \t eval loss: 0.412819\n",
      "epoch: 0 \t iteration 8 \t eval loss: 0.394685\n",
      "epoch: 0 \t iteration 9 \t eval loss: 0.414468\n",
      "epoch: 0 \t iteration 10 \t eval loss: 0.400638\n",
      "epoch: 0 \t iteration 11 \t eval loss: 0.420490\n",
      "epoch: 0 \t iteration 12 \t eval loss: 0.439904\n",
      "epoch: 0 \t iteration 13 \t eval loss: 0.419710\n",
      "epoch: 0 \t iteration 14 \t eval loss: 0.447043\n",
      "epoch: 0 \t iteration 15 \t eval loss: 0.412412\n",
      "epoch: 0 \t iteration 16 \t eval loss: 0.442503\n",
      "epoch: 0 \t iteration 17 \t eval loss: 0.436085\n",
      "epoch: 0 \t iteration 18 \t eval loss: 0.417055\n",
      "epoch: 0 \t iteration 19 \t eval loss: 0.434694\n",
      "epoch: 0 \t iteration 20 \t eval loss: 0.430647\n",
      "epoch: 0 \t iteration 21 \t eval loss: 0.395864\n",
      "epoch: 0 \t iteration 22 \t eval loss: 0.431502\n",
      "epoch: 0 \t iteration 23 \t eval loss: 0.413630\n",
      "epoch: 0 \t iteration 24 \t eval loss: 0.393861\n",
      "epoch: 0 \t iteration 25 \t eval loss: 0.432683\n",
      "epoch: 0 \t iteration 26 \t eval loss: 0.346925\n",
      "epoch: 0 \t iteration 27 \t eval loss: 0.478902\n",
      "epoch: 0 \t iteration 28 \t eval loss: 0.466736\n",
      "epoch: 0 \t iteration 29 \t eval loss: 0.473777\n",
      "epoch: 0 \t iteration 30 \t eval loss: 0.441004\n",
      "epoch: 0 \t iteration 31 \t eval loss: 0.475560\n",
      "epoch: 0 \t iteration 32 \t eval loss: 0.457068\n",
      "epoch: 0 \t iteration 33 \t eval loss: 0.455155\n",
      "epoch: 0 \t iteration 34 \t eval loss: 0.490069\n",
      "epoch: 0 \t iteration 35 \t eval loss: 0.477170\n",
      "epoch: 0 \t iteration 36 \t eval loss: 0.391490\n",
      "epoch: 0 \t iteration 37 \t eval loss: 0.430802\n",
      "epoch: 0 \t iteration 38 \t eval loss: 0.420583\n",
      "epoch: 0 \t iteration 39 \t eval loss: 0.384946\n",
      "epoch:0 \t mean eval loss: 0.431216 \t mean eval acc: 0.840500\n",
      "epoch: 1 \t iteration 0 \t train loss: 0.433785\n",
      "epoch: 1 \t iteration 1 \t train loss: 0.388913\n",
      "epoch: 1 \t iteration 2 \t train loss: 0.405176\n",
      "epoch: 1 \t iteration 3 \t train loss: 0.416211\n",
      "epoch: 1 \t iteration 4 \t train loss: 0.421264\n",
      "epoch: 1 \t iteration 5 \t train loss: 0.399509\n",
      "epoch: 1 \t iteration 6 \t train loss: 0.516604\n",
      "epoch: 1 \t iteration 7 \t train loss: 0.452216\n",
      "epoch: 1 \t iteration 8 \t train loss: 0.411836\n",
      "epoch: 1 \t iteration 9 \t train loss: 0.476256\n",
      "epoch: 1 \t iteration 10 \t train loss: 0.466292\n",
      "epoch: 1 \t iteration 11 \t train loss: 0.466454\n",
      "epoch: 1 \t iteration 12 \t train loss: 0.489003\n",
      "epoch: 1 \t iteration 13 \t train loss: 0.418501\n",
      "epoch: 1 \t iteration 14 \t train loss: 0.429502\n",
      "epoch: 1 \t iteration 15 \t train loss: 0.478504\n",
      "epoch: 1 \t iteration 16 \t train loss: 0.509297\n",
      "epoch: 1 \t iteration 17 \t train loss: 0.488379\n",
      "epoch: 1 \t iteration 18 \t train loss: 0.541482\n",
      "epoch: 1 \t iteration 19 \t train loss: 0.462415\n",
      "epoch: 1 \t iteration 20 \t train loss: 0.415038\n",
      "epoch: 1 \t iteration 21 \t train loss: 0.403898\n",
      "epoch: 1 \t iteration 22 \t train loss: 0.441045\n",
      "epoch: 1 \t iteration 23 \t train loss: 0.484089\n",
      "epoch: 1 \t iteration 24 \t train loss: 0.467494\n",
      "epoch: 1 \t iteration 25 \t train loss: 0.401320\n",
      "epoch: 1 \t iteration 26 \t train loss: 0.401047\n",
      "epoch: 1 \t iteration 27 \t train loss: 0.483463\n",
      "epoch: 1 \t iteration 28 \t train loss: 0.467363\n",
      "epoch: 1 \t iteration 29 \t train loss: 0.412025\n",
      "epoch: 1 \t iteration 30 \t train loss: 0.517544\n",
      "epoch: 1 \t iteration 31 \t train loss: 0.440663\n",
      "epoch: 1 \t iteration 32 \t train loss: 0.408814\n",
      "epoch: 1 \t iteration 33 \t train loss: 0.410320\n",
      "epoch: 1 \t iteration 34 \t train loss: 0.413134\n",
      "epoch: 1 \t iteration 35 \t train loss: 0.370996\n",
      "epoch: 1 \t iteration 36 \t train loss: 0.460230\n",
      "epoch: 1 \t iteration 37 \t train loss: 0.429161\n",
      "epoch: 1 \t iteration 38 \t train loss: 0.397168\n",
      "epoch: 1 \t iteration 39 \t train loss: 0.432193\n",
      "epoch: 1 \t iteration 40 \t train loss: 0.464561\n",
      "epoch: 1 \t iteration 41 \t train loss: 0.405648\n",
      "epoch: 1 \t iteration 42 \t train loss: 0.417293\n",
      "epoch: 1 \t iteration 43 \t train loss: 0.479680\n",
      "epoch: 1 \t iteration 44 \t train loss: 0.388192\n",
      "epoch: 1 \t iteration 45 \t train loss: 0.436397\n",
      "epoch: 1 \t iteration 46 \t train loss: 0.430187\n",
      "epoch: 1 \t iteration 47 \t train loss: 0.359930\n",
      "epoch: 1 \t iteration 48 \t train loss: 0.460149\n",
      "epoch: 1 \t iteration 49 \t train loss: 0.433737\n",
      "epoch: 1 \t iteration 50 \t train loss: 0.551354\n",
      "epoch: 1 \t iteration 51 \t train loss: 0.399049\n",
      "epoch: 1 \t iteration 52 \t train loss: 0.446693\n",
      "epoch: 1 \t iteration 53 \t train loss: 0.414323\n",
      "epoch: 1 \t iteration 54 \t train loss: 0.433511\n",
      "epoch: 1 \t iteration 55 \t train loss: 0.441757\n",
      "epoch: 1 \t iteration 56 \t train loss: 0.429821\n",
      "epoch: 1 \t iteration 57 \t train loss: 0.426802\n",
      "epoch: 1 \t iteration 58 \t train loss: 0.446422\n",
      "epoch: 1 \t iteration 59 \t train loss: 0.454044\n",
      "epoch: 1 \t iteration 60 \t train loss: 0.396522\n",
      "epoch: 1 \t iteration 61 \t train loss: 0.397664\n",
      "epoch: 1 \t iteration 62 \t train loss: 0.401389\n",
      "epoch: 1 \t iteration 63 \t train loss: 0.423791\n",
      "epoch: 1 \t iteration 64 \t train loss: 0.392532\n",
      "epoch: 1 \t iteration 65 \t train loss: 0.455343\n",
      "epoch: 1 \t iteration 66 \t train loss: 0.480924\n",
      "epoch: 1 \t iteration 67 \t train loss: 0.424280\n",
      "epoch: 1 \t iteration 68 \t train loss: 0.454653\n",
      "epoch: 1 \t iteration 69 \t train loss: 0.457659\n",
      "epoch: 1 \t iteration 70 \t train loss: 0.416189\n",
      "epoch: 1 \t iteration 71 \t train loss: 0.394861\n",
      "epoch: 1 \t iteration 72 \t train loss: 0.375354\n",
      "epoch: 1 \t iteration 73 \t train loss: 0.438071\n",
      "epoch: 1 \t iteration 74 \t train loss: 0.439980\n",
      "epoch: 1 \t iteration 75 \t train loss: 0.403314\n",
      "epoch: 1 \t iteration 76 \t train loss: 0.467520\n",
      "epoch: 1 \t iteration 77 \t train loss: 0.406964\n",
      "epoch: 1 \t iteration 78 \t train loss: 0.438258\n",
      "epoch: 1 \t iteration 79 \t train loss: 0.495369\n",
      "epoch: 1 \t iteration 80 \t train loss: 0.484266\n",
      "epoch: 1 \t iteration 81 \t train loss: 0.428996\n",
      "epoch: 1 \t iteration 82 \t train loss: 0.470618\n",
      "epoch: 1 \t iteration 83 \t train loss: 0.441715\n",
      "epoch: 1 \t iteration 84 \t train loss: 0.431446\n",
      "epoch: 1 \t iteration 85 \t train loss: 0.495969\n",
      "epoch: 1 \t iteration 86 \t train loss: 0.474982\n",
      "epoch: 1 \t iteration 87 \t train loss: 0.426125\n",
      "epoch: 1 \t iteration 88 \t train loss: 0.458847\n",
      "epoch: 1 \t iteration 89 \t train loss: 0.505662\n",
      "epoch: 1 \t iteration 90 \t train loss: 0.423895\n",
      "epoch: 1 \t iteration 91 \t train loss: 0.410957\n",
      "epoch: 1 \t iteration 92 \t train loss: 0.455759\n",
      "epoch: 1 \t iteration 93 \t train loss: 0.430727\n",
      "epoch: 1 \t iteration 94 \t train loss: 0.385607\n",
      "epoch: 1 \t iteration 95 \t train loss: 0.369629\n",
      "epoch: 1 \t iteration 96 \t train loss: 0.406308\n",
      "epoch: 1 \t iteration 97 \t train loss: 0.406421\n",
      "epoch: 1 \t iteration 98 \t train loss: 0.467889\n",
      "epoch: 1 \t iteration 99 \t train loss: 0.457772\n",
      "epoch: 1 \t iteration 100 \t train loss: 0.424331\n",
      "epoch: 1 \t iteration 101 \t train loss: 0.413048\n",
      "epoch: 1 \t iteration 102 \t train loss: 0.416959\n",
      "epoch: 1 \t iteration 103 \t train loss: 0.423379\n",
      "epoch: 1 \t iteration 104 \t train loss: 0.452871\n",
      "epoch: 1 \t iteration 105 \t train loss: 0.432189\n",
      "epoch: 1 \t iteration 106 \t train loss: 0.386717\n",
      "epoch: 1 \t iteration 107 \t train loss: 0.421937\n",
      "epoch: 1 \t iteration 108 \t train loss: 0.450510\n",
      "epoch: 1 \t iteration 109 \t train loss: 0.506574\n",
      "epoch: 1 \t iteration 110 \t train loss: 0.436647\n",
      "epoch: 1 \t iteration 111 \t train loss: 0.431889\n",
      "epoch: 1 \t iteration 112 \t train loss: 0.399736\n",
      "epoch: 1 \t iteration 113 \t train loss: 0.432467\n",
      "epoch: 1 \t iteration 114 \t train loss: 0.440168\n",
      "epoch: 1 \t iteration 115 \t train loss: 0.370416\n",
      "epoch: 1 \t iteration 116 \t train loss: 0.354790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t iteration 117 \t train loss: 0.494183\n",
      "epoch: 1 \t iteration 118 \t train loss: 0.458091\n",
      "epoch: 1 \t iteration 119 \t train loss: 0.477497\n",
      "epoch: 1 \t iteration 120 \t train loss: 0.401830\n",
      "epoch: 1 \t iteration 121 \t train loss: 0.431207\n",
      "epoch: 1 \t iteration 122 \t train loss: 0.429561\n",
      "epoch: 1 \t iteration 123 \t train loss: 0.380232\n",
      "epoch: 1 \t iteration 124 \t train loss: 0.429901\n",
      "epoch: 1 \t iteration 125 \t train loss: 0.505624\n",
      "epoch: 1 \t iteration 126 \t train loss: 0.446243\n",
      "epoch: 1 \t iteration 127 \t train loss: 0.427298\n",
      "epoch: 1 \t iteration 128 \t train loss: 0.458553\n",
      "epoch: 1 \t iteration 129 \t train loss: 0.489436\n",
      "epoch: 1 \t iteration 130 \t train loss: 0.433097\n",
      "epoch: 1 \t iteration 131 \t train loss: 0.432531\n",
      "epoch: 1 \t iteration 132 \t train loss: 0.445811\n",
      "epoch: 1 \t iteration 133 \t train loss: 0.364348\n",
      "epoch: 1 \t iteration 134 \t train loss: 0.398849\n",
      "epoch: 1 \t iteration 135 \t train loss: 0.429634\n",
      "epoch: 1 \t iteration 136 \t train loss: 0.439010\n",
      "epoch: 1 \t iteration 137 \t train loss: 0.461412\n",
      "epoch: 1 \t iteration 138 \t train loss: 0.370048\n",
      "epoch: 1 \t iteration 139 \t train loss: 0.456439\n",
      "epoch: 1 \t iteration 140 \t train loss: 0.445595\n",
      "epoch: 1 \t iteration 141 \t train loss: 0.418742\n",
      "epoch: 1 \t iteration 142 \t train loss: 0.432932\n",
      "epoch: 1 \t iteration 143 \t train loss: 0.462074\n",
      "epoch: 1 \t iteration 144 \t train loss: 0.454409\n",
      "epoch: 1 \t iteration 145 \t train loss: 0.459157\n",
      "epoch: 1 \t iteration 146 \t train loss: 0.402999\n",
      "epoch: 1 \t iteration 147 \t train loss: 0.374388\n",
      "epoch: 1 \t iteration 148 \t train loss: 0.408169\n",
      "epoch: 1 \t iteration 149 \t train loss: 0.472604\n",
      "epoch: 1 \t iteration 150 \t train loss: 0.453246\n",
      "epoch: 1 \t iteration 151 \t train loss: 0.408689\n",
      "epoch: 1 \t iteration 152 \t train loss: 0.378575\n",
      "epoch: 1 \t iteration 153 \t train loss: 0.402394\n",
      "epoch: 1 \t iteration 154 \t train loss: 0.403317\n",
      "epoch: 1 \t iteration 155 \t train loss: 0.439971\n",
      "epoch: 1 \t iteration 156 \t train loss: 0.497197\n",
      "epoch: 1 \t iteration 157 \t train loss: 0.408245\n",
      "epoch: 1 \t iteration 158 \t train loss: 0.508644\n",
      "epoch: 1 \t iteration 159 \t train loss: 0.464143\n",
      "epoch: 1 \t iteration 160 \t train loss: 0.413244\n",
      "epoch: 1 \t iteration 161 \t train loss: 0.456726\n",
      "epoch: 1 \t iteration 162 \t train loss: 0.447496\n",
      "epoch: 1 \t iteration 163 \t train loss: 0.396346\n",
      "epoch: 1 \t iteration 164 \t train loss: 0.401475\n",
      "epoch: 1 \t iteration 165 \t train loss: 0.392228\n",
      "epoch: 1 \t iteration 166 \t train loss: 0.375499\n",
      "epoch: 1 \t iteration 167 \t train loss: 0.404733\n",
      "epoch: 1 \t iteration 168 \t train loss: 0.493381\n",
      "epoch: 1 \t iteration 169 \t train loss: 0.382706\n",
      "epoch: 1 \t iteration 170 \t train loss: 0.388189\n",
      "epoch: 1 \t iteration 171 \t train loss: 0.462554\n",
      "epoch: 1 \t iteration 172 \t train loss: 0.416828\n",
      "epoch: 1 \t iteration 173 \t train loss: 0.370233\n",
      "epoch: 1 \t iteration 174 \t train loss: 0.419088\n",
      "epoch: 1 \t iteration 175 \t train loss: 0.406771\n",
      "epoch: 1 \t iteration 176 \t train loss: 0.433092\n",
      "epoch: 1 \t iteration 177 \t train loss: 0.405604\n",
      "epoch: 1 \t iteration 178 \t train loss: 0.378168\n",
      "epoch: 1 \t iteration 179 \t train loss: 0.462363\n",
      "epoch: 1 \t iteration 180 \t train loss: 0.379861\n",
      "epoch: 1 \t iteration 181 \t train loss: 0.394347\n",
      "epoch: 1 \t iteration 182 \t train loss: 0.425061\n",
      "epoch: 1 \t iteration 183 \t train loss: 0.351101\n",
      "epoch: 1 \t iteration 184 \t train loss: 0.404665\n",
      "epoch: 1 \t iteration 185 \t train loss: 0.440496\n",
      "epoch: 1 \t iteration 186 \t train loss: 0.387660\n",
      "epoch: 1 \t iteration 187 \t train loss: 0.369809\n",
      "epoch: 1 \t iteration 188 \t train loss: 0.394836\n",
      "epoch: 1 \t iteration 189 \t train loss: 0.429830\n",
      "epoch: 1 \t iteration 190 \t train loss: 0.453423\n",
      "epoch: 1 \t iteration 191 \t train loss: 0.370624\n",
      "epoch: 1 \t iteration 192 \t train loss: 0.336089\n",
      "epoch: 1 \t iteration 193 \t train loss: 0.357924\n",
      "epoch: 1 \t iteration 194 \t train loss: 0.367691\n",
      "epoch: 1 \t iteration 195 \t train loss: 0.304830\n",
      "epoch: 1 \t iteration 196 \t train loss: 0.280491\n",
      "epoch: 1 \t iteration 197 \t train loss: 0.449801\n",
      "epoch: 1 \t iteration 198 \t train loss: 0.403189\n",
      "epoch: 1 \t iteration 199 \t train loss: 0.363902\n",
      "epoch:1 \t mean train loss: 0.428828 \t mean train acc: 0.846020\n",
      "epoch: 1 \t iteration 0 \t eval loss: 0.398128\n",
      "epoch: 1 \t iteration 1 \t eval loss: 0.371123\n",
      "epoch: 1 \t iteration 2 \t eval loss: 0.465170\n",
      "epoch: 1 \t iteration 3 \t eval loss: 0.423492\n",
      "epoch: 1 \t iteration 4 \t eval loss: 0.471571\n",
      "epoch: 1 \t iteration 5 \t eval loss: 0.435088\n",
      "epoch: 1 \t iteration 6 \t eval loss: 0.384604\n",
      "epoch: 1 \t iteration 7 \t eval loss: 0.394877\n",
      "epoch: 1 \t iteration 8 \t eval loss: 0.378362\n",
      "epoch: 1 \t iteration 9 \t eval loss: 0.393892\n",
      "epoch: 1 \t iteration 10 \t eval loss: 0.379660\n",
      "epoch: 1 \t iteration 11 \t eval loss: 0.402572\n",
      "epoch: 1 \t iteration 12 \t eval loss: 0.418295\n",
      "epoch: 1 \t iteration 13 \t eval loss: 0.397716\n",
      "epoch: 1 \t iteration 14 \t eval loss: 0.432363\n",
      "epoch: 1 \t iteration 15 \t eval loss: 0.391841\n",
      "epoch: 1 \t iteration 16 \t eval loss: 0.426439\n",
      "epoch: 1 \t iteration 17 \t eval loss: 0.417073\n",
      "epoch: 1 \t iteration 18 \t eval loss: 0.397319\n",
      "epoch: 1 \t iteration 19 \t eval loss: 0.415815\n",
      "epoch: 1 \t iteration 20 \t eval loss: 0.415690\n",
      "epoch: 1 \t iteration 21 \t eval loss: 0.379703\n",
      "epoch: 1 \t iteration 22 \t eval loss: 0.415840\n",
      "epoch: 1 \t iteration 23 \t eval loss: 0.393433\n",
      "epoch: 1 \t iteration 24 \t eval loss: 0.379731\n",
      "epoch: 1 \t iteration 25 \t eval loss: 0.417270\n",
      "epoch: 1 \t iteration 26 \t eval loss: 0.328076\n",
      "epoch: 1 \t iteration 27 \t eval loss: 0.469396\n",
      "epoch: 1 \t iteration 28 \t eval loss: 0.450081\n",
      "epoch: 1 \t iteration 29 \t eval loss: 0.453633\n",
      "epoch: 1 \t iteration 30 \t eval loss: 0.421713\n",
      "epoch: 1 \t iteration 31 \t eval loss: 0.458960\n",
      "epoch: 1 \t iteration 32 \t eval loss: 0.442494\n",
      "epoch: 1 \t iteration 33 \t eval loss: 0.438259\n",
      "epoch: 1 \t iteration 34 \t eval loss: 0.478465\n",
      "epoch: 1 \t iteration 35 \t eval loss: 0.461422\n",
      "epoch: 1 \t iteration 36 \t eval loss: 0.373489\n",
      "epoch: 1 \t iteration 37 \t eval loss: 0.415650\n",
      "epoch: 1 \t iteration 38 \t eval loss: 0.404160\n",
      "epoch: 1 \t iteration 39 \t eval loss: 0.364740\n",
      "epoch:1 \t mean eval loss: 0.413940 \t mean eval acc: 0.847000\n",
      "epoch: 2 \t iteration 0 \t train loss: 0.416124\n",
      "epoch: 2 \t iteration 1 \t train loss: 0.369986\n",
      "epoch: 2 \t iteration 2 \t train loss: 0.387269\n",
      "epoch: 2 \t iteration 3 \t train loss: 0.400263\n",
      "epoch: 2 \t iteration 4 \t train loss: 0.406086\n",
      "epoch: 2 \t iteration 5 \t train loss: 0.384388\n",
      "epoch: 2 \t iteration 6 \t train loss: 0.504786\n",
      "epoch: 2 \t iteration 7 \t train loss: 0.434481\n",
      "epoch: 2 \t iteration 8 \t train loss: 0.395920\n",
      "epoch: 2 \t iteration 9 \t train loss: 0.460003\n",
      "epoch: 2 \t iteration 10 \t train loss: 0.448319\n",
      "epoch: 2 \t iteration 11 \t train loss: 0.450301\n",
      "epoch: 2 \t iteration 12 \t train loss: 0.475386\n",
      "epoch: 2 \t iteration 13 \t train loss: 0.398579\n",
      "epoch: 2 \t iteration 14 \t train loss: 0.416304\n",
      "epoch: 2 \t iteration 15 \t train loss: 0.462596\n",
      "epoch: 2 \t iteration 16 \t train loss: 0.496412\n",
      "epoch: 2 \t iteration 17 \t train loss: 0.470072\n",
      "epoch: 2 \t iteration 18 \t train loss: 0.524168\n",
      "epoch: 2 \t iteration 19 \t train loss: 0.448470\n",
      "epoch: 2 \t iteration 20 \t train loss: 0.402581\n",
      "epoch: 2 \t iteration 21 \t train loss: 0.389431\n",
      "epoch: 2 \t iteration 22 \t train loss: 0.424887\n",
      "epoch: 2 \t iteration 23 \t train loss: 0.468632\n",
      "epoch: 2 \t iteration 24 \t train loss: 0.451336\n",
      "epoch: 2 \t iteration 25 \t train loss: 0.385143\n",
      "epoch: 2 \t iteration 26 \t train loss: 0.389884\n",
      "epoch: 2 \t iteration 27 \t train loss: 0.464863\n",
      "epoch: 2 \t iteration 28 \t train loss: 0.451617\n",
      "epoch: 2 \t iteration 29 \t train loss: 0.396416\n",
      "epoch: 2 \t iteration 30 \t train loss: 0.501208\n",
      "epoch: 2 \t iteration 31 \t train loss: 0.427103\n",
      "epoch: 2 \t iteration 32 \t train loss: 0.392946\n",
      "epoch: 2 \t iteration 33 \t train loss: 0.395728\n",
      "epoch: 2 \t iteration 34 \t train loss: 0.394289\n",
      "epoch: 2 \t iteration 35 \t train loss: 0.354557\n",
      "epoch: 2 \t iteration 36 \t train loss: 0.444125\n",
      "epoch: 2 \t iteration 37 \t train loss: 0.416665\n",
      "epoch: 2 \t iteration 38 \t train loss: 0.383432\n",
      "epoch: 2 \t iteration 39 \t train loss: 0.417835\n",
      "epoch: 2 \t iteration 40 \t train loss: 0.449135\n",
      "epoch: 2 \t iteration 41 \t train loss: 0.388004\n",
      "epoch: 2 \t iteration 42 \t train loss: 0.405670\n",
      "epoch: 2 \t iteration 43 \t train loss: 0.467445\n",
      "epoch: 2 \t iteration 44 \t train loss: 0.373099\n",
      "epoch: 2 \t iteration 45 \t train loss: 0.418150\n",
      "epoch: 2 \t iteration 46 \t train loss: 0.417434\n",
      "epoch: 2 \t iteration 47 \t train loss: 0.348715\n",
      "epoch: 2 \t iteration 48 \t train loss: 0.443301\n",
      "epoch: 2 \t iteration 49 \t train loss: 0.420662\n",
      "epoch: 2 \t iteration 50 \t train loss: 0.545323\n",
      "epoch: 2 \t iteration 51 \t train loss: 0.384698\n",
      "epoch: 2 \t iteration 52 \t train loss: 0.434822\n",
      "epoch: 2 \t iteration 53 \t train loss: 0.401722\n",
      "epoch: 2 \t iteration 54 \t train loss: 0.415638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 \t iteration 55 \t train loss: 0.428630\n",
      "epoch: 2 \t iteration 56 \t train loss: 0.417869\n",
      "epoch: 2 \t iteration 57 \t train loss: 0.411485\n",
      "epoch: 2 \t iteration 58 \t train loss: 0.432879\n",
      "epoch: 2 \t iteration 59 \t train loss: 0.437048\n",
      "epoch: 2 \t iteration 60 \t train loss: 0.384244\n",
      "epoch: 2 \t iteration 61 \t train loss: 0.384188\n",
      "epoch: 2 \t iteration 62 \t train loss: 0.391952\n",
      "epoch: 2 \t iteration 63 \t train loss: 0.412004\n",
      "epoch: 2 \t iteration 64 \t train loss: 0.376988\n",
      "epoch: 2 \t iteration 65 \t train loss: 0.441388\n",
      "epoch: 2 \t iteration 66 \t train loss: 0.468535\n",
      "epoch: 2 \t iteration 67 \t train loss: 0.411003\n",
      "epoch: 2 \t iteration 68 \t train loss: 0.441178\n",
      "epoch: 2 \t iteration 69 \t train loss: 0.442646\n",
      "epoch: 2 \t iteration 70 \t train loss: 0.404105\n",
      "epoch: 2 \t iteration 71 \t train loss: 0.382053\n",
      "epoch: 2 \t iteration 72 \t train loss: 0.363021\n",
      "epoch: 2 \t iteration 73 \t train loss: 0.423689\n",
      "epoch: 2 \t iteration 74 \t train loss: 0.426525\n",
      "epoch: 2 \t iteration 75 \t train loss: 0.388522\n",
      "epoch: 2 \t iteration 76 \t train loss: 0.455052\n",
      "epoch: 2 \t iteration 77 \t train loss: 0.396050\n",
      "epoch: 2 \t iteration 78 \t train loss: 0.427409\n",
      "epoch: 2 \t iteration 79 \t train loss: 0.482032\n",
      "epoch: 2 \t iteration 80 \t train loss: 0.468893\n",
      "epoch: 2 \t iteration 81 \t train loss: 0.417572\n",
      "epoch: 2 \t iteration 82 \t train loss: 0.457993\n",
      "epoch: 2 \t iteration 83 \t train loss: 0.430557\n",
      "epoch: 2 \t iteration 84 \t train loss: 0.421749\n",
      "epoch: 2 \t iteration 85 \t train loss: 0.481354\n",
      "epoch: 2 \t iteration 86 \t train loss: 0.460655\n",
      "epoch: 2 \t iteration 87 \t train loss: 0.412442\n",
      "epoch: 2 \t iteration 88 \t train loss: 0.444945\n",
      "epoch: 2 \t iteration 89 \t train loss: 0.491883\n",
      "epoch: 2 \t iteration 90 \t train loss: 0.409787\n",
      "epoch: 2 \t iteration 91 \t train loss: 0.398917\n",
      "epoch: 2 \t iteration 92 \t train loss: 0.440192\n",
      "epoch: 2 \t iteration 93 \t train loss: 0.420026\n",
      "epoch: 2 \t iteration 94 \t train loss: 0.373144\n",
      "epoch: 2 \t iteration 95 \t train loss: 0.357439\n",
      "epoch: 2 \t iteration 96 \t train loss: 0.392789\n",
      "epoch: 2 \t iteration 97 \t train loss: 0.395744\n",
      "epoch: 2 \t iteration 98 \t train loss: 0.457419\n",
      "epoch: 2 \t iteration 99 \t train loss: 0.444685\n",
      "epoch: 2 \t iteration 100 \t train loss: 0.412398\n",
      "epoch: 2 \t iteration 101 \t train loss: 0.399414\n",
      "epoch: 2 \t iteration 102 \t train loss: 0.406075\n",
      "epoch: 2 \t iteration 103 \t train loss: 0.412114\n",
      "epoch: 2 \t iteration 104 \t train loss: 0.441571\n",
      "epoch: 2 \t iteration 105 \t train loss: 0.418138\n",
      "epoch: 2 \t iteration 106 \t train loss: 0.379286\n",
      "epoch: 2 \t iteration 107 \t train loss: 0.414461\n",
      "epoch: 2 \t iteration 108 \t train loss: 0.442380\n",
      "epoch: 2 \t iteration 109 \t train loss: 0.503176\n",
      "epoch: 2 \t iteration 110 \t train loss: 0.427211\n",
      "epoch: 2 \t iteration 111 \t train loss: 0.421143\n",
      "epoch: 2 \t iteration 112 \t train loss: 0.388311\n",
      "epoch: 2 \t iteration 113 \t train loss: 0.423000\n",
      "epoch: 2 \t iteration 114 \t train loss: 0.430035\n",
      "epoch: 2 \t iteration 115 \t train loss: 0.358259\n",
      "epoch: 2 \t iteration 116 \t train loss: 0.344025\n",
      "epoch: 2 \t iteration 117 \t train loss: 0.483205\n",
      "epoch: 2 \t iteration 118 \t train loss: 0.447014\n",
      "epoch: 2 \t iteration 119 \t train loss: 0.467880\n",
      "epoch: 2 \t iteration 120 \t train loss: 0.391306\n",
      "epoch: 2 \t iteration 121 \t train loss: 0.422477\n",
      "epoch: 2 \t iteration 122 \t train loss: 0.419059\n",
      "epoch: 2 \t iteration 123 \t train loss: 0.368656\n",
      "epoch: 2 \t iteration 124 \t train loss: 0.418130\n",
      "epoch: 2 \t iteration 125 \t train loss: 0.495081\n",
      "epoch: 2 \t iteration 126 \t train loss: 0.433589\n",
      "epoch: 2 \t iteration 127 \t train loss: 0.413830\n",
      "epoch: 2 \t iteration 128 \t train loss: 0.450664\n",
      "epoch: 2 \t iteration 129 \t train loss: 0.481498\n",
      "epoch: 2 \t iteration 130 \t train loss: 0.424635\n",
      "epoch: 2 \t iteration 131 \t train loss: 0.423217\n",
      "epoch: 2 \t iteration 132 \t train loss: 0.438249\n",
      "epoch: 2 \t iteration 133 \t train loss: 0.355061\n",
      "epoch: 2 \t iteration 134 \t train loss: 0.388584\n",
      "epoch: 2 \t iteration 135 \t train loss: 0.420695\n",
      "epoch: 2 \t iteration 136 \t train loss: 0.428429\n",
      "epoch: 2 \t iteration 137 \t train loss: 0.451919\n",
      "epoch: 2 \t iteration 138 \t train loss: 0.359891\n",
      "epoch: 2 \t iteration 139 \t train loss: 0.448417\n",
      "epoch: 2 \t iteration 140 \t train loss: 0.434801\n",
      "epoch: 2 \t iteration 141 \t train loss: 0.409081\n",
      "epoch: 2 \t iteration 142 \t train loss: 0.423657\n",
      "epoch: 2 \t iteration 143 \t train loss: 0.452511\n",
      "epoch: 2 \t iteration 144 \t train loss: 0.445721\n",
      "epoch: 2 \t iteration 145 \t train loss: 0.450746\n",
      "epoch: 2 \t iteration 146 \t train loss: 0.393084\n",
      "epoch: 2 \t iteration 147 \t train loss: 0.366060\n",
      "epoch: 2 \t iteration 148 \t train loss: 0.396135\n",
      "epoch: 2 \t iteration 149 \t train loss: 0.462268\n",
      "epoch: 2 \t iteration 150 \t train loss: 0.442138\n",
      "epoch: 2 \t iteration 151 \t train loss: 0.400046\n",
      "epoch: 2 \t iteration 152 \t train loss: 0.369606\n",
      "epoch: 2 \t iteration 153 \t train loss: 0.394710\n",
      "epoch: 2 \t iteration 154 \t train loss: 0.394332\n",
      "epoch: 2 \t iteration 155 \t train loss: 0.428846\n",
      "epoch: 2 \t iteration 156 \t train loss: 0.486469\n",
      "epoch: 2 \t iteration 157 \t train loss: 0.400631\n",
      "epoch: 2 \t iteration 158 \t train loss: 0.498246\n",
      "epoch: 2 \t iteration 159 \t train loss: 0.455728\n",
      "epoch: 2 \t iteration 160 \t train loss: 0.404157\n",
      "epoch: 2 \t iteration 161 \t train loss: 0.450794\n",
      "epoch: 2 \t iteration 162 \t train loss: 0.435694\n",
      "epoch: 2 \t iteration 163 \t train loss: 0.386656\n",
      "epoch: 2 \t iteration 164 \t train loss: 0.390968\n",
      "epoch: 2 \t iteration 165 \t train loss: 0.382247\n",
      "epoch: 2 \t iteration 166 \t train loss: 0.365505\n",
      "epoch: 2 \t iteration 167 \t train loss: 0.396624\n",
      "epoch: 2 \t iteration 168 \t train loss: 0.484205\n",
      "epoch: 2 \t iteration 169 \t train loss: 0.373999\n",
      "epoch: 2 \t iteration 170 \t train loss: 0.379813\n",
      "epoch: 2 \t iteration 171 \t train loss: 0.453839\n",
      "epoch: 2 \t iteration 172 \t train loss: 0.410229\n",
      "epoch: 2 \t iteration 173 \t train loss: 0.359741\n",
      "epoch: 2 \t iteration 174 \t train loss: 0.411108\n",
      "epoch: 2 \t iteration 175 \t train loss: 0.397513\n",
      "epoch: 2 \t iteration 176 \t train loss: 0.425426\n",
      "epoch: 2 \t iteration 177 \t train loss: 0.396644\n",
      "epoch: 2 \t iteration 178 \t train loss: 0.369625\n",
      "epoch: 2 \t iteration 179 \t train loss: 0.453908\n",
      "epoch: 2 \t iteration 180 \t train loss: 0.371891\n",
      "epoch: 2 \t iteration 181 \t train loss: 0.384910\n",
      "epoch: 2 \t iteration 182 \t train loss: 0.418454\n",
      "epoch: 2 \t iteration 183 \t train loss: 0.341795\n",
      "epoch: 2 \t iteration 184 \t train loss: 0.397832\n",
      "epoch: 2 \t iteration 185 \t train loss: 0.431351\n",
      "epoch: 2 \t iteration 186 \t train loss: 0.379347\n",
      "epoch: 2 \t iteration 187 \t train loss: 0.361451\n",
      "epoch: 2 \t iteration 188 \t train loss: 0.386577\n",
      "epoch: 2 \t iteration 189 \t train loss: 0.419394\n",
      "epoch: 2 \t iteration 190 \t train loss: 0.448900\n",
      "epoch: 2 \t iteration 191 \t train loss: 0.362701\n",
      "epoch: 2 \t iteration 192 \t train loss: 0.326736\n",
      "epoch: 2 \t iteration 193 \t train loss: 0.348172\n",
      "epoch: 2 \t iteration 194 \t train loss: 0.359734\n",
      "epoch: 2 \t iteration 195 \t train loss: 0.295972\n",
      "epoch: 2 \t iteration 196 \t train loss: 0.272500\n",
      "epoch: 2 \t iteration 197 \t train loss: 0.443569\n",
      "epoch: 2 \t iteration 198 \t train loss: 0.395680\n",
      "epoch: 2 \t iteration 199 \t train loss: 0.353632\n",
      "epoch:2 \t mean train loss: 0.417058 \t mean train acc: 0.850040\n",
      "epoch: 2 \t iteration 0 \t eval loss: 0.389643\n",
      "epoch: 2 \t iteration 1 \t eval loss: 0.362653\n",
      "epoch: 2 \t iteration 2 \t eval loss: 0.455351\n",
      "epoch: 2 \t iteration 3 \t eval loss: 0.413487\n",
      "epoch: 2 \t iteration 4 \t eval loss: 0.464736\n",
      "epoch: 2 \t iteration 5 \t eval loss: 0.431710\n",
      "epoch: 2 \t iteration 6 \t eval loss: 0.377662\n",
      "epoch: 2 \t iteration 7 \t eval loss: 0.387045\n",
      "epoch: 2 \t iteration 8 \t eval loss: 0.371154\n",
      "epoch: 2 \t iteration 9 \t eval loss: 0.385016\n",
      "epoch: 2 \t iteration 10 \t eval loss: 0.370229\n",
      "epoch: 2 \t iteration 11 \t eval loss: 0.394135\n",
      "epoch: 2 \t iteration 12 \t eval loss: 0.408221\n",
      "epoch: 2 \t iteration 13 \t eval loss: 0.387245\n",
      "epoch: 2 \t iteration 14 \t eval loss: 0.424985\n",
      "epoch: 2 \t iteration 15 \t eval loss: 0.382256\n",
      "epoch: 2 \t iteration 16 \t eval loss: 0.419406\n",
      "epoch: 2 \t iteration 17 \t eval loss: 0.408391\n",
      "epoch: 2 \t iteration 18 \t eval loss: 0.387699\n",
      "epoch: 2 \t iteration 19 \t eval loss: 0.407284\n",
      "epoch: 2 \t iteration 20 \t eval loss: 0.408731\n",
      "epoch: 2 \t iteration 21 \t eval loss: 0.372116\n",
      "epoch: 2 \t iteration 22 \t eval loss: 0.407386\n",
      "epoch: 2 \t iteration 23 \t eval loss: 0.383716\n",
      "epoch: 2 \t iteration 24 \t eval loss: 0.372942\n",
      "epoch: 2 \t iteration 25 \t eval loss: 0.409767\n",
      "epoch: 2 \t iteration 26 \t eval loss: 0.320082\n",
      "epoch: 2 \t iteration 27 \t eval loss: 0.465523\n",
      "epoch: 2 \t iteration 28 \t eval loss: 0.442269\n",
      "epoch: 2 \t iteration 29 \t eval loss: 0.444039\n",
      "epoch: 2 \t iteration 30 \t eval loss: 0.413270\n",
      "epoch: 2 \t iteration 31 \t eval loss: 0.450490\n",
      "epoch: 2 \t iteration 32 \t eval loss: 0.435636\n",
      "epoch: 2 \t iteration 33 \t eval loss: 0.430306\n",
      "epoch: 2 \t iteration 34 \t eval loss: 0.472406\n",
      "epoch: 2 \t iteration 35 \t eval loss: 0.453144\n",
      "epoch: 2 \t iteration 36 \t eval loss: 0.365783\n",
      "epoch: 2 \t iteration 37 \t eval loss: 0.408157\n",
      "epoch: 2 \t iteration 38 \t eval loss: 0.396497\n",
      "epoch: 2 \t iteration 39 \t eval loss: 0.355389\n",
      "epoch:2 \t mean eval loss: 0.405899 \t mean eval acc: 0.851300\n",
      "epoch: 3 \t iteration 0 \t train loss: 0.408610\n",
      "epoch: 3 \t iteration 1 \t train loss: 0.361492\n",
      "epoch: 3 \t iteration 2 \t train loss: 0.379327\n",
      "epoch: 3 \t iteration 3 \t train loss: 0.391714\n",
      "epoch: 3 \t iteration 4 \t train loss: 0.397893\n",
      "epoch: 3 \t iteration 5 \t train loss: 0.378298\n",
      "epoch: 3 \t iteration 6 \t train loss: 0.498031\n",
      "epoch: 3 \t iteration 7 \t train loss: 0.426685\n",
      "epoch: 3 \t iteration 8 \t train loss: 0.388941\n",
      "epoch: 3 \t iteration 9 \t train loss: 0.451894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 \t iteration 10 \t train loss: 0.439562\n",
      "epoch: 3 \t iteration 11 \t train loss: 0.442132\n",
      "epoch: 3 \t iteration 12 \t train loss: 0.468101\n",
      "epoch: 3 \t iteration 13 \t train loss: 0.389142\n",
      "epoch: 3 \t iteration 14 \t train loss: 0.410181\n",
      "epoch: 3 \t iteration 15 \t train loss: 0.454410\n",
      "epoch: 3 \t iteration 16 \t train loss: 0.489247\n",
      "epoch: 3 \t iteration 17 \t train loss: 0.461023\n",
      "epoch: 3 \t iteration 18 \t train loss: 0.515296\n",
      "epoch: 3 \t iteration 19 \t train loss: 0.441576\n",
      "epoch: 3 \t iteration 20 \t train loss: 0.396787\n",
      "epoch: 3 \t iteration 21 \t train loss: 0.382199\n",
      "epoch: 3 \t iteration 22 \t train loss: 0.416971\n",
      "epoch: 3 \t iteration 23 \t train loss: 0.460654\n",
      "epoch: 3 \t iteration 24 \t train loss: 0.442118\n",
      "epoch: 3 \t iteration 25 \t train loss: 0.376824\n",
      "epoch: 3 \t iteration 26 \t train loss: 0.385051\n",
      "epoch: 3 \t iteration 27 \t train loss: 0.456068\n",
      "epoch: 3 \t iteration 28 \t train loss: 0.443496\n",
      "epoch: 3 \t iteration 29 \t train loss: 0.389137\n",
      "epoch: 3 \t iteration 30 \t train loss: 0.493196\n",
      "epoch: 3 \t iteration 31 \t train loss: 0.420521\n",
      "epoch: 3 \t iteration 32 \t train loss: 0.385429\n",
      "epoch: 3 \t iteration 33 \t train loss: 0.388679\n",
      "epoch: 3 \t iteration 34 \t train loss: 0.385108\n",
      "epoch: 3 \t iteration 35 \t train loss: 0.346405\n",
      "epoch: 3 \t iteration 36 \t train loss: 0.435286\n",
      "epoch: 3 \t iteration 37 \t train loss: 0.410010\n",
      "epoch: 3 \t iteration 38 \t train loss: 0.376918\n",
      "epoch: 3 \t iteration 39 \t train loss: 0.410394\n",
      "epoch: 3 \t iteration 40 \t train loss: 0.441972\n",
      "epoch: 3 \t iteration 41 \t train loss: 0.378851\n",
      "epoch: 3 \t iteration 42 \t train loss: 0.399587\n",
      "epoch: 3 \t iteration 43 \t train loss: 0.460611\n",
      "epoch: 3 \t iteration 44 \t train loss: 0.365779\n",
      "epoch: 3 \t iteration 45 \t train loss: 0.409133\n",
      "epoch: 3 \t iteration 46 \t train loss: 0.410953\n",
      "epoch: 3 \t iteration 47 \t train loss: 0.343867\n",
      "epoch: 3 \t iteration 48 \t train loss: 0.434447\n",
      "epoch: 3 \t iteration 49 \t train loss: 0.413823\n",
      "epoch: 3 \t iteration 50 \t train loss: 0.541365\n",
      "epoch: 3 \t iteration 51 \t train loss: 0.377303\n",
      "epoch: 3 \t iteration 52 \t train loss: 0.428257\n",
      "epoch: 3 \t iteration 53 \t train loss: 0.394424\n",
      "epoch: 3 \t iteration 54 \t train loss: 0.406502\n",
      "epoch: 3 \t iteration 55 \t train loss: 0.421609\n",
      "epoch: 3 \t iteration 56 \t train loss: 0.411466\n",
      "epoch: 3 \t iteration 57 \t train loss: 0.403269\n",
      "epoch: 3 \t iteration 58 \t train loss: 0.425750\n",
      "epoch: 3 \t iteration 59 \t train loss: 0.427461\n",
      "epoch: 3 \t iteration 60 \t train loss: 0.377628\n",
      "epoch: 3 \t iteration 61 \t train loss: 0.377467\n",
      "epoch: 3 \t iteration 62 \t train loss: 0.387160\n",
      "epoch: 3 \t iteration 63 \t train loss: 0.406044\n",
      "epoch: 3 \t iteration 64 \t train loss: 0.368538\n",
      "epoch: 3 \t iteration 65 \t train loss: 0.433386\n",
      "epoch: 3 \t iteration 66 \t train loss: 0.462141\n",
      "epoch: 3 \t iteration 67 \t train loss: 0.403737\n",
      "epoch: 3 \t iteration 68 \t train loss: 0.434197\n",
      "epoch: 3 \t iteration 69 \t train loss: 0.434692\n",
      "epoch: 3 \t iteration 70 \t train loss: 0.397282\n",
      "epoch: 3 \t iteration 71 \t train loss: 0.375923\n",
      "epoch: 3 \t iteration 72 \t train loss: 0.356876\n",
      "epoch: 3 \t iteration 73 \t train loss: 0.415973\n",
      "epoch: 3 \t iteration 74 \t train loss: 0.419316\n",
      "epoch: 3 \t iteration 75 \t train loss: 0.381304\n",
      "epoch: 3 \t iteration 76 \t train loss: 0.448167\n",
      "epoch: 3 \t iteration 77 \t train loss: 0.389946\n",
      "epoch: 3 \t iteration 78 \t train loss: 0.421294\n",
      "epoch: 3 \t iteration 79 \t train loss: 0.474897\n",
      "epoch: 3 \t iteration 80 \t train loss: 0.460221\n",
      "epoch: 3 \t iteration 81 \t train loss: 0.411569\n",
      "epoch: 3 \t iteration 82 \t train loss: 0.451429\n",
      "epoch: 3 \t iteration 83 \t train loss: 0.424630\n",
      "epoch: 3 \t iteration 84 \t train loss: 0.416288\n",
      "epoch: 3 \t iteration 85 \t train loss: 0.472995\n",
      "epoch: 3 \t iteration 86 \t train loss: 0.452784\n",
      "epoch: 3 \t iteration 87 \t train loss: 0.405386\n",
      "epoch: 3 \t iteration 88 \t train loss: 0.436757\n",
      "epoch: 3 \t iteration 89 \t train loss: 0.484172\n",
      "epoch: 3 \t iteration 90 \t train loss: 0.401783\n",
      "epoch: 3 \t iteration 91 \t train loss: 0.392435\n",
      "epoch: 3 \t iteration 92 \t train loss: 0.430259\n",
      "epoch: 3 \t iteration 93 \t train loss: 0.414470\n",
      "epoch: 3 \t iteration 94 \t train loss: 0.366303\n",
      "epoch: 3 \t iteration 95 \t train loss: 0.351474\n",
      "epoch: 3 \t iteration 96 \t train loss: 0.385437\n",
      "epoch: 3 \t iteration 97 \t train loss: 0.389675\n",
      "epoch: 3 \t iteration 98 \t train loss: 0.450829\n",
      "epoch: 3 \t iteration 99 \t train loss: 0.436662\n",
      "epoch: 3 \t iteration 100 \t train loss: 0.405867\n",
      "epoch: 3 \t iteration 101 \t train loss: 0.391650\n",
      "epoch: 3 \t iteration 102 \t train loss: 0.400376\n",
      "epoch: 3 \t iteration 103 \t train loss: 0.405381\n",
      "epoch: 3 \t iteration 104 \t train loss: 0.434885\n",
      "epoch: 3 \t iteration 105 \t train loss: 0.409658\n",
      "epoch: 3 \t iteration 106 \t train loss: 0.375226\n",
      "epoch: 3 \t iteration 107 \t train loss: 0.410497\n",
      "epoch: 3 \t iteration 108 \t train loss: 0.437657\n",
      "epoch: 3 \t iteration 109 \t train loss: 0.501635\n",
      "epoch: 3 \t iteration 110 \t train loss: 0.421501\n",
      "epoch: 3 \t iteration 111 \t train loss: 0.415248\n",
      "epoch: 3 \t iteration 112 \t train loss: 0.381814\n",
      "epoch: 3 \t iteration 113 \t train loss: 0.417043\n",
      "epoch: 3 \t iteration 114 \t train loss: 0.423933\n",
      "epoch: 3 \t iteration 115 \t train loss: 0.351713\n",
      "epoch: 3 \t iteration 116 \t train loss: 0.337840\n",
      "epoch: 3 \t iteration 117 \t train loss: 0.476305\n",
      "epoch: 3 \t iteration 118 \t train loss: 0.440211\n",
      "epoch: 3 \t iteration 119 \t train loss: 0.462204\n",
      "epoch: 3 \t iteration 120 \t train loss: 0.385297\n",
      "epoch: 3 \t iteration 121 \t train loss: 0.417479\n",
      "epoch: 3 \t iteration 122 \t train loss: 0.412945\n",
      "epoch: 3 \t iteration 123 \t train loss: 0.361791\n",
      "epoch: 3 \t iteration 124 \t train loss: 0.411548\n",
      "epoch: 3 \t iteration 125 \t train loss: 0.488460\n",
      "epoch: 3 \t iteration 126 \t train loss: 0.425920\n",
      "epoch: 3 \t iteration 127 \t train loss: 0.406081\n",
      "epoch: 3 \t iteration 128 \t train loss: 0.445912\n",
      "epoch: 3 \t iteration 129 \t train loss: 0.476531\n",
      "epoch: 3 \t iteration 130 \t train loss: 0.419764\n",
      "epoch: 3 \t iteration 131 \t train loss: 0.417729\n",
      "epoch: 3 \t iteration 132 \t train loss: 0.434178\n",
      "epoch: 3 \t iteration 133 \t train loss: 0.350064\n",
      "epoch: 3 \t iteration 134 \t train loss: 0.383107\n",
      "epoch: 3 \t iteration 135 \t train loss: 0.415802\n",
      "epoch: 3 \t iteration 136 \t train loss: 0.422552\n",
      "epoch: 3 \t iteration 137 \t train loss: 0.446240\n",
      "epoch: 3 \t iteration 138 \t train loss: 0.354253\n",
      "epoch: 3 \t iteration 139 \t train loss: 0.443962\n",
      "epoch: 3 \t iteration 140 \t train loss: 0.428661\n",
      "epoch: 3 \t iteration 141 \t train loss: 0.403544\n",
      "epoch: 3 \t iteration 142 \t train loss: 0.418142\n",
      "epoch: 3 \t iteration 143 \t train loss: 0.446934\n",
      "epoch: 3 \t iteration 144 \t train loss: 0.440395\n",
      "epoch: 3 \t iteration 145 \t train loss: 0.445605\n",
      "epoch: 3 \t iteration 146 \t train loss: 0.387309\n",
      "epoch: 3 \t iteration 147 \t train loss: 0.360860\n",
      "epoch: 3 \t iteration 148 \t train loss: 0.388680\n",
      "epoch: 3 \t iteration 149 \t train loss: 0.456101\n",
      "epoch: 3 \t iteration 150 \t train loss: 0.435558\n",
      "epoch: 3 \t iteration 151 \t train loss: 0.394811\n",
      "epoch: 3 \t iteration 152 \t train loss: 0.364017\n",
      "epoch: 3 \t iteration 153 \t train loss: 0.390033\n",
      "epoch: 3 \t iteration 154 \t train loss: 0.388915\n",
      "epoch: 3 \t iteration 155 \t train loss: 0.422080\n",
      "epoch: 3 \t iteration 156 \t train loss: 0.479376\n",
      "epoch: 3 \t iteration 157 \t train loss: 0.396251\n",
      "epoch: 3 \t iteration 158 \t train loss: 0.491722\n",
      "epoch: 3 \t iteration 159 \t train loss: 0.451081\n",
      "epoch: 3 \t iteration 160 \t train loss: 0.398405\n",
      "epoch: 3 \t iteration 161 \t train loss: 0.447703\n",
      "epoch: 3 \t iteration 162 \t train loss: 0.428629\n",
      "epoch: 3 \t iteration 163 \t train loss: 0.381187\n",
      "epoch: 3 \t iteration 164 \t train loss: 0.385112\n",
      "epoch: 3 \t iteration 165 \t train loss: 0.376559\n",
      "epoch: 3 \t iteration 166 \t train loss: 0.359415\n",
      "epoch: 3 \t iteration 167 \t train loss: 0.392156\n",
      "epoch: 3 \t iteration 168 \t train loss: 0.478316\n",
      "epoch: 3 \t iteration 169 \t train loss: 0.368750\n",
      "epoch: 3 \t iteration 170 \t train loss: 0.374585\n",
      "epoch: 3 \t iteration 171 \t train loss: 0.448116\n",
      "epoch: 3 \t iteration 172 \t train loss: 0.406255\n",
      "epoch: 3 \t iteration 173 \t train loss: 0.353424\n",
      "epoch: 3 \t iteration 174 \t train loss: 0.406567\n",
      "epoch: 3 \t iteration 175 \t train loss: 0.391653\n",
      "epoch: 3 \t iteration 176 \t train loss: 0.420595\n",
      "epoch: 3 \t iteration 177 \t train loss: 0.391171\n",
      "epoch: 3 \t iteration 178 \t train loss: 0.364442\n",
      "epoch: 3 \t iteration 179 \t train loss: 0.448514\n",
      "epoch: 3 \t iteration 180 \t train loss: 0.367072\n",
      "epoch: 3 \t iteration 181 \t train loss: 0.379052\n",
      "epoch: 3 \t iteration 182 \t train loss: 0.414097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 \t iteration 183 \t train loss: 0.336401\n",
      "epoch: 3 \t iteration 184 \t train loss: 0.393816\n",
      "epoch: 3 \t iteration 185 \t train loss: 0.425625\n",
      "epoch: 3 \t iteration 186 \t train loss: 0.374214\n",
      "epoch: 3 \t iteration 187 \t train loss: 0.356370\n",
      "epoch: 3 \t iteration 188 \t train loss: 0.381944\n",
      "epoch: 3 \t iteration 189 \t train loss: 0.413472\n",
      "epoch: 3 \t iteration 190 \t train loss: 0.446321\n",
      "epoch: 3 \t iteration 191 \t train loss: 0.358190\n",
      "epoch: 3 \t iteration 192 \t train loss: 0.321112\n",
      "epoch: 3 \t iteration 193 \t train loss: 0.342365\n",
      "epoch: 3 \t iteration 194 \t train loss: 0.354951\n",
      "epoch: 3 \t iteration 195 \t train loss: 0.291262\n",
      "epoch: 3 \t iteration 196 \t train loss: 0.267922\n",
      "epoch: 3 \t iteration 197 \t train loss: 0.440596\n",
      "epoch: 3 \t iteration 198 \t train loss: 0.391239\n",
      "epoch: 3 \t iteration 199 \t train loss: 0.347370\n",
      "epoch:3 \t mean train loss: 0.410640 \t mean train acc: 0.852480\n",
      "epoch: 3 \t iteration 0 \t eval loss: 0.384337\n",
      "epoch: 3 \t iteration 1 \t eval loss: 0.357766\n",
      "epoch: 3 \t iteration 2 \t eval loss: 0.449579\n",
      "epoch: 3 \t iteration 3 \t eval loss: 0.407424\n",
      "epoch: 3 \t iteration 4 \t eval loss: 0.460606\n",
      "epoch: 3 \t iteration 5 \t eval loss: 0.430174\n",
      "epoch: 3 \t iteration 6 \t eval loss: 0.373275\n",
      "epoch: 3 \t iteration 7 \t eval loss: 0.382283\n",
      "epoch: 3 \t iteration 8 \t eval loss: 0.367065\n",
      "epoch: 3 \t iteration 9 \t eval loss: 0.379791\n",
      "epoch: 3 \t iteration 10 \t eval loss: 0.364639\n",
      "epoch: 3 \t iteration 11 \t eval loss: 0.389168\n",
      "epoch: 3 \t iteration 12 \t eval loss: 0.402209\n",
      "epoch: 3 \t iteration 13 \t eval loss: 0.380620\n",
      "epoch: 3 \t iteration 14 \t eval loss: 0.420131\n",
      "epoch: 3 \t iteration 15 \t eval loss: 0.376381\n",
      "epoch: 3 \t iteration 16 \t eval loss: 0.415339\n",
      "epoch: 3 \t iteration 17 \t eval loss: 0.403149\n",
      "epoch: 3 \t iteration 18 \t eval loss: 0.381816\n",
      "epoch: 3 \t iteration 19 \t eval loss: 0.402238\n",
      "epoch: 3 \t iteration 20 \t eval loss: 0.404548\n",
      "epoch: 3 \t iteration 21 \t eval loss: 0.367464\n",
      "epoch: 3 \t iteration 22 \t eval loss: 0.401940\n",
      "epoch: 3 \t iteration 23 \t eval loss: 0.377642\n",
      "epoch: 3 \t iteration 24 \t eval loss: 0.368752\n",
      "epoch: 3 \t iteration 25 \t eval loss: 0.405046\n",
      "epoch: 3 \t iteration 26 \t eval loss: 0.315361\n",
      "epoch: 3 \t iteration 27 \t eval loss: 0.463520\n",
      "epoch: 3 \t iteration 28 \t eval loss: 0.437337\n",
      "epoch: 3 \t iteration 29 \t eval loss: 0.438064\n",
      "epoch: 3 \t iteration 30 \t eval loss: 0.408008\n",
      "epoch: 3 \t iteration 31 \t eval loss: 0.445133\n",
      "epoch: 3 \t iteration 32 \t eval loss: 0.431429\n",
      "epoch: 3 \t iteration 33 \t eval loss: 0.425425\n",
      "epoch: 3 \t iteration 34 \t eval loss: 0.468668\n",
      "epoch: 3 \t iteration 35 \t eval loss: 0.447895\n",
      "epoch: 3 \t iteration 36 \t eval loss: 0.361231\n",
      "epoch: 3 \t iteration 37 \t eval loss: 0.403480\n",
      "epoch: 3 \t iteration 38 \t eval loss: 0.391924\n",
      "epoch: 3 \t iteration 39 \t eval loss: 0.349744\n",
      "epoch:3 \t mean eval loss: 0.401015 \t mean eval acc: 0.853900\n",
      "epoch: 4 \t iteration 0 \t train loss: 0.404267\n",
      "epoch: 4 \t iteration 1 \t train loss: 0.356583\n",
      "epoch: 4 \t iteration 2 \t train loss: 0.374688\n",
      "epoch: 4 \t iteration 3 \t train loss: 0.386177\n",
      "epoch: 4 \t iteration 4 \t train loss: 0.392559\n",
      "epoch: 4 \t iteration 5 \t train loss: 0.374906\n",
      "epoch: 4 \t iteration 6 \t train loss: 0.493695\n",
      "epoch: 4 \t iteration 7 \t train loss: 0.422144\n",
      "epoch: 4 \t iteration 8 \t train loss: 0.384944\n",
      "epoch: 4 \t iteration 9 \t train loss: 0.446791\n",
      "epoch: 4 \t iteration 10 \t train loss: 0.434159\n",
      "epoch: 4 \t iteration 11 \t train loss: 0.436971\n",
      "epoch: 4 \t iteration 12 \t train loss: 0.463491\n",
      "epoch: 4 \t iteration 13 \t train loss: 0.383325\n",
      "epoch: 4 \t iteration 14 \t train loss: 0.406415\n",
      "epoch: 4 \t iteration 15 \t train loss: 0.449137\n",
      "epoch: 4 \t iteration 16 \t train loss: 0.484539\n",
      "epoch: 4 \t iteration 17 \t train loss: 0.455369\n",
      "epoch: 4 \t iteration 18 \t train loss: 0.509759\n",
      "epoch: 4 \t iteration 19 \t train loss: 0.437369\n",
      "epoch: 4 \t iteration 20 \t train loss: 0.393055\n",
      "epoch: 4 \t iteration 21 \t train loss: 0.377637\n",
      "epoch: 4 \t iteration 22 \t train loss: 0.412144\n",
      "epoch: 4 \t iteration 23 \t train loss: 0.455457\n",
      "epoch: 4 \t iteration 24 \t train loss: 0.435935\n",
      "epoch: 4 \t iteration 25 \t train loss: 0.371395\n",
      "epoch: 4 \t iteration 26 \t train loss: 0.382283\n",
      "epoch: 4 \t iteration 27 \t train loss: 0.450827\n",
      "epoch: 4 \t iteration 28 \t train loss: 0.438141\n",
      "epoch: 4 \t iteration 29 \t train loss: 0.384703\n",
      "epoch: 4 \t iteration 30 \t train loss: 0.488210\n",
      "epoch: 4 \t iteration 31 \t train loss: 0.416325\n",
      "epoch: 4 \t iteration 32 \t train loss: 0.380877\n",
      "epoch: 4 \t iteration 33 \t train loss: 0.384268\n",
      "epoch: 4 \t iteration 34 \t train loss: 0.379388\n",
      "epoch: 4 \t iteration 35 \t train loss: 0.341197\n",
      "epoch: 4 \t iteration 36 \t train loss: 0.429427\n",
      "epoch: 4 \t iteration 37 \t train loss: 0.405702\n",
      "epoch: 4 \t iteration 38 \t train loss: 0.372895\n",
      "epoch: 4 \t iteration 39 \t train loss: 0.405588\n",
      "epoch: 4 \t iteration 40 \t train loss: 0.437641\n",
      "epoch: 4 \t iteration 41 \t train loss: 0.373069\n",
      "epoch: 4 \t iteration 42 \t train loss: 0.395641\n",
      "epoch: 4 \t iteration 43 \t train loss: 0.455906\n",
      "epoch: 4 \t iteration 44 \t train loss: 0.361216\n",
      "epoch: 4 \t iteration 45 \t train loss: 0.403716\n",
      "epoch: 4 \t iteration 46 \t train loss: 0.406715\n",
      "epoch: 4 \t iteration 47 \t train loss: 0.341118\n",
      "epoch: 4 \t iteration 48 \t train loss: 0.428828\n",
      "epoch: 4 \t iteration 49 \t train loss: 0.409636\n",
      "epoch: 4 \t iteration 50 \t train loss: 0.538434\n",
      "epoch: 4 \t iteration 51 \t train loss: 0.372679\n",
      "epoch: 4 \t iteration 52 \t train loss: 0.423992\n",
      "epoch: 4 \t iteration 53 \t train loss: 0.389445\n",
      "epoch: 4 \t iteration 54 \t train loss: 0.400666\n",
      "epoch: 4 \t iteration 55 \t train loss: 0.417277\n",
      "epoch: 4 \t iteration 56 \t train loss: 0.407329\n",
      "epoch: 4 \t iteration 57 \t train loss: 0.398043\n",
      "epoch: 4 \t iteration 58 \t train loss: 0.421152\n",
      "epoch: 4 \t iteration 59 \t train loss: 0.421094\n",
      "epoch: 4 \t iteration 60 \t train loss: 0.373163\n",
      "epoch: 4 \t iteration 61 \t train loss: 0.373387\n",
      "epoch: 4 \t iteration 62 \t train loss: 0.384090\n",
      "epoch: 4 \t iteration 63 \t train loss: 0.402361\n",
      "epoch: 4 \t iteration 64 \t train loss: 0.363111\n",
      "epoch: 4 \t iteration 65 \t train loss: 0.427876\n",
      "epoch: 4 \t iteration 66 \t train loss: 0.458213\n",
      "epoch: 4 \t iteration 67 \t train loss: 0.398994\n",
      "epoch: 4 \t iteration 68 \t train loss: 0.429777\n",
      "epoch: 4 \t iteration 69 \t train loss: 0.429664\n",
      "epoch: 4 \t iteration 70 \t train loss: 0.392667\n",
      "epoch: 4 \t iteration 71 \t train loss: 0.372220\n",
      "epoch: 4 \t iteration 72 \t train loss: 0.353149\n",
      "epoch: 4 \t iteration 73 \t train loss: 0.411071\n",
      "epoch: 4 \t iteration 74 \t train loss: 0.414732\n",
      "epoch: 4 \t iteration 75 \t train loss: 0.377062\n",
      "epoch: 4 \t iteration 76 \t train loss: 0.443608\n",
      "epoch: 4 \t iteration 77 \t train loss: 0.386013\n",
      "epoch: 4 \t iteration 78 \t train loss: 0.417140\n",
      "epoch: 4 \t iteration 79 \t train loss: 0.470366\n",
      "epoch: 4 \t iteration 80 \t train loss: 0.454473\n",
      "epoch: 4 \t iteration 81 \t train loss: 0.407686\n",
      "epoch: 4 \t iteration 82 \t train loss: 0.447355\n",
      "epoch: 4 \t iteration 83 \t train loss: 0.420771\n",
      "epoch: 4 \t iteration 84 \t train loss: 0.412747\n",
      "epoch: 4 \t iteration 85 \t train loss: 0.467323\n",
      "epoch: 4 \t iteration 86 \t train loss: 0.447705\n",
      "epoch: 4 \t iteration 87 \t train loss: 0.400853\n",
      "epoch: 4 \t iteration 88 \t train loss: 0.431096\n",
      "epoch: 4 \t iteration 89 \t train loss: 0.479057\n",
      "epoch: 4 \t iteration 90 \t train loss: 0.396413\n",
      "epoch: 4 \t iteration 91 \t train loss: 0.388208\n",
      "epoch: 4 \t iteration 92 \t train loss: 0.423121\n",
      "epoch: 4 \t iteration 93 \t train loss: 0.410914\n",
      "epoch: 4 \t iteration 94 \t train loss: 0.361806\n",
      "epoch: 4 \t iteration 95 \t train loss: 0.347916\n",
      "epoch: 4 \t iteration 96 \t train loss: 0.380703\n",
      "epoch: 4 \t iteration 97 \t train loss: 0.385653\n",
      "epoch: 4 \t iteration 98 \t train loss: 0.446199\n",
      "epoch: 4 \t iteration 99 \t train loss: 0.431121\n",
      "epoch: 4 \t iteration 100 \t train loss: 0.401619\n",
      "epoch: 4 \t iteration 101 \t train loss: 0.386498\n",
      "epoch: 4 \t iteration 102 \t train loss: 0.396814\n",
      "epoch: 4 \t iteration 103 \t train loss: 0.400714\n",
      "epoch: 4 \t iteration 104 \t train loss: 0.430364\n",
      "epoch: 4 \t iteration 105 \t train loss: 0.403816\n",
      "epoch: 4 \t iteration 106 \t train loss: 0.372620\n",
      "epoch: 4 \t iteration 107 \t train loss: 0.407973\n",
      "epoch: 4 \t iteration 108 \t train loss: 0.434403\n",
      "epoch: 4 \t iteration 109 \t train loss: 0.500754\n",
      "epoch: 4 \t iteration 110 \t train loss: 0.417504\n",
      "epoch: 4 \t iteration 111 \t train loss: 0.411475\n",
      "epoch: 4 \t iteration 112 \t train loss: 0.377364\n",
      "epoch: 4 \t iteration 113 \t train loss: 0.412822\n",
      "epoch: 4 \t iteration 114 \t train loss: 0.419640\n",
      "epoch: 4 \t iteration 115 \t train loss: 0.347502\n",
      "epoch: 4 \t iteration 116 \t train loss: 0.333700\n",
      "epoch: 4 \t iteration 117 \t train loss: 0.471455\n",
      "epoch: 4 \t iteration 118 \t train loss: 0.435526\n",
      "epoch: 4 \t iteration 119 \t train loss: 0.458341\n",
      "epoch: 4 \t iteration 120 \t train loss: 0.381253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 \t iteration 121 \t train loss: 0.414120\n",
      "epoch: 4 \t iteration 122 \t train loss: 0.408887\n",
      "epoch: 4 \t iteration 123 \t train loss: 0.357032\n",
      "epoch: 4 \t iteration 124 \t train loss: 0.407160\n",
      "epoch: 4 \t iteration 125 \t train loss: 0.483849\n",
      "epoch: 4 \t iteration 126 \t train loss: 0.420790\n",
      "epoch: 4 \t iteration 127 \t train loss: 0.400975\n",
      "epoch: 4 \t iteration 128 \t train loss: 0.442750\n",
      "epoch: 4 \t iteration 129 \t train loss: 0.472986\n",
      "epoch: 4 \t iteration 130 \t train loss: 0.416541\n",
      "epoch: 4 \t iteration 131 \t train loss: 0.413957\n",
      "epoch: 4 \t iteration 132 \t train loss: 0.431466\n",
      "epoch: 4 \t iteration 133 \t train loss: 0.346890\n",
      "epoch: 4 \t iteration 134 \t train loss: 0.379685\n",
      "epoch: 4 \t iteration 135 \t train loss: 0.412631\n",
      "epoch: 4 \t iteration 136 \t train loss: 0.418828\n",
      "epoch: 4 \t iteration 137 \t train loss: 0.442386\n",
      "epoch: 4 \t iteration 138 \t train loss: 0.350488\n",
      "epoch: 4 \t iteration 139 \t train loss: 0.441091\n",
      "epoch: 4 \t iteration 140 \t train loss: 0.424583\n",
      "epoch: 4 \t iteration 141 \t train loss: 0.399814\n",
      "epoch: 4 \t iteration 142 \t train loss: 0.414587\n",
      "epoch: 4 \t iteration 143 \t train loss: 0.443220\n",
      "epoch: 4 \t iteration 144 \t train loss: 0.436763\n",
      "epoch: 4 \t iteration 145 \t train loss: 0.442039\n",
      "epoch: 4 \t iteration 146 \t train loss: 0.383445\n",
      "epoch: 4 \t iteration 147 \t train loss: 0.357206\n",
      "epoch: 4 \t iteration 148 \t train loss: 0.383565\n",
      "epoch: 4 \t iteration 149 \t train loss: 0.451920\n",
      "epoch: 4 \t iteration 150 \t train loss: 0.431210\n",
      "epoch: 4 \t iteration 151 \t train loss: 0.391125\n",
      "epoch: 4 \t iteration 152 \t train loss: 0.360191\n",
      "epoch: 4 \t iteration 153 \t train loss: 0.386854\n",
      "epoch: 4 \t iteration 154 \t train loss: 0.385183\n",
      "epoch: 4 \t iteration 155 \t train loss: 0.417479\n",
      "epoch: 4 \t iteration 156 \t train loss: 0.474335\n",
      "epoch: 4 \t iteration 157 \t train loss: 0.393287\n",
      "epoch: 4 \t iteration 158 \t train loss: 0.487196\n",
      "epoch: 4 \t iteration 159 \t train loss: 0.447974\n",
      "epoch: 4 \t iteration 160 \t train loss: 0.394201\n",
      "epoch: 4 \t iteration 161 \t train loss: 0.445793\n",
      "epoch: 4 \t iteration 162 \t train loss: 0.423880\n",
      "epoch: 4 \t iteration 163 \t train loss: 0.377713\n",
      "epoch: 4 \t iteration 164 \t train loss: 0.381349\n",
      "epoch: 4 \t iteration 165 \t train loss: 0.372851\n",
      "epoch: 4 \t iteration 166 \t train loss: 0.355158\n",
      "epoch: 4 \t iteration 167 \t train loss: 0.389309\n",
      "epoch: 4 \t iteration 168 \t train loss: 0.474099\n",
      "epoch: 4 \t iteration 169 \t train loss: 0.365191\n",
      "epoch: 4 \t iteration 170 \t train loss: 0.370925\n",
      "epoch: 4 \t iteration 171 \t train loss: 0.444053\n",
      "epoch: 4 \t iteration 172 \t train loss: 0.403430\n",
      "epoch: 4 \t iteration 173 \t train loss: 0.349046\n",
      "epoch: 4 \t iteration 174 \t train loss: 0.403577\n",
      "epoch: 4 \t iteration 175 \t train loss: 0.387424\n",
      "epoch: 4 \t iteration 176 \t train loss: 0.417130\n",
      "epoch: 4 \t iteration 177 \t train loss: 0.387383\n",
      "epoch: 4 \t iteration 178 \t train loss: 0.360830\n",
      "epoch: 4 \t iteration 179 \t train loss: 0.444574\n",
      "epoch: 4 \t iteration 180 \t train loss: 0.363809\n",
      "epoch: 4 \t iteration 181 \t train loss: 0.374963\n",
      "epoch: 4 \t iteration 182 \t train loss: 0.410979\n",
      "epoch: 4 \t iteration 183 \t train loss: 0.332803\n",
      "epoch: 4 \t iteration 184 \t train loss: 0.391110\n",
      "epoch: 4 \t iteration 185 \t train loss: 0.421686\n",
      "epoch: 4 \t iteration 186 \t train loss: 0.370596\n",
      "epoch: 4 \t iteration 187 \t train loss: 0.352891\n",
      "epoch: 4 \t iteration 188 \t train loss: 0.378917\n",
      "epoch: 4 \t iteration 189 \t train loss: 0.409673\n",
      "epoch: 4 \t iteration 190 \t train loss: 0.444590\n",
      "epoch: 4 \t iteration 191 \t train loss: 0.355232\n",
      "epoch: 4 \t iteration 192 \t train loss: 0.317372\n",
      "epoch: 4 \t iteration 193 \t train loss: 0.338421\n",
      "epoch: 4 \t iteration 194 \t train loss: 0.351709\n",
      "epoch: 4 \t iteration 195 \t train loss: 0.288386\n",
      "epoch: 4 \t iteration 196 \t train loss: 0.264836\n",
      "epoch: 4 \t iteration 197 \t train loss: 0.439018\n",
      "epoch: 4 \t iteration 198 \t train loss: 0.388306\n",
      "epoch: 4 \t iteration 199 \t train loss: 0.343102\n",
      "epoch:4 \t mean train loss: 0.406445 \t mean train acc: 0.853380\n",
      "epoch: 4 \t iteration 0 \t eval loss: 0.380717\n",
      "epoch: 4 \t iteration 1 \t eval loss: 0.354577\n",
      "epoch: 4 \t iteration 2 \t eval loss: 0.445805\n",
      "epoch: 4 \t iteration 3 \t eval loss: 0.403343\n",
      "epoch: 4 \t iteration 4 \t eval loss: 0.457865\n",
      "epoch: 4 \t iteration 5 \t eval loss: 0.429335\n",
      "epoch: 4 \t iteration 6 \t eval loss: 0.370184\n",
      "epoch: 4 \t iteration 7 \t eval loss: 0.378963\n",
      "epoch: 4 \t iteration 8 \t eval loss: 0.364483\n",
      "epoch: 4 \t iteration 9 \t eval loss: 0.376272\n",
      "epoch: 4 \t iteration 10 \t eval loss: 0.360887\n",
      "epoch: 4 \t iteration 11 \t eval loss: 0.385904\n",
      "epoch: 4 \t iteration 12 \t eval loss: 0.398223\n",
      "epoch: 4 \t iteration 13 \t eval loss: 0.375976\n",
      "epoch: 4 \t iteration 14 \t eval loss: 0.416572\n",
      "epoch: 4 \t iteration 15 \t eval loss: 0.372372\n",
      "epoch: 4 \t iteration 16 \t eval loss: 0.412679\n",
      "epoch: 4 \t iteration 17 \t eval loss: 0.399545\n",
      "epoch: 4 \t iteration 18 \t eval loss: 0.377807\n",
      "epoch: 4 \t iteration 19 \t eval loss: 0.398920\n",
      "epoch: 4 \t iteration 20 \t eval loss: 0.401763\n",
      "epoch: 4 \t iteration 21 \t eval loss: 0.364331\n",
      "epoch: 4 \t iteration 22 \t eval loss: 0.398155\n",
      "epoch: 4 \t iteration 23 \t eval loss: 0.373485\n",
      "epoch: 4 \t iteration 24 \t eval loss: 0.365901\n",
      "epoch: 4 \t iteration 25 \t eval loss: 0.401814\n",
      "epoch: 4 \t iteration 26 \t eval loss: 0.312237\n",
      "epoch: 4 \t iteration 27 \t eval loss: 0.462383\n",
      "epoch: 4 \t iteration 28 \t eval loss: 0.433874\n",
      "epoch: 4 \t iteration 29 \t eval loss: 0.433936\n",
      "epoch: 4 \t iteration 30 \t eval loss: 0.404260\n",
      "epoch: 4 \t iteration 31 \t eval loss: 0.441417\n",
      "epoch: 4 \t iteration 32 \t eval loss: 0.428561\n",
      "epoch: 4 \t iteration 33 \t eval loss: 0.422157\n",
      "epoch: 4 \t iteration 34 \t eval loss: 0.466206\n",
      "epoch: 4 \t iteration 35 \t eval loss: 0.444241\n",
      "epoch: 4 \t iteration 36 \t eval loss: 0.358179\n",
      "epoch: 4 \t iteration 37 \t eval loss: 0.400264\n",
      "epoch: 4 \t iteration 38 \t eval loss: 0.388855\n",
      "epoch: 4 \t iteration 39 \t eval loss: 0.345893\n",
      "epoch:4 \t mean eval loss: 0.397709 \t mean eval acc: 0.856000\n",
      "epoch: 5 \t iteration 0 \t train loss: 0.401413\n",
      "epoch: 5 \t iteration 1 \t train loss: 0.353387\n",
      "epoch: 5 \t iteration 2 \t train loss: 0.371637\n",
      "epoch: 5 \t iteration 3 \t train loss: 0.382303\n",
      "epoch: 5 \t iteration 4 \t train loss: 0.388836\n",
      "epoch: 5 \t iteration 5 \t train loss: 0.372712\n",
      "epoch: 5 \t iteration 6 \t train loss: 0.490719\n",
      "epoch: 5 \t iteration 7 \t train loss: 0.419158\n",
      "epoch: 5 \t iteration 8 \t train loss: 0.382369\n",
      "epoch: 5 \t iteration 9 \t train loss: 0.443247\n",
      "epoch: 5 \t iteration 10 \t train loss: 0.430466\n",
      "epoch: 5 \t iteration 11 \t train loss: 0.433364\n",
      "epoch: 5 \t iteration 12 \t train loss: 0.460316\n",
      "epoch: 5 \t iteration 13 \t train loss: 0.379324\n",
      "epoch: 5 \t iteration 14 \t train loss: 0.403819\n",
      "epoch: 5 \t iteration 15 \t train loss: 0.445327\n",
      "epoch: 5 \t iteration 16 \t train loss: 0.481219\n",
      "epoch: 5 \t iteration 17 \t train loss: 0.451452\n",
      "epoch: 5 \t iteration 18 \t train loss: 0.505945\n",
      "epoch: 5 \t iteration 19 \t train loss: 0.434538\n",
      "epoch: 5 \t iteration 20 \t train loss: 0.390354\n",
      "epoch: 5 \t iteration 21 \t train loss: 0.374466\n",
      "epoch: 5 \t iteration 22 \t train loss: 0.408865\n",
      "epoch: 5 \t iteration 23 \t train loss: 0.451695\n",
      "epoch: 5 \t iteration 24 \t train loss: 0.431458\n",
      "epoch: 5 \t iteration 25 \t train loss: 0.367562\n",
      "epoch: 5 \t iteration 26 \t train loss: 0.380479\n",
      "epoch: 5 \t iteration 27 \t train loss: 0.447341\n",
      "epoch: 5 \t iteration 28 \t train loss: 0.434236\n",
      "epoch: 5 \t iteration 29 \t train loss: 0.381666\n",
      "epoch: 5 \t iteration 30 \t train loss: 0.484777\n",
      "epoch: 5 \t iteration 31 \t train loss: 0.413372\n",
      "epoch: 5 \t iteration 32 \t train loss: 0.377783\n",
      "epoch: 5 \t iteration 33 \t train loss: 0.381195\n",
      "epoch: 5 \t iteration 34 \t train loss: 0.375400\n",
      "epoch: 5 \t iteration 35 \t train loss: 0.337519\n",
      "epoch: 5 \t iteration 36 \t train loss: 0.425190\n",
      "epoch: 5 \t iteration 37 \t train loss: 0.402655\n",
      "epoch: 5 \t iteration 38 \t train loss: 0.370097\n",
      "epoch: 5 \t iteration 39 \t train loss: 0.402157\n",
      "epoch: 5 \t iteration 40 \t train loss: 0.434653\n",
      "epoch: 5 \t iteration 41 \t train loss: 0.369052\n",
      "epoch: 5 \t iteration 42 \t train loss: 0.392825\n",
      "epoch: 5 \t iteration 43 \t train loss: 0.452388\n",
      "epoch: 5 \t iteration 44 \t train loss: 0.358039\n",
      "epoch: 5 \t iteration 45 \t train loss: 0.400095\n",
      "epoch: 5 \t iteration 46 \t train loss: 0.403619\n",
      "epoch: 5 \t iteration 47 \t train loss: 0.339342\n",
      "epoch: 5 \t iteration 48 \t train loss: 0.424919\n",
      "epoch: 5 \t iteration 49 \t train loss: 0.406884\n",
      "epoch: 5 \t iteration 50 \t train loss: 0.536138\n",
      "epoch: 5 \t iteration 51 \t train loss: 0.369505\n",
      "epoch: 5 \t iteration 52 \t train loss: 0.420992\n",
      "epoch: 5 \t iteration 53 \t train loss: 0.385774\n",
      "epoch: 5 \t iteration 54 \t train loss: 0.396538\n",
      "epoch: 5 \t iteration 55 \t train loss: 0.414421\n",
      "epoch: 5 \t iteration 56 \t train loss: 0.404408\n",
      "epoch: 5 \t iteration 57 \t train loss: 0.394412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 \t iteration 58 \t train loss: 0.417929\n",
      "epoch: 5 \t iteration 59 \t train loss: 0.416539\n",
      "epoch: 5 \t iteration 60 \t train loss: 0.369860\n",
      "epoch: 5 \t iteration 61 \t train loss: 0.370659\n",
      "epoch: 5 \t iteration 62 \t train loss: 0.381924\n",
      "epoch: 5 \t iteration 63 \t train loss: 0.399883\n",
      "epoch: 5 \t iteration 64 \t train loss: 0.359308\n",
      "epoch: 5 \t iteration 65 \t train loss: 0.423780\n",
      "epoch: 5 \t iteration 66 \t train loss: 0.455521\n",
      "epoch: 5 \t iteration 67 \t train loss: 0.395608\n",
      "epoch: 5 \t iteration 68 \t train loss: 0.426683\n",
      "epoch: 5 \t iteration 69 \t train loss: 0.426182\n",
      "epoch: 5 \t iteration 70 \t train loss: 0.389279\n",
      "epoch: 5 \t iteration 71 \t train loss: 0.369695\n",
      "epoch: 5 \t iteration 72 \t train loss: 0.350649\n",
      "epoch: 5 \t iteration 73 \t train loss: 0.407644\n",
      "epoch: 5 \t iteration 74 \t train loss: 0.411566\n",
      "epoch: 5 \t iteration 75 \t train loss: 0.374326\n",
      "epoch: 5 \t iteration 76 \t train loss: 0.440329\n",
      "epoch: 5 \t iteration 77 \t train loss: 0.383323\n",
      "epoch: 5 \t iteration 78 \t train loss: 0.414083\n",
      "epoch: 5 \t iteration 79 \t train loss: 0.467222\n",
      "epoch: 5 \t iteration 80 \t train loss: 0.450308\n",
      "epoch: 5 \t iteration 81 \t train loss: 0.404911\n",
      "epoch: 5 \t iteration 82 \t train loss: 0.444608\n",
      "epoch: 5 \t iteration 83 \t train loss: 0.418032\n",
      "epoch: 5 \t iteration 84 \t train loss: 0.410267\n",
      "epoch: 5 \t iteration 85 \t train loss: 0.463140\n",
      "epoch: 5 \t iteration 86 \t train loss: 0.444105\n",
      "epoch: 5 \t iteration 87 \t train loss: 0.397633\n",
      "epoch: 5 \t iteration 88 \t train loss: 0.426881\n",
      "epoch: 5 \t iteration 89 \t train loss: 0.475370\n",
      "epoch: 5 \t iteration 90 \t train loss: 0.392536\n",
      "epoch: 5 \t iteration 91 \t train loss: 0.385190\n",
      "epoch: 5 \t iteration 92 \t train loss: 0.417685\n",
      "epoch: 5 \t iteration 93 \t train loss: 0.408396\n",
      "epoch: 5 \t iteration 94 \t train loss: 0.358590\n",
      "epoch: 5 \t iteration 95 \t train loss: 0.345557\n",
      "epoch: 5 \t iteration 96 \t train loss: 0.377371\n",
      "epoch: 5 \t iteration 97 \t train loss: 0.382774\n",
      "epoch: 5 \t iteration 98 \t train loss: 0.442740\n",
      "epoch: 5 \t iteration 99 \t train loss: 0.427058\n",
      "epoch: 5 \t iteration 100 \t train loss: 0.398630\n",
      "epoch: 5 \t iteration 101 \t train loss: 0.382794\n",
      "epoch: 5 \t iteration 102 \t train loss: 0.394355\n",
      "epoch: 5 \t iteration 103 \t train loss: 0.397246\n",
      "epoch: 5 \t iteration 104 \t train loss: 0.427098\n",
      "epoch: 5 \t iteration 105 \t train loss: 0.399511\n",
      "epoch: 5 \t iteration 106 \t train loss: 0.370820\n",
      "epoch: 5 \t iteration 107 \t train loss: 0.406206\n",
      "epoch: 5 \t iteration 108 \t train loss: 0.431991\n",
      "epoch: 5 \t iteration 109 \t train loss: 0.500204\n",
      "epoch: 5 \t iteration 110 \t train loss: 0.414491\n",
      "epoch: 5 \t iteration 111 \t train loss: 0.408842\n",
      "epoch: 5 \t iteration 112 \t train loss: 0.374039\n",
      "epoch: 5 \t iteration 113 \t train loss: 0.409670\n",
      "epoch: 5 \t iteration 114 \t train loss: 0.416409\n",
      "epoch: 5 \t iteration 115 \t train loss: 0.344524\n",
      "epoch: 5 \t iteration 116 \t train loss: 0.330711\n",
      "epoch: 5 \t iteration 117 \t train loss: 0.467836\n",
      "epoch: 5 \t iteration 118 \t train loss: 0.432076\n",
      "epoch: 5 \t iteration 119 \t train loss: 0.455500\n",
      "epoch: 5 \t iteration 120 \t train loss: 0.378287\n",
      "epoch: 5 \t iteration 121 \t train loss: 0.411713\n",
      "epoch: 5 \t iteration 122 \t train loss: 0.405999\n",
      "epoch: 5 \t iteration 123 \t train loss: 0.353466\n",
      "epoch: 5 \t iteration 124 \t train loss: 0.403980\n",
      "epoch: 5 \t iteration 125 \t train loss: 0.480442\n",
      "epoch: 5 \t iteration 126 \t train loss: 0.417166\n",
      "epoch: 5 \t iteration 127 \t train loss: 0.397356\n",
      "epoch: 5 \t iteration 128 \t train loss: 0.440523\n",
      "epoch: 5 \t iteration 129 \t train loss: 0.470308\n",
      "epoch: 5 \t iteration 130 \t train loss: 0.414241\n",
      "epoch: 5 \t iteration 131 \t train loss: 0.411168\n",
      "epoch: 5 \t iteration 132 \t train loss: 0.429467\n",
      "epoch: 5 \t iteration 133 \t train loss: 0.344700\n",
      "epoch: 5 \t iteration 134 \t train loss: 0.377375\n",
      "epoch: 5 \t iteration 135 \t train loss: 0.410372\n",
      "epoch: 5 \t iteration 136 \t train loss: 0.416296\n",
      "epoch: 5 \t iteration 137 \t train loss: 0.439570\n",
      "epoch: 5 \t iteration 138 \t train loss: 0.347752\n",
      "epoch: 5 \t iteration 139 \t train loss: 0.439107\n",
      "epoch: 5 \t iteration 140 \t train loss: 0.421629\n",
      "epoch: 5 \t iteration 141 \t train loss: 0.397086\n",
      "epoch: 5 \t iteration 142 \t train loss: 0.412170\n",
      "epoch: 5 \t iteration 143 \t train loss: 0.440543\n",
      "epoch: 5 \t iteration 144 \t train loss: 0.434114\n",
      "epoch: 5 \t iteration 145 \t train loss: 0.439408\n",
      "epoch: 5 \t iteration 146 \t train loss: 0.380671\n",
      "epoch: 5 \t iteration 147 \t train loss: 0.354471\n",
      "epoch: 5 \t iteration 148 \t train loss: 0.379822\n",
      "epoch: 5 \t iteration 149 \t train loss: 0.448895\n",
      "epoch: 5 \t iteration 150 \t train loss: 0.428133\n",
      "epoch: 5 \t iteration 151 \t train loss: 0.388332\n",
      "epoch: 5 \t iteration 152 \t train loss: 0.357411\n",
      "epoch: 5 \t iteration 153 \t train loss: 0.384542\n",
      "epoch: 5 \t iteration 154 \t train loss: 0.382421\n",
      "epoch: 5 \t iteration 155 \t train loss: 0.414134\n",
      "epoch: 5 \t iteration 156 \t train loss: 0.470570\n",
      "epoch: 5 \t iteration 157 \t train loss: 0.391090\n",
      "epoch: 5 \t iteration 158 \t train loss: 0.483876\n",
      "epoch: 5 \t iteration 159 \t train loss: 0.445677\n",
      "epoch: 5 \t iteration 160 \t train loss: 0.390918\n",
      "epoch: 5 \t iteration 161 \t train loss: 0.444497\n",
      "epoch: 5 \t iteration 162 \t train loss: 0.420474\n",
      "epoch: 5 \t iteration 163 \t train loss: 0.375363\n",
      "epoch: 5 \t iteration 164 \t train loss: 0.378734\n",
      "epoch: 5 \t iteration 165 \t train loss: 0.370246\n",
      "epoch: 5 \t iteration 166 \t train loss: 0.352005\n",
      "epoch: 5 \t iteration 167 \t train loss: 0.387348\n",
      "epoch: 5 \t iteration 168 \t train loss: 0.470889\n",
      "epoch: 5 \t iteration 169 \t train loss: 0.362614\n",
      "epoch: 5 \t iteration 170 \t train loss: 0.368219\n",
      "epoch: 5 \t iteration 171 \t train loss: 0.441038\n",
      "epoch: 5 \t iteration 172 \t train loss: 0.401271\n",
      "epoch: 5 \t iteration 173 \t train loss: 0.345774\n",
      "epoch: 5 \t iteration 174 \t train loss: 0.401443\n",
      "epoch: 5 \t iteration 175 \t train loss: 0.384175\n",
      "epoch: 5 \t iteration 176 \t train loss: 0.414460\n",
      "epoch: 5 \t iteration 177 \t train loss: 0.384574\n",
      "epoch: 5 \t iteration 178 \t train loss: 0.358129\n",
      "epoch: 5 \t iteration 179 \t train loss: 0.441519\n",
      "epoch: 5 \t iteration 180 \t train loss: 0.361461\n",
      "epoch: 5 \t iteration 181 \t train loss: 0.371925\n",
      "epoch: 5 \t iteration 182 \t train loss: 0.408629\n",
      "epoch: 5 \t iteration 183 \t train loss: 0.330219\n",
      "epoch: 5 \t iteration 184 \t train loss: 0.389154\n",
      "epoch: 5 \t iteration 185 \t train loss: 0.418804\n",
      "epoch: 5 \t iteration 186 \t train loss: 0.367848\n",
      "epoch: 5 \t iteration 187 \t train loss: 0.350339\n",
      "epoch: 5 \t iteration 188 \t train loss: 0.376761\n",
      "epoch: 5 \t iteration 189 \t train loss: 0.407058\n",
      "epoch: 5 \t iteration 190 \t train loss: 0.443321\n",
      "epoch: 5 \t iteration 191 \t train loss: 0.353125\n",
      "epoch: 5 \t iteration 192 \t train loss: 0.314743\n",
      "epoch: 5 \t iteration 193 \t train loss: 0.335537\n",
      "epoch: 5 \t iteration 194 \t train loss: 0.349341\n",
      "epoch: 5 \t iteration 195 \t train loss: 0.286493\n",
      "epoch: 5 \t iteration 196 \t train loss: 0.262578\n",
      "epoch: 5 \t iteration 197 \t train loss: 0.438120\n",
      "epoch: 5 \t iteration 198 \t train loss: 0.386245\n",
      "epoch: 5 \t iteration 199 \t train loss: 0.339997\n",
      "epoch:5 \t mean train loss: 0.403458 \t mean train acc: 0.853480\n",
      "epoch: 5 \t iteration 0 \t eval loss: 0.378117\n",
      "epoch: 5 \t iteration 1 \t eval loss: 0.352352\n",
      "epoch: 5 \t iteration 2 \t eval loss: 0.443169\n",
      "epoch: 5 \t iteration 3 \t eval loss: 0.400426\n",
      "epoch: 5 \t iteration 4 \t eval loss: 0.455947\n",
      "epoch: 5 \t iteration 5 \t eval loss: 0.428822\n",
      "epoch: 5 \t iteration 6 \t eval loss: 0.367869\n",
      "epoch: 5 \t iteration 7 \t eval loss: 0.376473\n",
      "epoch: 5 \t iteration 8 \t eval loss: 0.362749\n",
      "epoch: 5 \t iteration 9 \t eval loss: 0.373716\n",
      "epoch: 5 \t iteration 10 \t eval loss: 0.358175\n",
      "epoch: 5 \t iteration 11 \t eval loss: 0.383609\n",
      "epoch: 5 \t iteration 12 \t eval loss: 0.395413\n",
      "epoch: 5 \t iteration 13 \t eval loss: 0.372538\n",
      "epoch: 5 \t iteration 14 \t eval loss: 0.413805\n",
      "epoch: 5 \t iteration 15 \t eval loss: 0.369469\n",
      "epoch: 5 \t iteration 16 \t eval loss: 0.410811\n",
      "epoch: 5 \t iteration 17 \t eval loss: 0.396880\n",
      "epoch: 5 \t iteration 18 \t eval loss: 0.374888\n",
      "epoch: 5 \t iteration 19 \t eval loss: 0.396610\n",
      "epoch: 5 \t iteration 20 \t eval loss: 0.399792\n",
      "epoch: 5 \t iteration 21 \t eval loss: 0.362104\n",
      "epoch: 5 \t iteration 22 \t eval loss: 0.395381\n",
      "epoch: 5 \t iteration 23 \t eval loss: 0.370493\n",
      "epoch: 5 \t iteration 24 \t eval loss: 0.363842\n",
      "epoch: 5 \t iteration 25 \t eval loss: 0.399491\n",
      "epoch: 5 \t iteration 26 \t eval loss: 0.310037\n",
      "epoch: 5 \t iteration 27 \t eval loss: 0.461693\n",
      "epoch: 5 \t iteration 28 \t eval loss: 0.431297\n",
      "epoch: 5 \t iteration 29 \t eval loss: 0.430923\n",
      "epoch: 5 \t iteration 30 \t eval loss: 0.401414\n",
      "epoch: 5 \t iteration 31 \t eval loss: 0.438706\n",
      "epoch: 5 \t iteration 32 \t eval loss: 0.426480\n",
      "epoch: 5 \t iteration 33 \t eval loss: 0.419873\n",
      "epoch: 5 \t iteration 34 \t eval loss: 0.464515\n",
      "epoch: 5 \t iteration 35 \t eval loss: 0.441539\n",
      "epoch: 5 \t iteration 36 \t eval loss: 0.355983\n",
      "epoch: 5 \t iteration 37 \t eval loss: 0.397932\n",
      "epoch: 5 \t iteration 38 \t eval loss: 0.386656\n",
      "epoch: 5 \t iteration 39 \t eval loss: 0.343077\n",
      "epoch:5 \t mean eval loss: 0.395327 \t mean eval acc: 0.854900\n",
      "epoch: 6 \t iteration 0 \t train loss: 0.399394\n",
      "epoch: 6 \t iteration 1 \t train loss: 0.351140\n",
      "epoch: 6 \t iteration 2 \t train loss: 0.369471\n",
      "epoch: 6 \t iteration 3 \t train loss: 0.379446\n",
      "epoch: 6 \t iteration 4 \t train loss: 0.386132\n",
      "epoch: 6 \t iteration 5 \t train loss: 0.371162\n",
      "epoch: 6 \t iteration 6 \t train loss: 0.488567\n",
      "epoch: 6 \t iteration 7 \t train loss: 0.417059\n",
      "epoch: 6 \t iteration 8 \t train loss: 0.380597\n",
      "epoch: 6 \t iteration 9 \t train loss: 0.440648\n",
      "epoch: 6 \t iteration 10 \t train loss: 0.427781\n",
      "epoch: 6 \t iteration 11 \t train loss: 0.430699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 \t iteration 12 \t train loss: 0.458004\n",
      "epoch: 6 \t iteration 13 \t train loss: 0.376394\n",
      "epoch: 6 \t iteration 14 \t train loss: 0.401908\n",
      "epoch: 6 \t iteration 15 \t train loss: 0.442385\n",
      "epoch: 6 \t iteration 16 \t train loss: 0.478761\n",
      "epoch: 6 \t iteration 17 \t train loss: 0.448573\n",
      "epoch: 6 \t iteration 18 \t train loss: 0.503154\n",
      "epoch: 6 \t iteration 19 \t train loss: 0.432508\n",
      "epoch: 6 \t iteration 20 \t train loss: 0.388294\n",
      "epoch: 6 \t iteration 21 \t train loss: 0.372119\n",
      "epoch: 6 \t iteration 22 \t train loss: 0.406484\n",
      "epoch: 6 \t iteration 23 \t train loss: 0.448795\n",
      "epoch: 6 \t iteration 24 \t train loss: 0.428046\n",
      "epoch: 6 \t iteration 25 \t train loss: 0.364730\n",
      "epoch: 6 \t iteration 26 \t train loss: 0.379201\n",
      "epoch: 6 \t iteration 27 \t train loss: 0.444863\n",
      "epoch: 6 \t iteration 28 \t train loss: 0.431233\n",
      "epoch: 6 \t iteration 29 \t train loss: 0.379434\n",
      "epoch: 6 \t iteration 30 \t train loss: 0.482278\n",
      "epoch: 6 \t iteration 31 \t train loss: 0.411173\n",
      "epoch: 6 \t iteration 32 \t train loss: 0.375518\n",
      "epoch: 6 \t iteration 33 \t train loss: 0.378913\n",
      "epoch: 6 \t iteration 34 \t train loss: 0.372435\n",
      "epoch: 6 \t iteration 35 \t train loss: 0.334768\n",
      "epoch: 6 \t iteration 36 \t train loss: 0.421955\n",
      "epoch: 6 \t iteration 37 \t train loss: 0.400372\n",
      "epoch: 6 \t iteration 38 \t train loss: 0.368008\n",
      "epoch: 6 \t iteration 39 \t train loss: 0.399549\n",
      "epoch: 6 \t iteration 40 \t train loss: 0.432429\n",
      "epoch: 6 \t iteration 41 \t train loss: 0.366089\n",
      "epoch: 6 \t iteration 42 \t train loss: 0.390701\n",
      "epoch: 6 \t iteration 43 \t train loss: 0.449641\n",
      "epoch: 6 \t iteration 44 \t train loss: 0.355682\n",
      "epoch: 6 \t iteration 45 \t train loss: 0.397500\n",
      "epoch: 6 \t iteration 46 \t train loss: 0.401214\n",
      "epoch: 6 \t iteration 47 \t train loss: 0.338087\n",
      "epoch: 6 \t iteration 48 \t train loss: 0.422019\n",
      "epoch: 6 \t iteration 49 \t train loss: 0.404991\n",
      "epoch: 6 \t iteration 50 \t train loss: 0.534276\n",
      "epoch: 6 \t iteration 51 \t train loss: 0.367198\n",
      "epoch: 6 \t iteration 52 \t train loss: 0.418761\n",
      "epoch: 6 \t iteration 53 \t train loss: 0.382927\n",
      "epoch: 6 \t iteration 54 \t train loss: 0.393440\n",
      "epoch: 6 \t iteration 55 \t train loss: 0.412454\n",
      "epoch: 6 \t iteration 56 \t train loss: 0.402227\n",
      "epoch: 6 \t iteration 57 \t train loss: 0.391739\n",
      "epoch: 6 \t iteration 58 \t train loss: 0.415549\n",
      "epoch: 6 \t iteration 59 \t train loss: 0.413121\n",
      "epoch: 6 \t iteration 60 \t train loss: 0.367295\n",
      "epoch: 6 \t iteration 61 \t train loss: 0.368702\n",
      "epoch: 6 \t iteration 62 \t train loss: 0.380314\n",
      "epoch: 6 \t iteration 63 \t train loss: 0.398136\n",
      "epoch: 6 \t iteration 64 \t train loss: 0.356482\n",
      "epoch: 6 \t iteration 65 \t train loss: 0.420599\n",
      "epoch: 6 \t iteration 66 \t train loss: 0.453533\n",
      "epoch: 6 \t iteration 67 \t train loss: 0.393046\n",
      "epoch: 6 \t iteration 68 \t train loss: 0.424374\n",
      "epoch: 6 \t iteration 69 \t train loss: 0.423628\n",
      "epoch: 6 \t iteration 70 \t train loss: 0.386669\n",
      "epoch: 6 \t iteration 71 \t train loss: 0.367836\n",
      "epoch: 6 \t iteration 72 \t train loss: 0.348866\n",
      "epoch: 6 \t iteration 73 \t train loss: 0.405091\n",
      "epoch: 6 \t iteration 74 \t train loss: 0.409265\n",
      "epoch: 6 \t iteration 75 \t train loss: 0.372459\n",
      "epoch: 6 \t iteration 76 \t train loss: 0.437853\n",
      "epoch: 6 \t iteration 77 \t train loss: 0.381409\n",
      "epoch: 6 \t iteration 78 \t train loss: 0.411724\n",
      "epoch: 6 \t iteration 79 \t train loss: 0.464917\n",
      "epoch: 6 \t iteration 80 \t train loss: 0.447126\n",
      "epoch: 6 \t iteration 81 \t train loss: 0.402809\n",
      "epoch: 6 \t iteration 82 \t train loss: 0.442658\n",
      "epoch: 6 \t iteration 83 \t train loss: 0.415988\n",
      "epoch: 6 \t iteration 84 \t train loss: 0.408436\n",
      "epoch: 6 \t iteration 85 \t train loss: 0.459900\n",
      "epoch: 6 \t iteration 86 \t train loss: 0.441396\n",
      "epoch: 6 \t iteration 87 \t train loss: 0.395216\n",
      "epoch: 6 \t iteration 88 \t train loss: 0.423600\n",
      "epoch: 6 \t iteration 89 \t train loss: 0.472571\n",
      "epoch: 6 \t iteration 90 \t train loss: 0.389605\n",
      "epoch: 6 \t iteration 91 \t train loss: 0.382917\n",
      "epoch: 6 \t iteration 92 \t train loss: 0.413391\n",
      "epoch: 6 \t iteration 93 \t train loss: 0.406505\n",
      "epoch: 6 \t iteration 94 \t train loss: 0.356166\n",
      "epoch: 6 \t iteration 95 \t train loss: 0.343881\n",
      "epoch: 6 \t iteration 96 \t train loss: 0.374890\n",
      "epoch: 6 \t iteration 97 \t train loss: 0.380600\n",
      "epoch: 6 \t iteration 98 \t train loss: 0.440047\n",
      "epoch: 6 \t iteration 99 \t train loss: 0.423958\n",
      "epoch: 6 \t iteration 100 \t train loss: 0.396426\n",
      "epoch: 6 \t iteration 101 \t train loss: 0.379998\n",
      "epoch: 6 \t iteration 102 \t train loss: 0.392548\n",
      "epoch: 6 \t iteration 103 \t train loss: 0.394553\n",
      "epoch: 6 \t iteration 104 \t train loss: 0.424632\n",
      "epoch: 6 \t iteration 105 \t train loss: 0.396198\n",
      "epoch: 6 \t iteration 106 \t train loss: 0.369518\n",
      "epoch: 6 \t iteration 107 \t train loss: 0.404890\n",
      "epoch: 6 \t iteration 108 \t train loss: 0.430133\n",
      "epoch: 6 \t iteration 109 \t train loss: 0.499857\n",
      "epoch: 6 \t iteration 110 \t train loss: 0.412113\n",
      "epoch: 6 \t iteration 111 \t train loss: 0.406896\n",
      "epoch: 6 \t iteration 112 \t train loss: 0.371428\n",
      "epoch: 6 \t iteration 113 \t train loss: 0.407228\n",
      "epoch: 6 \t iteration 114 \t train loss: 0.413883\n",
      "epoch: 6 \t iteration 115 \t train loss: 0.342290\n",
      "epoch: 6 \t iteration 116 \t train loss: 0.328448\n",
      "epoch: 6 \t iteration 117 \t train loss: 0.465033\n",
      "epoch: 6 \t iteration 118 \t train loss: 0.429412\n",
      "epoch: 6 \t iteration 119 \t train loss: 0.453306\n",
      "epoch: 6 \t iteration 120 \t train loss: 0.375994\n",
      "epoch: 6 \t iteration 121 \t train loss: 0.409923\n",
      "epoch: 6 \t iteration 122 \t train loss: 0.403850\n",
      "epoch: 6 \t iteration 123 \t train loss: 0.350666\n",
      "epoch: 6 \t iteration 124 \t train loss: 0.401557\n",
      "epoch: 6 \t iteration 125 \t train loss: 0.477818\n",
      "epoch: 6 \t iteration 126 \t train loss: 0.414505\n",
      "epoch: 6 \t iteration 127 \t train loss: 0.394661\n",
      "epoch: 6 \t iteration 128 \t train loss: 0.438886\n",
      "epoch: 6 \t iteration 129 \t train loss: 0.468209\n",
      "epoch: 6 \t iteration 130 \t train loss: 0.412519\n",
      "epoch: 6 \t iteration 131 \t train loss: 0.409014\n",
      "epoch: 6 \t iteration 132 \t train loss: 0.427908\n",
      "epoch: 6 \t iteration 133 \t train loss: 0.343110\n",
      "epoch: 6 \t iteration 134 \t train loss: 0.375741\n",
      "epoch: 6 \t iteration 135 \t train loss: 0.408658\n",
      "epoch: 6 \t iteration 136 \t train loss: 0.414492\n",
      "epoch: 6 \t iteration 137 \t train loss: 0.437409\n",
      "epoch: 6 \t iteration 138 \t train loss: 0.345663\n",
      "epoch: 6 \t iteration 139 \t train loss: 0.437680\n",
      "epoch: 6 \t iteration 140 \t train loss: 0.419364\n",
      "epoch: 6 \t iteration 141 \t train loss: 0.394991\n",
      "epoch: 6 \t iteration 142 \t train loss: 0.410455\n",
      "epoch: 6 \t iteration 143 \t train loss: 0.438508\n",
      "epoch: 6 \t iteration 144 \t train loss: 0.432088\n",
      "epoch: 6 \t iteration 145 \t train loss: 0.437383\n",
      "epoch: 6 \t iteration 146 \t train loss: 0.378586\n",
      "epoch: 6 \t iteration 147 \t train loss: 0.352336\n",
      "epoch: 6 \t iteration 148 \t train loss: 0.376953\n",
      "epoch: 6 \t iteration 149 \t train loss: 0.446616\n",
      "epoch: 6 \t iteration 150 \t train loss: 0.425845\n",
      "epoch: 6 \t iteration 151 \t train loss: 0.386133\n",
      "epoch: 6 \t iteration 152 \t train loss: 0.355296\n",
      "epoch: 6 \t iteration 153 \t train loss: 0.382781\n",
      "epoch: 6 \t iteration 154 \t train loss: 0.380287\n",
      "epoch: 6 \t iteration 155 \t train loss: 0.411578\n",
      "epoch: 6 \t iteration 156 \t train loss: 0.467648\n",
      "epoch: 6 \t iteration 157 \t train loss: 0.389367\n",
      "epoch: 6 \t iteration 158 \t train loss: 0.481341\n",
      "epoch: 6 \t iteration 159 \t train loss: 0.443870\n",
      "epoch: 6 \t iteration 160 \t train loss: 0.388257\n",
      "epoch: 6 \t iteration 161 \t train loss: 0.443561\n",
      "epoch: 6 \t iteration 162 \t train loss: 0.417925\n",
      "epoch: 6 \t iteration 163 \t train loss: 0.373705\n",
      "epoch: 6 \t iteration 164 \t train loss: 0.376823\n",
      "epoch: 6 \t iteration 165 \t train loss: 0.368319\n",
      "epoch: 6 \t iteration 166 \t train loss: 0.349591\n",
      "epoch: 6 \t iteration 167 \t train loss: 0.385932\n",
      "epoch: 6 \t iteration 168 \t train loss: 0.468345\n",
      "epoch: 6 \t iteration 169 \t train loss: 0.360661\n",
      "epoch: 6 \t iteration 170 \t train loss: 0.366148\n",
      "epoch: 6 \t iteration 171 \t train loss: 0.438733\n",
      "epoch: 6 \t iteration 172 \t train loss: 0.399559\n",
      "epoch: 6 \t iteration 173 \t train loss: 0.343209\n",
      "epoch: 6 \t iteration 174 \t train loss: 0.399834\n",
      "epoch: 6 \t iteration 175 \t train loss: 0.381582\n",
      "epoch: 6 \t iteration 176 \t train loss: 0.412309\n",
      "epoch: 6 \t iteration 177 \t train loss: 0.382394\n",
      "epoch: 6 \t iteration 178 \t train loss: 0.356022\n",
      "epoch: 6 \t iteration 179 \t train loss: 0.439069\n",
      "epoch: 6 \t iteration 180 \t train loss: 0.359703\n",
      "epoch: 6 \t iteration 181 \t train loss: 0.369573\n",
      "epoch: 6 \t iteration 182 \t train loss: 0.406788\n",
      "epoch: 6 \t iteration 183 \t train loss: 0.328281\n",
      "epoch: 6 \t iteration 184 \t train loss: 0.387672\n",
      "epoch: 6 \t iteration 185 \t train loss: 0.416601\n",
      "epoch: 6 \t iteration 186 \t train loss: 0.365656\n",
      "epoch: 6 \t iteration 187 \t train loss: 0.348380\n",
      "epoch: 6 \t iteration 188 \t train loss: 0.375137\n",
      "epoch: 6 \t iteration 189 \t train loss: 0.405176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 \t iteration 190 \t train loss: 0.442338\n",
      "epoch: 6 \t iteration 191 \t train loss: 0.351539\n",
      "epoch: 6 \t iteration 192 \t train loss: 0.312824\n",
      "epoch: 6 \t iteration 193 \t train loss: 0.333323\n",
      "epoch: 6 \t iteration 194 \t train loss: 0.347524\n",
      "epoch: 6 \t iteration 195 \t train loss: 0.285190\n",
      "epoch: 6 \t iteration 196 \t train loss: 0.260842\n",
      "epoch: 6 \t iteration 197 \t train loss: 0.437569\n",
      "epoch: 6 \t iteration 198 \t train loss: 0.384731\n",
      "epoch: 6 \t iteration 199 \t train loss: 0.337634\n",
      "epoch:6 \t mean train loss: 0.401214 \t mean train acc: 0.853620\n",
      "epoch: 6 \t iteration 0 \t eval loss: 0.376183\n",
      "epoch: 6 \t iteration 1 \t eval loss: 0.350727\n",
      "epoch: 6 \t iteration 2 \t eval loss: 0.441239\n",
      "epoch: 6 \t iteration 3 \t eval loss: 0.398255\n",
      "epoch: 6 \t iteration 4 \t eval loss: 0.454553\n",
      "epoch: 6 \t iteration 5 \t eval loss: 0.428484\n",
      "epoch: 6 \t iteration 6 \t eval loss: 0.366063\n",
      "epoch: 6 \t iteration 7 \t eval loss: 0.374520\n",
      "epoch: 6 \t iteration 8 \t eval loss: 0.361540\n",
      "epoch: 6 \t iteration 9 \t eval loss: 0.371768\n",
      "epoch: 6 \t iteration 10 \t eval loss: 0.356117\n",
      "epoch: 6 \t iteration 11 \t eval loss: 0.381923\n",
      "epoch: 6 \t iteration 12 \t eval loss: 0.393344\n",
      "epoch: 6 \t iteration 13 \t eval loss: 0.369897\n",
      "epoch: 6 \t iteration 14 \t eval loss: 0.411575\n",
      "epoch: 6 \t iteration 15 \t eval loss: 0.367279\n",
      "epoch: 6 \t iteration 16 \t eval loss: 0.409441\n",
      "epoch: 6 \t iteration 17 \t eval loss: 0.394820\n",
      "epoch: 6 \t iteration 18 \t eval loss: 0.372665\n",
      "epoch: 6 \t iteration 19 \t eval loss: 0.394939\n",
      "epoch: 6 \t iteration 20 \t eval loss: 0.398334\n",
      "epoch: 6 \t iteration 21 \t eval loss: 0.360457\n",
      "epoch: 6 \t iteration 22 \t eval loss: 0.393267\n",
      "epoch: 6 \t iteration 23 \t eval loss: 0.368262\n",
      "epoch: 6 \t iteration 24 \t eval loss: 0.362292\n",
      "epoch: 6 \t iteration 25 \t eval loss: 0.397768\n",
      "epoch: 6 \t iteration 26 \t eval loss: 0.308420\n",
      "epoch: 6 \t iteration 27 \t eval loss: 0.461257\n",
      "epoch: 6 \t iteration 28 \t eval loss: 0.429300\n",
      "epoch: 6 \t iteration 29 \t eval loss: 0.428642\n",
      "epoch: 6 \t iteration 30 \t eval loss: 0.399169\n",
      "epoch: 6 \t iteration 31 \t eval loss: 0.436668\n",
      "epoch: 6 \t iteration 32 \t eval loss: 0.424900\n",
      "epoch: 6 \t iteration 33 \t eval loss: 0.418228\n",
      "epoch: 6 \t iteration 34 \t eval loss: 0.463319\n",
      "epoch: 6 \t iteration 35 \t eval loss: 0.439455\n",
      "epoch: 6 \t iteration 36 \t eval loss: 0.354327\n",
      "epoch: 6 \t iteration 37 \t eval loss: 0.396181\n",
      "epoch: 6 \t iteration 38 \t eval loss: 0.385019\n",
      "epoch: 6 \t iteration 39 \t eval loss: 0.340921\n",
      "epoch:6 \t mean eval loss: 0.393538 \t mean eval acc: 0.855000\n",
      "epoch: 7 \t iteration 0 \t train loss: 0.397889\n",
      "epoch: 7 \t iteration 1 \t train loss: 0.349468\n",
      "epoch: 7 \t iteration 2 \t train loss: 0.367842\n",
      "epoch: 7 \t iteration 3 \t train loss: 0.377257\n",
      "epoch: 7 \t iteration 4 \t train loss: 0.384110\n",
      "epoch: 7 \t iteration 5 \t train loss: 0.369999\n",
      "epoch: 7 \t iteration 6 \t train loss: 0.486951\n",
      "epoch: 7 \t iteration 7 \t train loss: 0.415522\n",
      "epoch: 7 \t iteration 8 \t train loss: 0.379326\n",
      "epoch: 7 \t iteration 9 \t train loss: 0.438670\n",
      "epoch: 7 \t iteration 10 \t train loss: 0.425747\n",
      "epoch: 7 \t iteration 11 \t train loss: 0.428658\n",
      "epoch: 7 \t iteration 12 \t train loss: 0.456256\n",
      "epoch: 7 \t iteration 13 \t train loss: 0.374155\n",
      "epoch: 7 \t iteration 14 \t train loss: 0.400438\n",
      "epoch: 7 \t iteration 15 \t train loss: 0.440013\n",
      "epoch: 7 \t iteration 16 \t train loss: 0.476869\n",
      "epoch: 7 \t iteration 17 \t train loss: 0.446369\n",
      "epoch: 7 \t iteration 18 \t train loss: 0.501026\n",
      "epoch: 7 \t iteration 19 \t train loss: 0.430983\n",
      "epoch: 7 \t iteration 20 \t train loss: 0.386676\n",
      "epoch: 7 \t iteration 21 \t train loss: 0.370300\n",
      "epoch: 7 \t iteration 22 \t train loss: 0.404673\n",
      "epoch: 7 \t iteration 23 \t train loss: 0.446465\n",
      "epoch: 7 \t iteration 24 \t train loss: 0.425350\n",
      "epoch: 7 \t iteration 25 \t train loss: 0.362563\n",
      "epoch: 7 \t iteration 26 \t train loss: 0.378241\n",
      "epoch: 7 \t iteration 27 \t train loss: 0.443019\n",
      "epoch: 7 \t iteration 28 \t train loss: 0.428847\n",
      "epoch: 7 \t iteration 29 \t train loss: 0.377711\n",
      "epoch: 7 \t iteration 30 \t train loss: 0.480394\n",
      "epoch: 7 \t iteration 31 \t train loss: 0.409466\n",
      "epoch: 7 \t iteration 32 \t train loss: 0.373772\n",
      "epoch: 7 \t iteration 33 \t train loss: 0.377145\n",
      "epoch: 7 \t iteration 34 \t train loss: 0.370137\n",
      "epoch: 7 \t iteration 35 \t train loss: 0.332629\n",
      "epoch: 7 \t iteration 36 \t train loss: 0.419388\n",
      "epoch: 7 \t iteration 37 \t train loss: 0.398591\n",
      "epoch: 7 \t iteration 38 \t train loss: 0.366374\n",
      "epoch: 7 \t iteration 39 \t train loss: 0.397479\n",
      "epoch: 7 \t iteration 40 \t train loss: 0.430692\n",
      "epoch: 7 \t iteration 41 \t train loss: 0.363810\n",
      "epoch: 7 \t iteration 42 \t train loss: 0.389038\n",
      "epoch: 7 \t iteration 43 \t train loss: 0.447436\n",
      "epoch: 7 \t iteration 44 \t train loss: 0.353857\n",
      "epoch: 7 \t iteration 45 \t train loss: 0.395546\n",
      "epoch: 7 \t iteration 46 \t train loss: 0.399272\n",
      "epoch: 7 \t iteration 47 \t train loss: 0.337136\n",
      "epoch: 7 \t iteration 48 \t train loss: 0.419757\n",
      "epoch: 7 \t iteration 49 \t train loss: 0.403645\n",
      "epoch: 7 \t iteration 50 \t train loss: 0.532724\n",
      "epoch: 7 \t iteration 51 \t train loss: 0.365454\n",
      "epoch: 7 \t iteration 52 \t train loss: 0.417031\n",
      "epoch: 7 \t iteration 53 \t train loss: 0.380640\n",
      "epoch: 7 \t iteration 54 \t train loss: 0.391020\n",
      "epoch: 7 \t iteration 55 \t train loss: 0.411054\n",
      "epoch: 7 \t iteration 56 \t train loss: 0.400536\n",
      "epoch: 7 \t iteration 57 \t train loss: 0.389686\n",
      "epoch: 7 \t iteration 58 \t train loss: 0.413726\n",
      "epoch: 7 \t iteration 59 \t train loss: 0.410464\n",
      "epoch: 7 \t iteration 60 \t train loss: 0.365240\n",
      "epoch: 7 \t iteration 61 \t train loss: 0.367216\n",
      "epoch: 7 \t iteration 62 \t train loss: 0.379075\n",
      "epoch: 7 \t iteration 63 \t train loss: 0.396869\n",
      "epoch: 7 \t iteration 64 \t train loss: 0.354293\n",
      "epoch: 7 \t iteration 65 \t train loss: 0.418053\n",
      "epoch: 7 \t iteration 66 \t train loss: 0.451986\n",
      "epoch: 7 \t iteration 67 \t train loss: 0.391028\n",
      "epoch: 7 \t iteration 68 \t train loss: 0.422573\n",
      "epoch: 7 \t iteration 69 \t train loss: 0.421677\n",
      "epoch: 7 \t iteration 70 \t train loss: 0.384594\n",
      "epoch: 7 \t iteration 71 \t train loss: 0.366395\n",
      "epoch: 7 \t iteration 72 \t train loss: 0.347538\n",
      "epoch: 7 \t iteration 73 \t train loss: 0.403101\n",
      "epoch: 7 \t iteration 74 \t train loss: 0.407532\n",
      "epoch: 7 \t iteration 75 \t train loss: 0.371135\n",
      "epoch: 7 \t iteration 76 \t train loss: 0.435921\n",
      "epoch: 7 \t iteration 77 \t train loss: 0.380009\n",
      "epoch: 7 \t iteration 78 \t train loss: 0.409837\n",
      "epoch: 7 \t iteration 79 \t train loss: 0.463158\n",
      "epoch: 7 \t iteration 80 \t train loss: 0.444606\n",
      "epoch: 7 \t iteration 81 \t train loss: 0.401151\n",
      "epoch: 7 \t iteration 82 \t train loss: 0.441220\n",
      "epoch: 7 \t iteration 83 \t train loss: 0.414411\n",
      "epoch: 7 \t iteration 84 \t train loss: 0.407026\n",
      "epoch: 7 \t iteration 85 \t train loss: 0.457302\n",
      "epoch: 7 \t iteration 86 \t train loss: 0.439271\n",
      "epoch: 7 \t iteration 87 \t train loss: 0.393335\n",
      "epoch: 7 \t iteration 88 \t train loss: 0.420961\n",
      "epoch: 7 \t iteration 89 \t train loss: 0.470371\n",
      "epoch: 7 \t iteration 90 \t train loss: 0.387309\n",
      "epoch: 7 \t iteration 91 \t train loss: 0.381139\n",
      "epoch: 7 \t iteration 92 \t train loss: 0.409907\n",
      "epoch: 7 \t iteration 93 \t train loss: 0.405027\n",
      "epoch: 7 \t iteration 94 \t train loss: 0.354273\n",
      "epoch: 7 \t iteration 95 \t train loss: 0.342627\n",
      "epoch: 7 \t iteration 96 \t train loss: 0.372968\n",
      "epoch: 7 \t iteration 97 \t train loss: 0.378895\n",
      "epoch: 7 \t iteration 98 \t train loss: 0.437889\n",
      "epoch: 7 \t iteration 99 \t train loss: 0.421523\n",
      "epoch: 7 \t iteration 100 \t train loss: 0.394747\n",
      "epoch: 7 \t iteration 101 \t train loss: 0.377818\n",
      "epoch: 7 \t iteration 102 \t train loss: 0.391163\n",
      "epoch: 7 \t iteration 103 \t train loss: 0.392391\n",
      "epoch: 7 \t iteration 104 \t train loss: 0.422706\n",
      "epoch: 7 \t iteration 105 \t train loss: 0.393568\n",
      "epoch: 7 \t iteration 106 \t train loss: 0.368542\n",
      "epoch: 7 \t iteration 107 \t train loss: 0.403863\n",
      "epoch: 7 \t iteration 108 \t train loss: 0.428665\n",
      "epoch: 7 \t iteration 109 \t train loss: 0.499649\n",
      "epoch: 7 \t iteration 110 \t train loss: 0.410172\n",
      "epoch: 7 \t iteration 111 \t train loss: 0.405398\n",
      "epoch: 7 \t iteration 112 \t train loss: 0.369311\n",
      "epoch: 7 \t iteration 113 \t train loss: 0.405282\n",
      "epoch: 7 \t iteration 114 \t train loss: 0.411858\n",
      "epoch: 7 \t iteration 115 \t train loss: 0.340548\n",
      "epoch: 7 \t iteration 116 \t train loss: 0.326674\n",
      "epoch: 7 \t iteration 117 \t train loss: 0.462802\n",
      "epoch: 7 \t iteration 118 \t train loss: 0.427286\n",
      "epoch: 7 \t iteration 119 \t train loss: 0.451554\n",
      "epoch: 7 \t iteration 120 \t train loss: 0.374158\n",
      "epoch: 7 \t iteration 121 \t train loss: 0.408553\n",
      "epoch: 7 \t iteration 122 \t train loss: 0.402197\n",
      "epoch: 7 \t iteration 123 \t train loss: 0.348398\n",
      "epoch: 7 \t iteration 124 \t train loss: 0.399650\n",
      "epoch: 7 \t iteration 125 \t train loss: 0.475732\n",
      "epoch: 7 \t iteration 126 \t train loss: 0.412491\n",
      "epoch: 7 \t iteration 127 \t train loss: 0.392582\n",
      "epoch: 7 \t iteration 128 \t train loss: 0.437639\n",
      "epoch: 7 \t iteration 129 \t train loss: 0.466516\n",
      "epoch: 7 \t iteration 130 \t train loss: 0.411184\n",
      "epoch: 7 \t iteration 131 \t train loss: 0.407301\n",
      "epoch: 7 \t iteration 132 \t train loss: 0.426648\n",
      "epoch: 7 \t iteration 133 \t train loss: 0.341913\n",
      "epoch: 7 \t iteration 134 \t train loss: 0.374547\n",
      "epoch: 7 \t iteration 135 \t train loss: 0.407300\n",
      "epoch: 7 \t iteration 136 \t train loss: 0.413156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 \t iteration 137 \t train loss: 0.435692\n",
      "epoch: 7 \t iteration 138 \t train loss: 0.344017\n",
      "epoch: 7 \t iteration 139 \t train loss: 0.436626\n",
      "epoch: 7 \t iteration 140 \t train loss: 0.417558\n",
      "epoch: 7 \t iteration 141 \t train loss: 0.393327\n",
      "epoch: 7 \t iteration 142 \t train loss: 0.409192\n",
      "epoch: 7 \t iteration 143 \t train loss: 0.436904\n",
      "epoch: 7 \t iteration 144 \t train loss: 0.430481\n",
      "epoch: 7 \t iteration 145 \t train loss: 0.435776\n",
      "epoch: 7 \t iteration 146 \t train loss: 0.376962\n",
      "epoch: 7 \t iteration 147 \t train loss: 0.350616\n",
      "epoch: 7 \t iteration 148 \t train loss: 0.374674\n",
      "epoch: 7 \t iteration 149 \t train loss: 0.444848\n",
      "epoch: 7 \t iteration 150 \t train loss: 0.424080\n",
      "epoch: 7 \t iteration 151 \t train loss: 0.384359\n",
      "epoch: 7 \t iteration 152 \t train loss: 0.353629\n",
      "epoch: 7 \t iteration 153 \t train loss: 0.381392\n",
      "epoch: 7 \t iteration 154 \t train loss: 0.378588\n",
      "epoch: 7 \t iteration 155 \t train loss: 0.409552\n",
      "epoch: 7 \t iteration 156 \t train loss: 0.465310\n",
      "epoch: 7 \t iteration 157 \t train loss: 0.387966\n",
      "epoch: 7 \t iteration 158 \t train loss: 0.479347\n",
      "epoch: 7 \t iteration 159 \t train loss: 0.442388\n",
      "epoch: 7 \t iteration 160 \t train loss: 0.386049\n",
      "epoch: 7 \t iteration 161 \t train loss: 0.442854\n",
      "epoch: 7 \t iteration 162 \t train loss: 0.415960\n",
      "epoch: 7 \t iteration 163 \t train loss: 0.372498\n",
      "epoch: 7 \t iteration 164 \t train loss: 0.375375\n",
      "epoch: 7 \t iteration 165 \t train loss: 0.366839\n",
      "epoch: 7 \t iteration 166 \t train loss: 0.347698\n",
      "epoch: 7 \t iteration 167 \t train loss: 0.384877\n",
      "epoch: 7 \t iteration 168 \t train loss: 0.466269\n",
      "epoch: 7 \t iteration 169 \t train loss: 0.359127\n",
      "epoch: 7 \t iteration 170 \t train loss: 0.364521\n",
      "epoch: 7 \t iteration 171 \t train loss: 0.436932\n",
      "epoch: 7 \t iteration 172 \t train loss: 0.398168\n",
      "epoch: 7 \t iteration 173 \t train loss: 0.341130\n",
      "epoch: 7 \t iteration 174 \t train loss: 0.398573\n",
      "epoch: 7 \t iteration 175 \t train loss: 0.379458\n",
      "epoch: 7 \t iteration 176 \t train loss: 0.410521\n",
      "epoch: 7 \t iteration 177 \t train loss: 0.380648\n",
      "epoch: 7 \t iteration 178 \t train loss: 0.354328\n",
      "epoch: 7 \t iteration 179 \t train loss: 0.437059\n",
      "epoch: 7 \t iteration 180 \t train loss: 0.358348\n",
      "epoch: 7 \t iteration 181 \t train loss: 0.367696\n",
      "epoch: 7 \t iteration 182 \t train loss: 0.405302\n",
      "epoch: 7 \t iteration 183 \t train loss: 0.326782\n",
      "epoch: 7 \t iteration 184 \t train loss: 0.386510\n",
      "epoch: 7 \t iteration 185 \t train loss: 0.414860\n",
      "epoch: 7 \t iteration 186 \t train loss: 0.363842\n",
      "epoch: 7 \t iteration 187 \t train loss: 0.346826\n",
      "epoch: 7 \t iteration 188 \t train loss: 0.373863\n",
      "epoch: 7 \t iteration 189 \t train loss: 0.403778\n",
      "epoch: 7 \t iteration 190 \t train loss: 0.441548\n",
      "epoch: 7 \t iteration 191 \t train loss: 0.350295\n",
      "epoch: 7 \t iteration 192 \t train loss: 0.311380\n",
      "epoch: 7 \t iteration 193 \t train loss: 0.331564\n",
      "epoch: 7 \t iteration 194 \t train loss: 0.346081\n",
      "epoch: 7 \t iteration 195 \t train loss: 0.284269\n",
      "epoch: 7 \t iteration 196 \t train loss: 0.259461\n",
      "epoch: 7 \t iteration 197 \t train loss: 0.437196\n",
      "epoch: 7 \t iteration 198 \t train loss: 0.383578\n",
      "epoch: 7 \t iteration 199 \t train loss: 0.335774\n",
      "epoch:7 \t mean train loss: 0.399464 \t mean train acc: 0.854320\n",
      "epoch: 7 \t iteration 0 \t eval loss: 0.374702\n",
      "epoch: 7 \t iteration 1 \t eval loss: 0.349499\n",
      "epoch: 7 \t iteration 2 \t eval loss: 0.439776\n",
      "epoch: 7 \t iteration 3 \t eval loss: 0.396591\n",
      "epoch: 7 \t iteration 4 \t eval loss: 0.453511\n",
      "epoch: 7 \t iteration 5 \t eval loss: 0.428249\n",
      "epoch: 7 \t iteration 6 \t eval loss: 0.364613\n",
      "epoch: 7 \t iteration 7 \t eval loss: 0.372944\n",
      "epoch: 7 \t iteration 8 \t eval loss: 0.360675\n",
      "epoch: 7 \t iteration 9 \t eval loss: 0.370230\n",
      "epoch: 7 \t iteration 10 \t eval loss: 0.354499\n",
      "epoch: 7 \t iteration 11 \t eval loss: 0.380645\n",
      "epoch: 7 \t iteration 12 \t eval loss: 0.391769\n",
      "epoch: 7 \t iteration 13 \t eval loss: 0.367815\n",
      "epoch: 7 \t iteration 14 \t eval loss: 0.409729\n",
      "epoch: 7 \t iteration 15 \t eval loss: 0.365579\n",
      "epoch: 7 \t iteration 16 \t eval loss: 0.408406\n",
      "epoch: 7 \t iteration 17 \t eval loss: 0.393178\n",
      "epoch: 7 \t iteration 18 \t eval loss: 0.370918\n",
      "epoch: 7 \t iteration 19 \t eval loss: 0.393697\n",
      "epoch: 7 \t iteration 20 \t eval loss: 0.397218\n",
      "epoch: 7 \t iteration 21 \t eval loss: 0.359202\n",
      "epoch: 7 \t iteration 22 \t eval loss: 0.391607\n",
      "epoch: 7 \t iteration 23 \t eval loss: 0.366553\n",
      "epoch: 7 \t iteration 24 \t eval loss: 0.361083\n",
      "epoch: 7 \t iteration 25 \t eval loss: 0.396460\n",
      "epoch: 7 \t iteration 26 \t eval loss: 0.307195\n",
      "epoch: 7 \t iteration 27 \t eval loss: 0.460973\n",
      "epoch: 7 \t iteration 28 \t eval loss: 0.427705\n",
      "epoch: 7 \t iteration 29 \t eval loss: 0.426870\n",
      "epoch: 7 \t iteration 30 \t eval loss: 0.397347\n",
      "epoch: 7 \t iteration 31 \t eval loss: 0.435108\n",
      "epoch: 7 \t iteration 32 \t eval loss: 0.423658\n",
      "epoch: 7 \t iteration 33 \t eval loss: 0.417019\n",
      "epoch: 7 \t iteration 34 \t eval loss: 0.462452\n",
      "epoch: 7 \t iteration 35 \t eval loss: 0.437797\n",
      "epoch: 7 \t iteration 36 \t eval loss: 0.353030\n",
      "epoch: 7 \t iteration 37 \t eval loss: 0.394834\n",
      "epoch: 7 \t iteration 38 \t eval loss: 0.383770\n",
      "epoch: 7 \t iteration 39 \t eval loss: 0.339217\n",
      "epoch:7 \t mean eval loss: 0.392153 \t mean eval acc: 0.855600\n",
      "epoch: 8 \t iteration 0 \t train loss: 0.396720\n",
      "epoch: 8 \t iteration 1 \t train loss: 0.348169\n",
      "epoch: 8 \t iteration 2 \t train loss: 0.366558\n",
      "epoch: 8 \t iteration 3 \t train loss: 0.375531\n",
      "epoch: 8 \t iteration 4 \t train loss: 0.382564\n",
      "epoch: 8 \t iteration 5 \t train loss: 0.369091\n",
      "epoch: 8 \t iteration 6 \t train loss: 0.485700\n",
      "epoch: 8 \t iteration 7 \t train loss: 0.414365\n",
      "epoch: 8 \t iteration 8 \t train loss: 0.378389\n",
      "epoch: 8 \t iteration 9 \t train loss: 0.437127\n",
      "epoch: 8 \t iteration 10 \t train loss: 0.424160\n",
      "epoch: 8 \t iteration 11 \t train loss: 0.427051\n",
      "epoch: 8 \t iteration 12 \t train loss: 0.454894\n",
      "epoch: 8 \t iteration 13 \t train loss: 0.372387\n",
      "epoch: 8 \t iteration 14 \t train loss: 0.399268\n",
      "epoch: 8 \t iteration 15 \t train loss: 0.438043\n",
      "epoch: 8 \t iteration 16 \t train loss: 0.475361\n",
      "epoch: 8 \t iteration 17 \t train loss: 0.444629\n",
      "epoch: 8 \t iteration 18 \t train loss: 0.499350\n",
      "epoch: 8 \t iteration 19 \t train loss: 0.429797\n",
      "epoch: 8 \t iteration 20 \t train loss: 0.385378\n",
      "epoch: 8 \t iteration 21 \t train loss: 0.368840\n",
      "epoch: 8 \t iteration 22 \t train loss: 0.403249\n",
      "epoch: 8 \t iteration 23 \t train loss: 0.444532\n",
      "epoch: 8 \t iteration 24 \t train loss: 0.423161\n",
      "epoch: 8 \t iteration 25 \t train loss: 0.360857\n",
      "epoch: 8 \t iteration 26 \t train loss: 0.377493\n",
      "epoch: 8 \t iteration 27 \t train loss: 0.441595\n",
      "epoch: 8 \t iteration 28 \t train loss: 0.426907\n",
      "epoch: 8 \t iteration 29 \t train loss: 0.376332\n",
      "epoch: 8 \t iteration 30 \t train loss: 0.478939\n",
      "epoch: 8 \t iteration 31 \t train loss: 0.408099\n",
      "epoch: 8 \t iteration 32 \t train loss: 0.372374\n",
      "epoch: 8 \t iteration 33 \t train loss: 0.375731\n",
      "epoch: 8 \t iteration 34 \t train loss: 0.368299\n",
      "epoch: 8 \t iteration 35 \t train loss: 0.330916\n",
      "epoch: 8 \t iteration 36 \t train loss: 0.417294\n",
      "epoch: 8 \t iteration 37 \t train loss: 0.397159\n",
      "epoch: 8 \t iteration 38 \t train loss: 0.365052\n",
      "epoch: 8 \t iteration 39 \t train loss: 0.395782\n",
      "epoch: 8 \t iteration 40 \t train loss: 0.429292\n",
      "epoch: 8 \t iteration 41 \t train loss: 0.362001\n",
      "epoch: 8 \t iteration 42 \t train loss: 0.387700\n",
      "epoch: 8 \t iteration 43 \t train loss: 0.445627\n",
      "epoch: 8 \t iteration 44 \t train loss: 0.352401\n",
      "epoch: 8 \t iteration 45 \t train loss: 0.394021\n",
      "epoch: 8 \t iteration 46 \t train loss: 0.397659\n",
      "epoch: 8 \t iteration 47 \t train loss: 0.336373\n",
      "epoch: 8 \t iteration 48 \t train loss: 0.417921\n",
      "epoch: 8 \t iteration 49 \t train loss: 0.402664\n",
      "epoch: 8 \t iteration 50 \t train loss: 0.531401\n",
      "epoch: 8 \t iteration 51 \t train loss: 0.364094\n",
      "epoch: 8 \t iteration 52 \t train loss: 0.415645\n",
      "epoch: 8 \t iteration 53 \t train loss: 0.378752\n",
      "epoch: 8 \t iteration 54 \t train loss: 0.389074\n",
      "epoch: 8 \t iteration 55 \t train loss: 0.410032\n",
      "epoch: 8 \t iteration 56 \t train loss: 0.399185\n",
      "epoch: 8 \t iteration 57 \t train loss: 0.388061\n",
      "epoch: 8 \t iteration 58 \t train loss: 0.412287\n",
      "epoch: 8 \t iteration 59 \t train loss: 0.408342\n",
      "epoch: 8 \t iteration 60 \t train loss: 0.363559\n",
      "epoch: 8 \t iteration 61 \t train loss: 0.366034\n",
      "epoch: 8 \t iteration 62 \t train loss: 0.378102\n",
      "epoch: 8 \t iteration 63 \t train loss: 0.395931\n",
      "epoch: 8 \t iteration 64 \t train loss: 0.352543\n",
      "epoch: 8 \t iteration 65 \t train loss: 0.415968\n",
      "epoch: 8 \t iteration 66 \t train loss: 0.450735\n",
      "epoch: 8 \t iteration 67 \t train loss: 0.389387\n",
      "epoch: 8 \t iteration 68 \t train loss: 0.421125\n",
      "epoch: 8 \t iteration 69 \t train loss: 0.420141\n",
      "epoch: 8 \t iteration 70 \t train loss: 0.382903\n",
      "epoch: 8 \t iteration 71 \t train loss: 0.365234\n",
      "epoch: 8 \t iteration 72 \t train loss: 0.346517\n",
      "epoch: 8 \t iteration 73 \t train loss: 0.401495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 \t iteration 74 \t train loss: 0.406191\n",
      "epoch: 8 \t iteration 75 \t train loss: 0.370169\n",
      "epoch: 8 \t iteration 76 \t train loss: 0.434372\n",
      "epoch: 8 \t iteration 77 \t train loss: 0.378964\n",
      "epoch: 8 \t iteration 78 \t train loss: 0.408287\n",
      "epoch: 8 \t iteration 79 \t train loss: 0.461773\n",
      "epoch: 8 \t iteration 80 \t train loss: 0.442560\n",
      "epoch: 8 \t iteration 81 \t train loss: 0.399807\n",
      "epoch: 8 \t iteration 82 \t train loss: 0.440125\n",
      "epoch: 8 \t iteration 83 \t train loss: 0.413164\n",
      "epoch: 8 \t iteration 84 \t train loss: 0.405904\n",
      "epoch: 8 \t iteration 85 \t train loss: 0.455166\n",
      "epoch: 8 \t iteration 86 \t train loss: 0.437554\n",
      "epoch: 8 \t iteration 87 \t train loss: 0.391832\n",
      "epoch: 8 \t iteration 88 \t train loss: 0.418787\n",
      "epoch: 8 \t iteration 89 \t train loss: 0.468594\n",
      "epoch: 8 \t iteration 90 \t train loss: 0.385457\n",
      "epoch: 8 \t iteration 91 \t train loss: 0.379712\n",
      "epoch: 8 \t iteration 92 \t train loss: 0.407023\n",
      "epoch: 8 \t iteration 93 \t train loss: 0.403836\n",
      "epoch: 8 \t iteration 94 \t train loss: 0.352754\n",
      "epoch: 8 \t iteration 95 \t train loss: 0.341649\n",
      "epoch: 8 \t iteration 96 \t train loss: 0.371436\n",
      "epoch: 8 \t iteration 97 \t train loss: 0.377517\n",
      "epoch: 8 \t iteration 98 \t train loss: 0.436121\n",
      "epoch: 8 \t iteration 99 \t train loss: 0.419564\n",
      "epoch: 8 \t iteration 100 \t train loss: 0.393435\n",
      "epoch: 8 \t iteration 101 \t train loss: 0.376078\n",
      "epoch: 8 \t iteration 102 \t train loss: 0.390067\n",
      "epoch: 8 \t iteration 103 \t train loss: 0.390610\n",
      "epoch: 8 \t iteration 104 \t train loss: 0.421159\n",
      "epoch: 8 \t iteration 105 \t train loss: 0.391429\n",
      "epoch: 8 \t iteration 106 \t train loss: 0.367791\n",
      "epoch: 8 \t iteration 107 \t train loss: 0.403031\n",
      "epoch: 8 \t iteration 108 \t train loss: 0.427482\n",
      "epoch: 8 \t iteration 109 \t train loss: 0.499538\n",
      "epoch: 8 \t iteration 110 \t train loss: 0.408550\n",
      "epoch: 8 \t iteration 111 \t train loss: 0.404208\n",
      "epoch: 8 \t iteration 112 \t train loss: 0.367554\n",
      "epoch: 8 \t iteration 113 \t train loss: 0.403692\n",
      "epoch: 8 \t iteration 114 \t train loss: 0.410202\n",
      "epoch: 8 \t iteration 115 \t train loss: 0.339150\n",
      "epoch: 8 \t iteration 116 \t train loss: 0.325250\n",
      "epoch: 8 \t iteration 117 \t train loss: 0.460989\n",
      "epoch: 8 \t iteration 118 \t train loss: 0.425543\n",
      "epoch: 8 \t iteration 119 \t train loss: 0.450122\n",
      "epoch: 8 \t iteration 120 \t train loss: 0.372649\n",
      "epoch: 8 \t iteration 121 \t train loss: 0.407479\n",
      "epoch: 8 \t iteration 122 \t train loss: 0.400896\n",
      "epoch: 8 \t iteration 123 \t train loss: 0.346520\n",
      "epoch: 8 \t iteration 124 \t train loss: 0.398108\n",
      "epoch: 8 \t iteration 125 \t train loss: 0.474029\n",
      "epoch: 8 \t iteration 126 \t train loss: 0.410929\n",
      "epoch: 8 \t iteration 127 \t train loss: 0.390930\n",
      "epoch: 8 \t iteration 128 \t train loss: 0.436658\n",
      "epoch: 8 \t iteration 129 \t train loss: 0.465118\n",
      "epoch: 8 \t iteration 130 \t train loss: 0.410120\n",
      "epoch: 8 \t iteration 131 \t train loss: 0.405907\n",
      "epoch: 8 \t iteration 132 \t train loss: 0.425606\n",
      "epoch: 8 \t iteration 133 \t train loss: 0.340985\n",
      "epoch: 8 \t iteration 134 \t train loss: 0.373653\n",
      "epoch: 8 \t iteration 135 \t train loss: 0.406188\n",
      "epoch: 8 \t iteration 136 \t train loss: 0.412135\n",
      "epoch: 8 \t iteration 137 \t train loss: 0.434292\n",
      "epoch: 8 \t iteration 138 \t train loss: 0.342688\n",
      "epoch: 8 \t iteration 139 \t train loss: 0.435834\n",
      "epoch: 8 \t iteration 140 \t train loss: 0.416076\n",
      "epoch: 8 \t iteration 141 \t train loss: 0.391975\n",
      "epoch: 8 \t iteration 142 \t train loss: 0.408234\n",
      "epoch: 8 \t iteration 143 \t train loss: 0.435604\n",
      "epoch: 8 \t iteration 144 \t train loss: 0.429171\n",
      "epoch: 8 \t iteration 145 \t train loss: 0.434467\n",
      "epoch: 8 \t iteration 146 \t train loss: 0.375662\n",
      "epoch: 8 \t iteration 147 \t train loss: 0.349199\n",
      "epoch: 8 \t iteration 148 \t train loss: 0.372815\n",
      "epoch: 8 \t iteration 149 \t train loss: 0.443444\n",
      "epoch: 8 \t iteration 150 \t train loss: 0.422677\n",
      "epoch: 8 \t iteration 151 \t train loss: 0.382903\n",
      "epoch: 8 \t iteration 152 \t train loss: 0.352275\n",
      "epoch: 8 \t iteration 153 \t train loss: 0.380268\n",
      "epoch: 8 \t iteration 154 \t train loss: 0.377208\n",
      "epoch: 8 \t iteration 155 \t train loss: 0.407897\n",
      "epoch: 8 \t iteration 156 \t train loss: 0.463392\n",
      "epoch: 8 \t iteration 157 \t train loss: 0.386798\n",
      "epoch: 8 \t iteration 158 \t train loss: 0.477738\n",
      "epoch: 8 \t iteration 159 \t train loss: 0.441140\n",
      "epoch: 8 \t iteration 160 \t train loss: 0.384183\n",
      "epoch: 8 \t iteration 161 \t train loss: 0.442302\n",
      "epoch: 8 \t iteration 162 \t train loss: 0.414409\n",
      "epoch: 8 \t iteration 163 \t train loss: 0.371596\n",
      "epoch: 8 \t iteration 164 \t train loss: 0.374245\n",
      "epoch: 8 \t iteration 165 \t train loss: 0.365668\n",
      "epoch: 8 \t iteration 166 \t train loss: 0.346186\n",
      "epoch: 8 \t iteration 167 \t train loss: 0.384075\n",
      "epoch: 8 \t iteration 168 \t train loss: 0.464535\n",
      "epoch: 8 \t iteration 169 \t train loss: 0.357889\n",
      "epoch: 8 \t iteration 170 \t train loss: 0.363214\n",
      "epoch: 8 \t iteration 171 \t train loss: 0.435499\n",
      "epoch: 8 \t iteration 172 \t train loss: 0.397015\n",
      "epoch: 8 \t iteration 173 \t train loss: 0.339403\n",
      "epoch: 8 \t iteration 174 \t train loss: 0.397554\n",
      "epoch: 8 \t iteration 175 \t train loss: 0.377681\n",
      "epoch: 8 \t iteration 176 \t train loss: 0.409004\n",
      "epoch: 8 \t iteration 177 \t train loss: 0.379217\n",
      "epoch: 8 \t iteration 178 \t train loss: 0.352937\n",
      "epoch: 8 \t iteration 179 \t train loss: 0.435382\n",
      "epoch: 8 \t iteration 180 \t train loss: 0.357280\n",
      "epoch: 8 \t iteration 181 \t train loss: 0.366164\n",
      "epoch: 8 \t iteration 182 \t train loss: 0.404077\n",
      "epoch: 8 \t iteration 183 \t train loss: 0.325599\n",
      "epoch: 8 \t iteration 184 \t train loss: 0.385573\n",
      "epoch: 8 \t iteration 185 \t train loss: 0.413447\n",
      "epoch: 8 \t iteration 186 \t train loss: 0.362300\n",
      "epoch: 8 \t iteration 187 \t train loss: 0.345563\n",
      "epoch: 8 \t iteration 188 \t train loss: 0.372831\n",
      "epoch: 8 \t iteration 189 \t train loss: 0.402717\n",
      "epoch: 8 \t iteration 190 \t train loss: 0.440895\n",
      "epoch: 8 \t iteration 191 \t train loss: 0.349287\n",
      "epoch: 8 \t iteration 192 \t train loss: 0.310265\n",
      "epoch: 8 \t iteration 193 \t train loss: 0.330130\n",
      "epoch: 8 \t iteration 194 \t train loss: 0.344906\n",
      "epoch: 8 \t iteration 195 \t train loss: 0.283608\n",
      "epoch: 8 \t iteration 196 \t train loss: 0.258334\n",
      "epoch: 8 \t iteration 197 \t train loss: 0.436911\n",
      "epoch: 8 \t iteration 198 \t train loss: 0.382671\n",
      "epoch: 8 \t iteration 199 \t train loss: 0.334269\n",
      "epoch:8 \t mean train loss: 0.398060 \t mean train acc: 0.854280\n",
      "epoch: 8 \t iteration 0 \t eval loss: 0.373544\n",
      "epoch: 8 \t iteration 1 \t eval loss: 0.348547\n",
      "epoch: 8 \t iteration 2 \t eval loss: 0.438634\n",
      "epoch: 8 \t iteration 3 \t eval loss: 0.395285\n",
      "epoch: 8 \t iteration 4 \t eval loss: 0.452710\n",
      "epoch: 8 \t iteration 5 \t eval loss: 0.428080\n",
      "epoch: 8 \t iteration 6 \t eval loss: 0.363423\n",
      "epoch: 8 \t iteration 7 \t eval loss: 0.371642\n",
      "epoch: 8 \t iteration 8 \t eval loss: 0.360048\n",
      "epoch: 8 \t iteration 9 \t eval loss: 0.368985\n",
      "epoch: 8 \t iteration 10 \t eval loss: 0.353192\n",
      "epoch: 8 \t iteration 11 \t eval loss: 0.379652\n",
      "epoch: 8 \t iteration 12 \t eval loss: 0.390536\n",
      "epoch: 8 \t iteration 13 \t eval loss: 0.366137\n",
      "epoch: 8 \t iteration 14 \t eval loss: 0.408172\n",
      "epoch: 8 \t iteration 15 \t eval loss: 0.364227\n",
      "epoch: 8 \t iteration 16 \t eval loss: 0.407608\n",
      "epoch: 8 \t iteration 17 \t eval loss: 0.391840\n",
      "epoch: 8 \t iteration 18 \t eval loss: 0.369513\n",
      "epoch: 8 \t iteration 19 \t eval loss: 0.392752\n",
      "epoch: 8 \t iteration 20 \t eval loss: 0.396339\n",
      "epoch: 8 \t iteration 21 \t eval loss: 0.358219\n",
      "epoch: 8 \t iteration 22 \t eval loss: 0.390272\n",
      "epoch: 8 \t iteration 23 \t eval loss: 0.365218\n",
      "epoch: 8 \t iteration 24 \t eval loss: 0.360117\n",
      "epoch: 8 \t iteration 25 \t eval loss: 0.395450\n",
      "epoch: 8 \t iteration 26 \t eval loss: 0.306243\n",
      "epoch: 8 \t iteration 27 \t eval loss: 0.460785\n",
      "epoch: 8 \t iteration 28 \t eval loss: 0.426399\n",
      "epoch: 8 \t iteration 29 \t eval loss: 0.425465\n",
      "epoch: 8 \t iteration 30 \t eval loss: 0.395837\n",
      "epoch: 8 \t iteration 31 \t eval loss: 0.433898\n",
      "epoch: 8 \t iteration 32 \t eval loss: 0.422653\n",
      "epoch: 8 \t iteration 33 \t eval loss: 0.416115\n",
      "epoch: 8 \t iteration 34 \t eval loss: 0.461812\n",
      "epoch: 8 \t iteration 35 \t eval loss: 0.436449\n",
      "epoch: 8 \t iteration 36 \t eval loss: 0.351987\n",
      "epoch: 8 \t iteration 37 \t eval loss: 0.393778\n",
      "epoch: 8 \t iteration 38 \t eval loss: 0.382803\n",
      "epoch: 8 \t iteration 39 \t eval loss: 0.337835\n",
      "epoch:8 \t mean eval loss: 0.391055 \t mean eval acc: 0.856000\n",
      "epoch: 9 \t iteration 0 \t train loss: 0.395781\n",
      "epoch: 9 \t iteration 1 \t train loss: 0.347122\n",
      "epoch: 9 \t iteration 2 \t train loss: 0.365506\n",
      "epoch: 9 \t iteration 3 \t train loss: 0.374138\n",
      "epoch: 9 \t iteration 4 \t train loss: 0.381359\n",
      "epoch: 9 \t iteration 5 \t train loss: 0.368358\n",
      "epoch: 9 \t iteration 6 \t train loss: 0.484711\n",
      "epoch: 9 \t iteration 7 \t train loss: 0.413477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 \t iteration 8 \t train loss: 0.377684\n",
      "epoch: 9 \t iteration 9 \t train loss: 0.435897\n",
      "epoch: 9 \t iteration 10 \t train loss: 0.422893\n",
      "epoch: 9 \t iteration 11 \t train loss: 0.425760\n",
      "epoch: 9 \t iteration 12 \t train loss: 0.453806\n",
      "epoch: 9 \t iteration 13 \t train loss: 0.370956\n",
      "epoch: 9 \t iteration 14 \t train loss: 0.398312\n",
      "epoch: 9 \t iteration 15 \t train loss: 0.436372\n",
      "epoch: 9 \t iteration 16 \t train loss: 0.474124\n",
      "epoch: 9 \t iteration 17 \t train loss: 0.443223\n",
      "epoch: 9 \t iteration 18 \t train loss: 0.497996\n",
      "epoch: 9 \t iteration 19 \t train loss: 0.428848\n",
      "epoch: 9 \t iteration 20 \t train loss: 0.384320\n",
      "epoch: 9 \t iteration 21 \t train loss: 0.367635\n",
      "epoch: 9 \t iteration 22 \t train loss: 0.402099\n",
      "epoch: 9 \t iteration 23 \t train loss: 0.442890\n",
      "epoch: 9 \t iteration 24 \t train loss: 0.421347\n",
      "epoch: 9 \t iteration 25 \t train loss: 0.359480\n",
      "epoch: 9 \t iteration 26 \t train loss: 0.376894\n",
      "epoch: 9 \t iteration 27 \t train loss: 0.440462\n",
      "epoch: 9 \t iteration 28 \t train loss: 0.425299\n",
      "epoch: 9 \t iteration 29 \t train loss: 0.375196\n",
      "epoch: 9 \t iteration 30 \t train loss: 0.477792\n",
      "epoch: 9 \t iteration 31 \t train loss: 0.406975\n",
      "epoch: 9 \t iteration 32 \t train loss: 0.371222\n",
      "epoch: 9 \t iteration 33 \t train loss: 0.374574\n",
      "epoch: 9 \t iteration 34 \t train loss: 0.366793\n",
      "epoch: 9 \t iteration 35 \t train loss: 0.329513\n",
      "epoch: 9 \t iteration 36 \t train loss: 0.415547\n",
      "epoch: 9 \t iteration 37 \t train loss: 0.395980\n",
      "epoch: 9 \t iteration 38 \t train loss: 0.363955\n",
      "epoch: 9 \t iteration 39 \t train loss: 0.394354\n",
      "epoch: 9 \t iteration 40 \t train loss: 0.428136\n",
      "epoch: 9 \t iteration 41 \t train loss: 0.360527\n",
      "epoch: 9 \t iteration 42 \t train loss: 0.386599\n",
      "epoch: 9 \t iteration 43 \t train loss: 0.444120\n",
      "epoch: 9 \t iteration 44 \t train loss: 0.351212\n",
      "epoch: 9 \t iteration 45 \t train loss: 0.392798\n",
      "epoch: 9 \t iteration 46 \t train loss: 0.396290\n",
      "epoch: 9 \t iteration 47 \t train loss: 0.335733\n",
      "epoch: 9 \t iteration 48 \t train loss: 0.416381\n",
      "epoch: 9 \t iteration 49 \t train loss: 0.401937\n",
      "epoch: 9 \t iteration 50 \t train loss: 0.530250\n",
      "epoch: 9 \t iteration 51 \t train loss: 0.363007\n",
      "epoch: 9 \t iteration 52 \t train loss: 0.414505\n",
      "epoch: 9 \t iteration 53 \t train loss: 0.377163\n",
      "epoch: 9 \t iteration 54 \t train loss: 0.387470\n",
      "epoch: 9 \t iteration 55 \t train loss: 0.409272\n",
      "epoch: 9 \t iteration 56 \t train loss: 0.398082\n",
      "epoch: 9 \t iteration 57 \t train loss: 0.386740\n",
      "epoch: 9 \t iteration 58 \t train loss: 0.411124\n",
      "epoch: 9 \t iteration 59 \t train loss: 0.406609\n",
      "epoch: 9 \t iteration 60 \t train loss: 0.362160\n",
      "epoch: 9 \t iteration 61 \t train loss: 0.365059\n",
      "epoch: 9 \t iteration 62 \t train loss: 0.377323\n",
      "epoch: 9 \t iteration 63 \t train loss: 0.395230\n",
      "epoch: 9 \t iteration 64 \t train loss: 0.351111\n",
      "epoch: 9 \t iteration 65 \t train loss: 0.414228\n",
      "epoch: 9 \t iteration 66 \t train loss: 0.449694\n",
      "epoch: 9 \t iteration 67 \t train loss: 0.388021\n",
      "epoch: 9 \t iteration 68 \t train loss: 0.419932\n",
      "epoch: 9 \t iteration 69 \t train loss: 0.418900\n",
      "epoch: 9 \t iteration 70 \t train loss: 0.381498\n",
      "epoch: 9 \t iteration 71 \t train loss: 0.364274\n",
      "epoch: 9 \t iteration 72 \t train loss: 0.345714\n",
      "epoch: 9 \t iteration 73 \t train loss: 0.400167\n",
      "epoch: 9 \t iteration 74 \t train loss: 0.405130\n",
      "epoch: 9 \t iteration 75 \t train loss: 0.369448\n",
      "epoch: 9 \t iteration 76 \t train loss: 0.433104\n",
      "epoch: 9 \t iteration 77 \t train loss: 0.378171\n",
      "epoch: 9 \t iteration 78 \t train loss: 0.406984\n",
      "epoch: 9 \t iteration 79 \t train loss: 0.460653\n",
      "epoch: 9 \t iteration 80 \t train loss: 0.440866\n",
      "epoch: 9 \t iteration 81 \t train loss: 0.398692\n",
      "epoch: 9 \t iteration 82 \t train loss: 0.439270\n",
      "epoch: 9 \t iteration 83 \t train loss: 0.412157\n",
      "epoch: 9 \t iteration 84 \t train loss: 0.404985\n",
      "epoch: 9 \t iteration 85 \t train loss: 0.453374\n",
      "epoch: 9 \t iteration 86 \t train loss: 0.436136\n",
      "epoch: 9 \t iteration 87 \t train loss: 0.390604\n",
      "epoch: 9 \t iteration 88 \t train loss: 0.416961\n",
      "epoch: 9 \t iteration 89 \t train loss: 0.467127\n",
      "epoch: 9 \t iteration 90 \t train loss: 0.383929\n",
      "epoch: 9 \t iteration 91 \t train loss: 0.378541\n",
      "epoch: 9 \t iteration 92 \t train loss: 0.404596\n",
      "epoch: 9 \t iteration 93 \t train loss: 0.402855\n",
      "epoch: 9 \t iteration 94 \t train loss: 0.351507\n",
      "epoch: 9 \t iteration 95 \t train loss: 0.340861\n",
      "epoch: 9 \t iteration 96 \t train loss: 0.370186\n",
      "epoch: 9 \t iteration 97 \t train loss: 0.376377\n",
      "epoch: 9 \t iteration 98 \t train loss: 0.434646\n",
      "epoch: 9 \t iteration 99 \t train loss: 0.417956\n",
      "epoch: 9 \t iteration 100 \t train loss: 0.392389\n",
      "epoch: 9 \t iteration 101 \t train loss: 0.374665\n",
      "epoch: 9 \t iteration 102 \t train loss: 0.389181\n",
      "epoch: 9 \t iteration 103 \t train loss: 0.389110\n",
      "epoch: 9 \t iteration 104 \t train loss: 0.419886\n",
      "epoch: 9 \t iteration 105 \t train loss: 0.389654\n",
      "epoch: 9 \t iteration 106 \t train loss: 0.367197\n",
      "epoch: 9 \t iteration 107 \t train loss: 0.402338\n",
      "epoch: 9 \t iteration 108 \t train loss: 0.426513\n",
      "epoch: 9 \t iteration 109 \t train loss: 0.499498\n",
      "epoch: 9 \t iteration 110 \t train loss: 0.407165\n",
      "epoch: 9 \t iteration 111 \t train loss: 0.403242\n",
      "epoch: 9 \t iteration 112 \t train loss: 0.366070\n",
      "epoch: 9 \t iteration 113 \t train loss: 0.402367\n",
      "epoch: 9 \t iteration 114 \t train loss: 0.408828\n",
      "epoch: 9 \t iteration 115 \t train loss: 0.338006\n",
      "epoch: 9 \t iteration 116 \t train loss: 0.324086\n",
      "epoch: 9 \t iteration 117 \t train loss: 0.459490\n",
      "epoch: 9 \t iteration 118 \t train loss: 0.424087\n",
      "epoch: 9 \t iteration 119 \t train loss: 0.448927\n",
      "epoch: 9 \t iteration 120 \t train loss: 0.371384\n",
      "epoch: 9 \t iteration 121 \t train loss: 0.406619\n",
      "epoch: 9 \t iteration 122 \t train loss: 0.399850\n",
      "epoch: 9 \t iteration 123 \t train loss: 0.344939\n",
      "epoch: 9 \t iteration 124 \t train loss: 0.396838\n",
      "epoch: 9 \t iteration 125 \t train loss: 0.472607\n",
      "epoch: 9 \t iteration 126 \t train loss: 0.409690\n",
      "epoch: 9 \t iteration 127 \t train loss: 0.389587\n",
      "epoch: 9 \t iteration 128 \t train loss: 0.435864\n",
      "epoch: 9 \t iteration 129 \t train loss: 0.463942\n",
      "epoch: 9 \t iteration 130 \t train loss: 0.409256\n",
      "epoch: 9 \t iteration 131 \t train loss: 0.404752\n",
      "epoch: 9 \t iteration 132 \t train loss: 0.424729\n",
      "epoch: 9 \t iteration 133 \t train loss: 0.340249\n",
      "epoch: 9 \t iteration 134 \t train loss: 0.372971\n",
      "epoch: 9 \t iteration 135 \t train loss: 0.405254\n",
      "epoch: 9 \t iteration 136 \t train loss: 0.411333\n",
      "epoch: 9 \t iteration 137 \t train loss: 0.433126\n",
      "epoch: 9 \t iteration 138 \t train loss: 0.341594\n",
      "epoch: 9 \t iteration 139 \t train loss: 0.435229\n",
      "epoch: 9 \t iteration 140 \t train loss: 0.414833\n",
      "epoch: 9 \t iteration 141 \t train loss: 0.390854\n",
      "epoch: 9 \t iteration 142 \t train loss: 0.407489\n",
      "epoch: 9 \t iteration 143 \t train loss: 0.434527\n",
      "epoch: 9 \t iteration 144 \t train loss: 0.428078\n",
      "epoch: 9 \t iteration 145 \t train loss: 0.433376\n",
      "epoch: 9 \t iteration 146 \t train loss: 0.374600\n",
      "epoch: 9 \t iteration 147 \t train loss: 0.348011\n",
      "epoch: 9 \t iteration 148 \t train loss: 0.371266\n",
      "epoch: 9 \t iteration 149 \t train loss: 0.442309\n",
      "epoch: 9 \t iteration 150 \t train loss: 0.421536\n",
      "epoch: 9 \t iteration 151 \t train loss: 0.381693\n",
      "epoch: 9 \t iteration 152 \t train loss: 0.351149\n",
      "epoch: 9 \t iteration 153 \t train loss: 0.379336\n",
      "epoch: 9 \t iteration 154 \t train loss: 0.376067\n",
      "epoch: 9 \t iteration 155 \t train loss: 0.406515\n",
      "epoch: 9 \t iteration 156 \t train loss: 0.461787\n",
      "epoch: 9 \t iteration 157 \t train loss: 0.385806\n",
      "epoch: 9 \t iteration 158 \t train loss: 0.476415\n",
      "epoch: 9 \t iteration 159 \t train loss: 0.440067\n",
      "epoch: 9 \t iteration 160 \t train loss: 0.382585\n",
      "epoch: 9 \t iteration 161 \t train loss: 0.441857\n",
      "epoch: 9 \t iteration 162 \t train loss: 0.413162\n",
      "epoch: 9 \t iteration 163 \t train loss: 0.370907\n",
      "epoch: 9 \t iteration 164 \t train loss: 0.373343\n",
      "epoch: 9 \t iteration 165 \t train loss: 0.364720\n",
      "epoch: 9 \t iteration 166 \t train loss: 0.344960\n",
      "epoch: 9 \t iteration 167 \t train loss: 0.383455\n",
      "epoch: 9 \t iteration 168 \t train loss: 0.463058\n",
      "epoch: 9 \t iteration 169 \t train loss: 0.356865\n",
      "epoch: 9 \t iteration 170 \t train loss: 0.362146\n",
      "epoch: 9 \t iteration 171 \t train loss: 0.434340\n",
      "epoch: 9 \t iteration 172 \t train loss: 0.396043\n",
      "epoch: 9 \t iteration 173 \t train loss: 0.337942\n",
      "epoch: 9 \t iteration 174 \t train loss: 0.396710\n",
      "epoch: 9 \t iteration 175 \t train loss: 0.376172\n",
      "epoch: 9 \t iteration 176 \t train loss: 0.407694\n",
      "epoch: 9 \t iteration 177 \t train loss: 0.378023\n",
      "epoch: 9 \t iteration 178 \t train loss: 0.351776\n",
      "epoch: 9 \t iteration 179 \t train loss: 0.433962\n",
      "epoch: 9 \t iteration 180 \t train loss: 0.356421\n",
      "epoch: 9 \t iteration 181 \t train loss: 0.364888\n",
      "epoch: 9 \t iteration 182 \t train loss: 0.403048\n",
      "epoch: 9 \t iteration 183 \t train loss: 0.324650\n",
      "epoch: 9 \t iteration 184 \t train loss: 0.384803\n",
      "epoch: 9 \t iteration 185 \t train loss: 0.412278\n",
      "epoch: 9 \t iteration 186 \t train loss: 0.360964\n",
      "epoch: 9 \t iteration 187 \t train loss: 0.344515\n",
      "epoch: 9 \t iteration 188 \t train loss: 0.371972\n",
      "epoch: 9 \t iteration 189 \t train loss: 0.401898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 \t iteration 190 \t train loss: 0.440342\n",
      "epoch: 9 \t iteration 191 \t train loss: 0.348449\n",
      "epoch: 9 \t iteration 192 \t train loss: 0.309386\n",
      "epoch: 9 \t iteration 193 \t train loss: 0.328937\n",
      "epoch: 9 \t iteration 194 \t train loss: 0.343932\n",
      "epoch: 9 \t iteration 195 \t train loss: 0.283131\n",
      "epoch: 9 \t iteration 196 \t train loss: 0.257394\n",
      "epoch: 9 \t iteration 197 \t train loss: 0.436663\n",
      "epoch: 9 \t iteration 198 \t train loss: 0.381936\n",
      "epoch: 9 \t iteration 199 \t train loss: 0.333024\n",
      "epoch:9 \t mean train loss: 0.396908 \t mean train acc: 0.854260\n",
      "epoch: 9 \t iteration 0 \t eval loss: 0.372622\n",
      "epoch: 9 \t iteration 1 \t eval loss: 0.347790\n",
      "epoch: 9 \t iteration 2 \t eval loss: 0.437722\n",
      "epoch: 9 \t iteration 3 \t eval loss: 0.394243\n",
      "epoch: 9 \t iteration 4 \t eval loss: 0.452082\n",
      "epoch: 9 \t iteration 5 \t eval loss: 0.427955\n",
      "epoch: 9 \t iteration 6 \t eval loss: 0.362431\n",
      "epoch: 9 \t iteration 7 \t eval loss: 0.370551\n",
      "epoch: 9 \t iteration 8 \t eval loss: 0.359590\n",
      "epoch: 9 \t iteration 9 \t eval loss: 0.367957\n",
      "epoch: 9 \t iteration 10 \t eval loss: 0.352114\n",
      "epoch: 9 \t iteration 11 \t eval loss: 0.378868\n",
      "epoch: 9 \t iteration 12 \t eval loss: 0.389550\n",
      "epoch: 9 \t iteration 13 \t eval loss: 0.364763\n",
      "epoch: 9 \t iteration 14 \t eval loss: 0.406838\n",
      "epoch: 9 \t iteration 15 \t eval loss: 0.363130\n",
      "epoch: 9 \t iteration 16 \t eval loss: 0.406983\n",
      "epoch: 9 \t iteration 17 \t eval loss: 0.390730\n",
      "epoch: 9 \t iteration 18 \t eval loss: 0.368362\n",
      "epoch: 9 \t iteration 19 \t eval loss: 0.392022\n",
      "epoch: 9 \t iteration 20 \t eval loss: 0.395631\n",
      "epoch: 9 \t iteration 21 \t eval loss: 0.357433\n",
      "epoch: 9 \t iteration 22 \t eval loss: 0.389176\n",
      "epoch: 9 \t iteration 23 \t eval loss: 0.364157\n",
      "epoch: 9 \t iteration 24 \t eval loss: 0.359325\n",
      "epoch: 9 \t iteration 25 \t eval loss: 0.394659\n",
      "epoch: 9 \t iteration 26 \t eval loss: 0.305487\n",
      "epoch: 9 \t iteration 27 \t eval loss: 0.460659\n",
      "epoch: 9 \t iteration 28 \t eval loss: 0.425307\n",
      "epoch: 9 \t iteration 29 \t eval loss: 0.424330\n",
      "epoch: 9 \t iteration 30 \t eval loss: 0.394564\n",
      "epoch: 9 \t iteration 31 \t eval loss: 0.432953\n",
      "epoch: 9 \t iteration 32 \t eval loss: 0.421822\n",
      "epoch: 9 \t iteration 33 \t eval loss: 0.415430\n",
      "epoch: 9 \t iteration 34 \t eval loss: 0.461334\n",
      "epoch: 9 \t iteration 35 \t eval loss: 0.435332\n",
      "epoch: 9 \t iteration 36 \t eval loss: 0.351128\n",
      "epoch: 9 \t iteration 37 \t eval loss: 0.392940\n",
      "epoch: 9 \t iteration 38 \t eval loss: 0.382047\n",
      "epoch: 9 \t iteration 39 \t eval loss: 0.336693\n",
      "epoch:9 \t mean eval loss: 0.390168 \t mean eval acc: 0.855300\n",
      "epoch: 10 \t iteration 0 \t train loss: 0.395006\n",
      "epoch: 10 \t iteration 1 \t train loss: 0.346256\n",
      "epoch: 10 \t iteration 2 \t train loss: 0.364617\n",
      "epoch: 10 \t iteration 3 \t train loss: 0.372991\n",
      "epoch: 10 \t iteration 4 \t train loss: 0.380405\n",
      "epoch: 10 \t iteration 5 \t train loss: 0.367754\n",
      "epoch: 10 \t iteration 6 \t train loss: 0.483913\n",
      "epoch: 10 \t iteration 7 \t train loss: 0.412786\n",
      "epoch: 10 \t iteration 8 \t train loss: 0.377147\n",
      "epoch: 10 \t iteration 9 \t train loss: 0.434901\n",
      "epoch: 10 \t iteration 10 \t train loss: 0.421864\n",
      "epoch: 10 \t iteration 11 \t train loss: 0.424704\n",
      "epoch: 10 \t iteration 12 \t train loss: 0.452918\n",
      "epoch: 10 \t iteration 13 \t train loss: 0.369771\n",
      "epoch: 10 \t iteration 14 \t train loss: 0.397513\n",
      "epoch: 10 \t iteration 15 \t train loss: 0.434929\n",
      "epoch: 10 \t iteration 16 \t train loss: 0.473084\n",
      "epoch: 10 \t iteration 17 \t train loss: 0.442062\n",
      "epoch: 10 \t iteration 18 \t train loss: 0.496877\n",
      "epoch: 10 \t iteration 19 \t train loss: 0.428069\n",
      "epoch: 10 \t iteration 20 \t train loss: 0.383446\n",
      "epoch: 10 \t iteration 21 \t train loss: 0.366618\n",
      "epoch: 10 \t iteration 22 \t train loss: 0.401151\n",
      "epoch: 10 \t iteration 23 \t train loss: 0.441469\n",
      "epoch: 10 \t iteration 24 \t train loss: 0.419819\n",
      "epoch: 10 \t iteration 25 \t train loss: 0.358343\n",
      "epoch: 10 \t iteration 26 \t train loss: 0.376406\n",
      "epoch: 10 \t iteration 27 \t train loss: 0.439536\n",
      "epoch: 10 \t iteration 28 \t train loss: 0.423948\n",
      "epoch: 10 \t iteration 29 \t train loss: 0.374239\n",
      "epoch: 10 \t iteration 30 \t train loss: 0.476874\n",
      "epoch: 10 \t iteration 31 \t train loss: 0.406029\n",
      "epoch: 10 \t iteration 32 \t train loss: 0.370250\n",
      "epoch: 10 \t iteration 33 \t train loss: 0.373610\n",
      "epoch: 10 \t iteration 34 \t train loss: 0.365536\n",
      "epoch: 10 \t iteration 35 \t train loss: 0.328342\n",
      "epoch: 10 \t iteration 36 \t train loss: 0.414065\n",
      "epoch: 10 \t iteration 37 \t train loss: 0.394991\n",
      "epoch: 10 \t iteration 38 \t train loss: 0.363027\n",
      "epoch: 10 \t iteration 39 \t train loss: 0.393128\n",
      "epoch: 10 \t iteration 40 \t train loss: 0.427164\n",
      "epoch: 10 \t iteration 41 \t train loss: 0.359302\n",
      "epoch: 10 \t iteration 42 \t train loss: 0.385679\n",
      "epoch: 10 \t iteration 43 \t train loss: 0.442844\n",
      "epoch: 10 \t iteration 44 \t train loss: 0.350225\n",
      "epoch: 10 \t iteration 45 \t train loss: 0.391799\n",
      "epoch: 10 \t iteration 46 \t train loss: 0.395108\n",
      "epoch: 10 \t iteration 47 \t train loss: 0.335180\n",
      "epoch: 10 \t iteration 48 \t train loss: 0.415056\n",
      "epoch: 10 \t iteration 49 \t train loss: 0.401390\n",
      "epoch: 10 \t iteration 50 \t train loss: 0.529233\n",
      "epoch: 10 \t iteration 51 \t train loss: 0.362123\n",
      "epoch: 10 \t iteration 52 \t train loss: 0.413547\n",
      "epoch: 10 \t iteration 53 \t train loss: 0.375802\n",
      "epoch: 10 \t iteration 54 \t train loss: 0.386124\n",
      "epoch: 10 \t iteration 55 \t train loss: 0.408697\n",
      "epoch: 10 \t iteration 56 \t train loss: 0.397164\n",
      "epoch: 10 \t iteration 57 \t train loss: 0.385644\n",
      "epoch: 10 \t iteration 58 \t train loss: 0.410167\n",
      "epoch: 10 \t iteration 59 \t train loss: 0.405169\n",
      "epoch: 10 \t iteration 60 \t train loss: 0.360981\n",
      "epoch: 10 \t iteration 61 \t train loss: 0.364230\n",
      "epoch: 10 \t iteration 62 \t train loss: 0.376692\n",
      "epoch: 10 \t iteration 63 \t train loss: 0.394701\n",
      "epoch: 10 \t iteration 64 \t train loss: 0.349919\n",
      "epoch: 10 \t iteration 65 \t train loss: 0.412756\n",
      "epoch: 10 \t iteration 66 \t train loss: 0.448811\n",
      "epoch: 10 \t iteration 67 \t train loss: 0.386863\n",
      "epoch: 10 \t iteration 68 \t train loss: 0.418934\n",
      "epoch: 10 \t iteration 69 \t train loss: 0.417878\n",
      "epoch: 10 \t iteration 70 \t train loss: 0.380312\n",
      "epoch: 10 \t iteration 71 \t train loss: 0.363462\n",
      "epoch: 10 \t iteration 72 \t train loss: 0.345068\n",
      "epoch: 10 \t iteration 73 \t train loss: 0.399047\n",
      "epoch: 10 \t iteration 74 \t train loss: 0.404275\n",
      "epoch: 10 \t iteration 75 \t train loss: 0.368900\n",
      "epoch: 10 \t iteration 76 \t train loss: 0.432047\n",
      "epoch: 10 \t iteration 77 \t train loss: 0.377562\n",
      "epoch: 10 \t iteration 78 \t train loss: 0.405869\n",
      "epoch: 10 \t iteration 79 \t train loss: 0.459725\n",
      "epoch: 10 \t iteration 80 \t train loss: 0.439440\n",
      "epoch: 10 \t iteration 81 \t train loss: 0.397750\n",
      "epoch: 10 \t iteration 82 \t train loss: 0.438587\n",
      "epoch: 10 \t iteration 83 \t train loss: 0.411331\n",
      "epoch: 10 \t iteration 84 \t train loss: 0.404216\n",
      "epoch: 10 \t iteration 85 \t train loss: 0.451847\n",
      "epoch: 10 \t iteration 86 \t train loss: 0.434944\n",
      "epoch: 10 \t iteration 87 \t train loss: 0.389584\n",
      "epoch: 10 \t iteration 88 \t train loss: 0.415403\n",
      "epoch: 10 \t iteration 89 \t train loss: 0.465894\n",
      "epoch: 10 \t iteration 90 \t train loss: 0.382641\n",
      "epoch: 10 \t iteration 91 \t train loss: 0.377565\n",
      "epoch: 10 \t iteration 92 \t train loss: 0.402528\n",
      "epoch: 10 \t iteration 93 \t train loss: 0.402030\n",
      "epoch: 10 \t iteration 94 \t train loss: 0.350466\n",
      "epoch: 10 \t iteration 95 \t train loss: 0.340207\n",
      "epoch: 10 \t iteration 96 \t train loss: 0.369148\n",
      "epoch: 10 \t iteration 97 \t train loss: 0.375415\n",
      "epoch: 10 \t iteration 98 \t train loss: 0.433399\n",
      "epoch: 10 \t iteration 99 \t train loss: 0.416615\n",
      "epoch: 10 \t iteration 100 \t train loss: 0.391539\n",
      "epoch: 10 \t iteration 101 \t train loss: 0.373499\n",
      "epoch: 10 \t iteration 102 \t train loss: 0.388450\n",
      "epoch: 10 \t iteration 103 \t train loss: 0.387824\n",
      "epoch: 10 \t iteration 104 \t train loss: 0.418818\n",
      "epoch: 10 \t iteration 105 \t train loss: 0.388159\n",
      "epoch: 10 \t iteration 106 \t train loss: 0.366717\n",
      "epoch: 10 \t iteration 107 \t train loss: 0.401747\n",
      "epoch: 10 \t iteration 108 \t train loss: 0.425710\n",
      "epoch: 10 \t iteration 109 \t train loss: 0.499508\n",
      "epoch: 10 \t iteration 110 \t train loss: 0.405965\n",
      "epoch: 10 \t iteration 111 \t train loss: 0.402442\n",
      "epoch: 10 \t iteration 112 \t train loss: 0.364797\n",
      "epoch: 10 \t iteration 113 \t train loss: 0.401245\n",
      "epoch: 10 \t iteration 114 \t train loss: 0.407673\n",
      "epoch: 10 \t iteration 115 \t train loss: 0.337052\n",
      "epoch: 10 \t iteration 116 \t train loss: 0.323119\n",
      "epoch: 10 \t iteration 117 \t train loss: 0.458232\n",
      "epoch: 10 \t iteration 118 \t train loss: 0.422850\n",
      "epoch: 10 \t iteration 119 \t train loss: 0.447916\n",
      "epoch: 10 \t iteration 120 \t train loss: 0.370308\n",
      "epoch: 10 \t iteration 121 \t train loss: 0.405918\n",
      "epoch: 10 \t iteration 122 \t train loss: 0.398998\n",
      "epoch: 10 \t iteration 123 \t train loss: 0.343592\n",
      "epoch: 10 \t iteration 124 \t train loss: 0.395773\n",
      "epoch: 10 \t iteration 125 \t train loss: 0.471398\n",
      "epoch: 10 \t iteration 126 \t train loss: 0.408689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 \t iteration 127 \t train loss: 0.388474\n",
      "epoch: 10 \t iteration 128 \t train loss: 0.435204\n",
      "epoch: 10 \t iteration 129 \t train loss: 0.462934\n",
      "epoch: 10 \t iteration 130 \t train loss: 0.408540\n",
      "epoch: 10 \t iteration 131 \t train loss: 0.403780\n",
      "epoch: 10 \t iteration 132 \t train loss: 0.423980\n",
      "epoch: 10 \t iteration 133 \t train loss: 0.339651\n",
      "epoch: 10 \t iteration 134 \t train loss: 0.372442\n",
      "epoch: 10 \t iteration 135 \t train loss: 0.404456\n",
      "epoch: 10 \t iteration 136 \t train loss: 0.410687\n",
      "epoch: 10 \t iteration 137 \t train loss: 0.432140\n",
      "epoch: 10 \t iteration 138 \t train loss: 0.340678\n",
      "epoch: 10 \t iteration 139 \t train loss: 0.434760\n",
      "epoch: 10 \t iteration 140 \t train loss: 0.413772\n",
      "epoch: 10 \t iteration 141 \t train loss: 0.389911\n",
      "epoch: 10 \t iteration 142 \t train loss: 0.406896\n",
      "epoch: 10 \t iteration 143 \t train loss: 0.433619\n",
      "epoch: 10 \t iteration 144 \t train loss: 0.427150\n",
      "epoch: 10 \t iteration 145 \t train loss: 0.432451\n",
      "epoch: 10 \t iteration 146 \t train loss: 0.373715\n",
      "epoch: 10 \t iteration 147 \t train loss: 0.347001\n",
      "epoch: 10 \t iteration 148 \t train loss: 0.369952\n",
      "epoch: 10 \t iteration 149 \t train loss: 0.441376\n",
      "epoch: 10 \t iteration 150 \t train loss: 0.420589\n",
      "epoch: 10 \t iteration 151 \t train loss: 0.380675\n",
      "epoch: 10 \t iteration 152 \t train loss: 0.350193\n",
      "epoch: 10 \t iteration 153 \t train loss: 0.378548\n",
      "epoch: 10 \t iteration 154 \t train loss: 0.375114\n",
      "epoch: 10 \t iteration 155 \t train loss: 0.405339\n",
      "epoch: 10 \t iteration 156 \t train loss: 0.460421\n",
      "epoch: 10 \t iteration 157 \t train loss: 0.384952\n",
      "epoch: 10 \t iteration 158 \t train loss: 0.475307\n",
      "epoch: 10 \t iteration 159 \t train loss: 0.439132\n",
      "epoch: 10 \t iteration 160 \t train loss: 0.381203\n",
      "epoch: 10 \t iteration 161 \t train loss: 0.441490\n",
      "epoch: 10 \t iteration 162 \t train loss: 0.412143\n",
      "epoch: 10 \t iteration 163 \t train loss: 0.370371\n",
      "epoch: 10 \t iteration 164 \t train loss: 0.372607\n",
      "epoch: 10 \t iteration 165 \t train loss: 0.363936\n",
      "epoch: 10 \t iteration 166 \t train loss: 0.343952\n",
      "epoch: 10 \t iteration 167 \t train loss: 0.382972\n",
      "epoch: 10 \t iteration 168 \t train loss: 0.461780\n",
      "epoch: 10 \t iteration 169 \t train loss: 0.356003\n",
      "epoch: 10 \t iteration 170 \t train loss: 0.361258\n",
      "epoch: 10 \t iteration 171 \t train loss: 0.433391\n",
      "epoch: 10 \t iteration 172 \t train loss: 0.395212\n",
      "epoch: 10 \t iteration 173 \t train loss: 0.336689\n",
      "epoch: 10 \t iteration 174 \t train loss: 0.395997\n",
      "epoch: 10 \t iteration 175 \t train loss: 0.374874\n",
      "epoch: 10 \t iteration 176 \t train loss: 0.406551\n",
      "epoch: 10 \t iteration 177 \t train loss: 0.377013\n",
      "epoch: 10 \t iteration 178 \t train loss: 0.350792\n",
      "epoch: 10 \t iteration 179 \t train loss: 0.432746\n",
      "epoch: 10 \t iteration 180 \t train loss: 0.355718\n",
      "epoch: 10 \t iteration 181 \t train loss: 0.363811\n",
      "epoch: 10 \t iteration 182 \t train loss: 0.402172\n",
      "epoch: 10 \t iteration 183 \t train loss: 0.323880\n",
      "epoch: 10 \t iteration 184 \t train loss: 0.384157\n",
      "epoch: 10 \t iteration 185 \t train loss: 0.411293\n",
      "epoch: 10 \t iteration 186 \t train loss: 0.359785\n",
      "epoch: 10 \t iteration 187 \t train loss: 0.343631\n",
      "epoch: 10 \t iteration 188 \t train loss: 0.371242\n",
      "epoch: 10 \t iteration 189 \t train loss: 0.401256\n",
      "epoch: 10 \t iteration 190 \t train loss: 0.439867\n",
      "epoch: 10 \t iteration 191 \t train loss: 0.347738\n",
      "epoch: 10 \t iteration 192 \t train loss: 0.308678\n",
      "epoch: 10 \t iteration 193 \t train loss: 0.327930\n",
      "epoch: 10 \t iteration 194 \t train loss: 0.343113\n",
      "epoch: 10 \t iteration 195 \t train loss: 0.282787\n",
      "epoch: 10 \t iteration 196 \t train loss: 0.256599\n",
      "epoch: 10 \t iteration 197 \t train loss: 0.436429\n",
      "epoch: 10 \t iteration 198 \t train loss: 0.381323\n",
      "epoch: 10 \t iteration 199 \t train loss: 0.331976\n",
      "epoch:10 \t mean train loss: 0.395945 \t mean train acc: 0.854380\n",
      "epoch: 10 \t iteration 0 \t eval loss: 0.371875\n",
      "epoch: 10 \t iteration 1 \t eval loss: 0.347176\n",
      "epoch: 10 \t iteration 2 \t eval loss: 0.436979\n",
      "epoch: 10 \t iteration 3 \t eval loss: 0.393397\n",
      "epoch: 10 \t iteration 4 \t eval loss: 0.451578\n",
      "epoch: 10 \t iteration 5 \t eval loss: 0.427861\n",
      "epoch: 10 \t iteration 6 \t eval loss: 0.361593\n",
      "epoch: 10 \t iteration 7 \t eval loss: 0.369623\n",
      "epoch: 10 \t iteration 8 \t eval loss: 0.359255\n",
      "epoch: 10 \t iteration 9 \t eval loss: 0.367092\n",
      "epoch: 10 \t iteration 10 \t eval loss: 0.351210\n",
      "epoch: 10 \t iteration 11 \t eval loss: 0.378240\n",
      "epoch: 10 \t iteration 12 \t eval loss: 0.388748\n",
      "epoch: 10 \t iteration 13 \t eval loss: 0.363621\n",
      "epoch: 10 \t iteration 14 \t eval loss: 0.405679\n",
      "epoch: 10 \t iteration 15 \t eval loss: 0.362227\n",
      "epoch: 10 \t iteration 16 \t eval loss: 0.406488\n",
      "epoch: 10 \t iteration 17 \t eval loss: 0.389794\n",
      "epoch: 10 \t iteration 18 \t eval loss: 0.367406\n",
      "epoch: 10 \t iteration 19 \t eval loss: 0.391449\n",
      "epoch: 10 \t iteration 20 \t eval loss: 0.395048\n",
      "epoch: 10 \t iteration 21 \t eval loss: 0.356793\n",
      "epoch: 10 \t iteration 22 \t eval loss: 0.388263\n",
      "epoch: 10 \t iteration 23 \t eval loss: 0.363301\n",
      "epoch: 10 \t iteration 24 \t eval loss: 0.358665\n",
      "epoch: 10 \t iteration 25 \t eval loss: 0.394036\n",
      "epoch: 10 \t iteration 26 \t eval loss: 0.304878\n",
      "epoch: 10 \t iteration 27 \t eval loss: 0.460574\n",
      "epoch: 10 \t iteration 28 \t eval loss: 0.424378\n",
      "epoch: 10 \t iteration 29 \t eval loss: 0.423400\n",
      "epoch: 10 \t iteration 30 \t eval loss: 0.393473\n",
      "epoch: 10 \t iteration 31 \t eval loss: 0.432212\n",
      "epoch: 10 \t iteration 32 \t eval loss: 0.421121\n",
      "epoch: 10 \t iteration 33 \t eval loss: 0.414905\n",
      "epoch: 10 \t iteration 34 \t eval loss: 0.460973\n",
      "epoch: 10 \t iteration 35 \t eval loss: 0.434394\n",
      "epoch: 10 \t iteration 36 \t eval loss: 0.350407\n",
      "epoch: 10 \t iteration 37 \t eval loss: 0.392266\n",
      "epoch: 10 \t iteration 38 \t eval loss: 0.381454\n",
      "epoch: 10 \t iteration 39 \t eval loss: 0.335733\n",
      "epoch:10 \t mean eval loss: 0.389439 \t mean eval acc: 0.855300\n",
      "epoch: 11 \t iteration 0 \t train loss: 0.394352\n",
      "epoch: 11 \t iteration 1 \t train loss: 0.345523\n",
      "epoch: 11 \t iteration 2 \t train loss: 0.363847\n",
      "epoch: 11 \t iteration 3 \t train loss: 0.372031\n",
      "epoch: 11 \t iteration 4 \t train loss: 0.379639\n",
      "epoch: 11 \t iteration 5 \t train loss: 0.367247\n",
      "epoch: 11 \t iteration 6 \t train loss: 0.483260\n",
      "epoch: 11 \t iteration 7 \t train loss: 0.412244\n",
      "epoch: 11 \t iteration 8 \t train loss: 0.376735\n",
      "epoch: 11 \t iteration 9 \t train loss: 0.434083\n",
      "epoch: 11 \t iteration 10 \t train loss: 0.421015\n",
      "epoch: 11 \t iteration 11 \t train loss: 0.423826\n",
      "epoch: 11 \t iteration 12 \t train loss: 0.452179\n",
      "epoch: 11 \t iteration 13 \t train loss: 0.368773\n",
      "epoch: 11 \t iteration 14 \t train loss: 0.396834\n",
      "epoch: 11 \t iteration 15 \t train loss: 0.433669\n",
      "epoch: 11 \t iteration 16 \t train loss: 0.472190\n",
      "epoch: 11 \t iteration 17 \t train loss: 0.441087\n",
      "epoch: 11 \t iteration 18 \t train loss: 0.495935\n",
      "epoch: 11 \t iteration 19 \t train loss: 0.427417\n",
      "epoch: 11 \t iteration 20 \t train loss: 0.382716\n",
      "epoch: 11 \t iteration 21 \t train loss: 0.365745\n",
      "epoch: 11 \t iteration 22 \t train loss: 0.400355\n",
      "epoch: 11 \t iteration 23 \t train loss: 0.440222\n",
      "epoch: 11 \t iteration 24 \t train loss: 0.418515\n",
      "epoch: 11 \t iteration 25 \t train loss: 0.357385\n",
      "epoch: 11 \t iteration 26 \t train loss: 0.376002\n",
      "epoch: 11 \t iteration 27 \t train loss: 0.438762\n",
      "epoch: 11 \t iteration 28 \t train loss: 0.422799\n",
      "epoch: 11 \t iteration 29 \t train loss: 0.373418\n",
      "epoch: 11 \t iteration 30 \t train loss: 0.476129\n",
      "epoch: 11 \t iteration 31 \t train loss: 0.405220\n",
      "epoch: 11 \t iteration 32 \t train loss: 0.369415\n",
      "epoch: 11 \t iteration 33 \t train loss: 0.372796\n",
      "epoch: 11 \t iteration 34 \t train loss: 0.364470\n",
      "epoch: 11 \t iteration 35 \t train loss: 0.327348\n",
      "epoch: 11 \t iteration 36 \t train loss: 0.412790\n",
      "epoch: 11 \t iteration 37 \t train loss: 0.394149\n",
      "epoch: 11 \t iteration 38 \t train loss: 0.362232\n",
      "epoch: 11 \t iteration 39 \t train loss: 0.392058\n",
      "epoch: 11 \t iteration 40 \t train loss: 0.426333\n",
      "epoch: 11 \t iteration 41 \t train loss: 0.358265\n",
      "epoch: 11 \t iteration 42 \t train loss: 0.384896\n",
      "epoch: 11 \t iteration 43 \t train loss: 0.441752\n",
      "epoch: 11 \t iteration 44 \t train loss: 0.349391\n",
      "epoch: 11 \t iteration 45 \t train loss: 0.390968\n",
      "epoch: 11 \t iteration 46 \t train loss: 0.394074\n",
      "epoch: 11 \t iteration 47 \t train loss: 0.334689\n",
      "epoch: 11 \t iteration 48 \t train loss: 0.413893\n",
      "epoch: 11 \t iteration 49 \t train loss: 0.400975\n",
      "epoch: 11 \t iteration 50 \t train loss: 0.528323\n",
      "epoch: 11 \t iteration 51 \t train loss: 0.361391\n",
      "epoch: 11 \t iteration 52 \t train loss: 0.412728\n",
      "epoch: 11 \t iteration 53 \t train loss: 0.374620\n",
      "epoch: 11 \t iteration 54 \t train loss: 0.384975\n",
      "epoch: 11 \t iteration 55 \t train loss: 0.408258\n",
      "epoch: 11 \t iteration 56 \t train loss: 0.396388\n",
      "epoch: 11 \t iteration 57 \t train loss: 0.384720\n",
      "epoch: 11 \t iteration 58 \t train loss: 0.409365\n",
      "epoch: 11 \t iteration 59 \t train loss: 0.403954\n",
      "epoch: 11 \t iteration 60 \t train loss: 0.359975\n",
      "epoch: 11 \t iteration 61 \t train loss: 0.363510\n",
      "epoch: 11 \t iteration 62 \t train loss: 0.376176\n",
      "epoch: 11 \t iteration 63 \t train loss: 0.394301\n",
      "epoch: 11 \t iteration 64 \t train loss: 0.348911\n",
      "epoch: 11 \t iteration 65 \t train loss: 0.411493\n",
      "epoch: 11 \t iteration 66 \t train loss: 0.448048\n",
      "epoch: 11 \t iteration 67 \t train loss: 0.385866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 \t iteration 68 \t train loss: 0.418088\n",
      "epoch: 11 \t iteration 69 \t train loss: 0.417021\n",
      "epoch: 11 \t iteration 70 \t train loss: 0.379297\n",
      "epoch: 11 \t iteration 71 \t train loss: 0.362764\n",
      "epoch: 11 \t iteration 72 \t train loss: 0.344541\n",
      "epoch: 11 \t iteration 73 \t train loss: 0.398087\n",
      "epoch: 11 \t iteration 74 \t train loss: 0.403575\n",
      "epoch: 11 \t iteration 75 \t train loss: 0.368477\n",
      "epoch: 11 \t iteration 76 \t train loss: 0.431152\n",
      "epoch: 11 \t iteration 77 \t train loss: 0.377092\n",
      "epoch: 11 \t iteration 78 \t train loss: 0.404900\n",
      "epoch: 11 \t iteration 79 \t train loss: 0.458941\n",
      "epoch: 11 \t iteration 80 \t train loss: 0.438224\n",
      "epoch: 11 \t iteration 81 \t train loss: 0.396943\n",
      "epoch: 11 \t iteration 82 \t train loss: 0.438030\n",
      "epoch: 11 \t iteration 83 \t train loss: 0.410643\n",
      "epoch: 11 \t iteration 84 \t train loss: 0.403558\n",
      "epoch: 11 \t iteration 85 \t train loss: 0.450529\n",
      "epoch: 11 \t iteration 86 \t train loss: 0.433927\n",
      "epoch: 11 \t iteration 87 \t train loss: 0.388723\n",
      "epoch: 11 \t iteration 88 \t train loss: 0.414055\n",
      "epoch: 11 \t iteration 89 \t train loss: 0.464843\n",
      "epoch: 11 \t iteration 90 \t train loss: 0.381537\n",
      "epoch: 11 \t iteration 91 \t train loss: 0.376741\n",
      "epoch: 11 \t iteration 92 \t train loss: 0.400745\n",
      "epoch: 11 \t iteration 93 \t train loss: 0.401327\n",
      "epoch: 11 \t iteration 94 \t train loss: 0.349585\n",
      "epoch: 11 \t iteration 95 \t train loss: 0.339653\n",
      "epoch: 11 \t iteration 96 \t train loss: 0.368274\n",
      "epoch: 11 \t iteration 97 \t train loss: 0.374591\n",
      "epoch: 11 \t iteration 98 \t train loss: 0.432330\n",
      "epoch: 11 \t iteration 99 \t train loss: 0.415481\n",
      "epoch: 11 \t iteration 100 \t train loss: 0.390840\n",
      "epoch: 11 \t iteration 101 \t train loss: 0.372527\n",
      "epoch: 11 \t iteration 102 \t train loss: 0.387840\n",
      "epoch: 11 \t iteration 103 \t train loss: 0.386707\n",
      "epoch: 11 \t iteration 104 \t train loss: 0.417907\n",
      "epoch: 11 \t iteration 105 \t train loss: 0.386882\n",
      "epoch: 11 \t iteration 106 \t train loss: 0.366321\n",
      "epoch: 11 \t iteration 107 \t train loss: 0.401235\n",
      "epoch: 11 \t iteration 108 \t train loss: 0.425037\n",
      "epoch: 11 \t iteration 109 \t train loss: 0.499554\n",
      "epoch: 11 \t iteration 110 \t train loss: 0.404909\n",
      "epoch: 11 \t iteration 111 \t train loss: 0.401770\n",
      "epoch: 11 \t iteration 112 \t train loss: 0.363693\n",
      "epoch: 11 \t iteration 113 \t train loss: 0.400280\n",
      "epoch: 11 \t iteration 114 \t train loss: 0.406690\n",
      "epoch: 11 \t iteration 115 \t train loss: 0.336248\n",
      "epoch: 11 \t iteration 116 \t train loss: 0.322307\n",
      "epoch: 11 \t iteration 117 \t train loss: 0.457164\n",
      "epoch: 11 \t iteration 118 \t train loss: 0.421786\n",
      "epoch: 11 \t iteration 119 \t train loss: 0.447049\n",
      "epoch: 11 \t iteration 120 \t train loss: 0.369380\n",
      "epoch: 11 \t iteration 121 \t train loss: 0.405338\n",
      "epoch: 11 \t iteration 122 \t train loss: 0.398293\n",
      "epoch: 11 \t iteration 123 \t train loss: 0.342431\n",
      "epoch: 11 \t iteration 124 \t train loss: 0.394869\n",
      "epoch: 11 \t iteration 125 \t train loss: 0.470351\n",
      "epoch: 11 \t iteration 126 \t train loss: 0.407867\n",
      "epoch: 11 \t iteration 127 \t train loss: 0.387537\n",
      "epoch: 11 \t iteration 128 \t train loss: 0.434645\n",
      "epoch: 11 \t iteration 129 \t train loss: 0.462061\n",
      "epoch: 11 \t iteration 130 \t train loss: 0.407937\n",
      "epoch: 11 \t iteration 131 \t train loss: 0.402954\n",
      "epoch: 11 \t iteration 132 \t train loss: 0.423333\n",
      "epoch: 11 \t iteration 133 \t train loss: 0.339157\n",
      "epoch: 11 \t iteration 134 \t train loss: 0.372026\n",
      "epoch: 11 \t iteration 135 \t train loss: 0.403765\n",
      "epoch: 11 \t iteration 136 \t train loss: 0.410154\n",
      "epoch: 11 \t iteration 137 \t train loss: 0.431294\n",
      "epoch: 11 \t iteration 138 \t train loss: 0.339902\n",
      "epoch: 11 \t iteration 139 \t train loss: 0.434394\n",
      "epoch: 11 \t iteration 140 \t train loss: 0.412854\n",
      "epoch: 11 \t iteration 141 \t train loss: 0.389108\n",
      "epoch: 11 \t iteration 142 \t train loss: 0.406418\n",
      "epoch: 11 \t iteration 143 \t train loss: 0.432843\n",
      "epoch: 11 \t iteration 144 \t train loss: 0.426350\n",
      "epoch: 11 \t iteration 145 \t train loss: 0.431654\n",
      "epoch: 11 \t iteration 146 \t train loss: 0.372968\n",
      "epoch: 11 \t iteration 147 \t train loss: 0.346133\n",
      "epoch: 11 \t iteration 148 \t train loss: 0.368822\n",
      "epoch: 11 \t iteration 149 \t train loss: 0.440597\n",
      "epoch: 11 \t iteration 150 \t train loss: 0.419791\n",
      "epoch: 11 \t iteration 151 \t train loss: 0.379810\n",
      "epoch: 11 \t iteration 152 \t train loss: 0.349369\n",
      "epoch: 11 \t iteration 153 \t train loss: 0.377871\n",
      "epoch: 11 \t iteration 154 \t train loss: 0.374307\n",
      "epoch: 11 \t iteration 155 \t train loss: 0.404326\n",
      "epoch: 11 \t iteration 156 \t train loss: 0.459241\n",
      "epoch: 11 \t iteration 157 \t train loss: 0.384208\n",
      "epoch: 11 \t iteration 158 \t train loss: 0.474366\n",
      "epoch: 11 \t iteration 159 \t train loss: 0.438307\n",
      "epoch: 11 \t iteration 160 \t train loss: 0.379995\n",
      "epoch: 11 \t iteration 161 \t train loss: 0.441180\n",
      "epoch: 11 \t iteration 162 \t train loss: 0.411300\n",
      "epoch: 11 \t iteration 163 \t train loss: 0.369947\n",
      "epoch: 11 \t iteration 164 \t train loss: 0.371998\n",
      "epoch: 11 \t iteration 165 \t train loss: 0.363278\n",
      "epoch: 11 \t iteration 166 \t train loss: 0.343115\n",
      "epoch: 11 \t iteration 167 \t train loss: 0.382591\n",
      "epoch: 11 \t iteration 168 \t train loss: 0.460659\n",
      "epoch: 11 \t iteration 169 \t train loss: 0.355265\n",
      "epoch: 11 \t iteration 170 \t train loss: 0.360509\n",
      "epoch: 11 \t iteration 171 \t train loss: 0.432604\n",
      "epoch: 11 \t iteration 172 \t train loss: 0.394494\n",
      "epoch: 11 \t iteration 173 \t train loss: 0.335600\n",
      "epoch: 11 \t iteration 174 \t train loss: 0.395385\n",
      "epoch: 11 \t iteration 175 \t train loss: 0.373744\n",
      "epoch: 11 \t iteration 176 \t train loss: 0.405542\n",
      "epoch: 11 \t iteration 177 \t train loss: 0.376147\n",
      "epoch: 11 \t iteration 178 \t train loss: 0.349950\n",
      "epoch: 11 \t iteration 179 \t train loss: 0.431693\n",
      "epoch: 11 \t iteration 180 \t train loss: 0.355134\n",
      "epoch: 11 \t iteration 181 \t train loss: 0.362888\n",
      "epoch: 11 \t iteration 182 \t train loss: 0.401419\n",
      "epoch: 11 \t iteration 183 \t train loss: 0.323248\n",
      "epoch: 11 \t iteration 184 \t train loss: 0.383607\n",
      "epoch: 11 \t iteration 185 \t train loss: 0.410453\n",
      "epoch: 11 \t iteration 186 \t train loss: 0.358732\n",
      "epoch: 11 \t iteration 187 \t train loss: 0.342876\n",
      "epoch: 11 \t iteration 188 \t train loss: 0.370610\n",
      "epoch: 11 \t iteration 189 \t train loss: 0.400748\n",
      "epoch: 11 \t iteration 190 \t train loss: 0.439453\n",
      "epoch: 11 \t iteration 191 \t train loss: 0.347124\n",
      "epoch: 11 \t iteration 192 \t train loss: 0.308099\n",
      "epoch: 11 \t iteration 193 \t train loss: 0.327068\n",
      "epoch: 11 \t iteration 194 \t train loss: 0.342416\n",
      "epoch: 11 \t iteration 195 \t train loss: 0.282541\n",
      "epoch: 11 \t iteration 196 \t train loss: 0.255915\n",
      "epoch: 11 \t iteration 197 \t train loss: 0.436195\n",
      "epoch: 11 \t iteration 198 \t train loss: 0.380801\n",
      "epoch: 11 \t iteration 199 \t train loss: 0.331079\n",
      "epoch:11 \t mean train loss: 0.395127 \t mean train acc: 0.854260\n",
      "epoch: 11 \t iteration 0 \t eval loss: 0.371262\n",
      "epoch: 11 \t iteration 1 \t eval loss: 0.346671\n",
      "epoch: 11 \t iteration 2 \t eval loss: 0.436363\n",
      "epoch: 11 \t iteration 3 \t eval loss: 0.392703\n",
      "epoch: 11 \t iteration 4 \t eval loss: 0.451168\n",
      "epoch: 11 \t iteration 5 \t eval loss: 0.427789\n",
      "epoch: 11 \t iteration 6 \t eval loss: 0.360877\n",
      "epoch: 11 \t iteration 7 \t eval loss: 0.368826\n",
      "epoch: 11 \t iteration 8 \t eval loss: 0.359012\n",
      "epoch: 11 \t iteration 9 \t eval loss: 0.366355\n",
      "epoch: 11 \t iteration 10 \t eval loss: 0.350441\n",
      "epoch: 11 \t iteration 11 \t eval loss: 0.377731\n",
      "epoch: 11 \t iteration 12 \t eval loss: 0.388084\n",
      "epoch: 11 \t iteration 13 \t eval loss: 0.362662\n",
      "epoch: 11 \t iteration 14 \t eval loss: 0.404663\n",
      "epoch: 11 \t iteration 15 \t eval loss: 0.361472\n",
      "epoch: 11 \t iteration 16 \t eval loss: 0.406094\n",
      "epoch: 11 \t iteration 17 \t eval loss: 0.388994\n",
      "epoch: 11 \t iteration 18 \t eval loss: 0.366601\n",
      "epoch: 11 \t iteration 19 \t eval loss: 0.390994\n",
      "epoch: 11 \t iteration 20 \t eval loss: 0.394560\n",
      "epoch: 11 \t iteration 21 \t eval loss: 0.356263\n",
      "epoch: 11 \t iteration 22 \t eval loss: 0.387490\n",
      "epoch: 11 \t iteration 23 \t eval loss: 0.362604\n",
      "epoch: 11 \t iteration 24 \t eval loss: 0.358107\n",
      "epoch: 11 \t iteration 25 \t eval loss: 0.393540\n",
      "epoch: 11 \t iteration 26 \t eval loss: 0.304379\n",
      "epoch: 11 \t iteration 27 \t eval loss: 0.460516\n",
      "epoch: 11 \t iteration 28 \t eval loss: 0.423576\n",
      "epoch: 11 \t iteration 29 \t eval loss: 0.422628\n",
      "epoch: 11 \t iteration 30 \t eval loss: 0.392527\n",
      "epoch: 11 \t iteration 31 \t eval loss: 0.431631\n",
      "epoch: 11 \t iteration 32 \t eval loss: 0.420520\n",
      "epoch: 11 \t iteration 33 \t eval loss: 0.414501\n",
      "epoch: 11 \t iteration 34 \t eval loss: 0.460701\n",
      "epoch: 11 \t iteration 35 \t eval loss: 0.433597\n",
      "epoch: 11 \t iteration 36 \t eval loss: 0.349794\n",
      "epoch: 11 \t iteration 37 \t eval loss: 0.391719\n",
      "epoch: 11 \t iteration 38 \t eval loss: 0.380987\n",
      "epoch: 11 \t iteration 39 \t eval loss: 0.334914\n",
      "epoch:11 \t mean eval loss: 0.388833 \t mean eval acc: 0.855100\n",
      "epoch: 12 \t iteration 0 \t train loss: 0.393789\n",
      "epoch: 12 \t iteration 1 \t train loss: 0.344893\n",
      "epoch: 12 \t iteration 2 \t train loss: 0.363167\n",
      "epoch: 12 \t iteration 3 \t train loss: 0.371217\n",
      "epoch: 12 \t iteration 4 \t train loss: 0.379017\n",
      "epoch: 12 \t iteration 5 \t train loss: 0.366815\n",
      "epoch: 12 \t iteration 6 \t train loss: 0.482716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 \t iteration 7 \t train loss: 0.411813\n",
      "epoch: 12 \t iteration 8 \t train loss: 0.376417\n",
      "epoch: 12 \t iteration 9 \t train loss: 0.433402\n",
      "epoch: 12 \t iteration 10 \t train loss: 0.420306\n",
      "epoch: 12 \t iteration 11 \t train loss: 0.423086\n",
      "epoch: 12 \t iteration 12 \t train loss: 0.451553\n",
      "epoch: 12 \t iteration 13 \t train loss: 0.367919\n",
      "epoch: 12 \t iteration 14 \t train loss: 0.396247\n",
      "epoch: 12 \t iteration 15 \t train loss: 0.432557\n",
      "epoch: 12 \t iteration 16 \t train loss: 0.471409\n",
      "epoch: 12 \t iteration 17 \t train loss: 0.440256\n",
      "epoch: 12 \t iteration 18 \t train loss: 0.495128\n",
      "epoch: 12 \t iteration 19 \t train loss: 0.426861\n",
      "epoch: 12 \t iteration 20 \t train loss: 0.382099\n",
      "epoch: 12 \t iteration 21 \t train loss: 0.364984\n",
      "epoch: 12 \t iteration 22 \t train loss: 0.399678\n",
      "epoch: 12 \t iteration 23 \t train loss: 0.439112\n",
      "epoch: 12 \t iteration 24 \t train loss: 0.417388\n",
      "epoch: 12 \t iteration 25 \t train loss: 0.356563\n",
      "epoch: 12 \t iteration 26 \t train loss: 0.375664\n",
      "epoch: 12 \t iteration 27 \t train loss: 0.438101\n",
      "epoch: 12 \t iteration 28 \t train loss: 0.421810\n",
      "epoch: 12 \t iteration 29 \t train loss: 0.372705\n",
      "epoch: 12 \t iteration 30 \t train loss: 0.475517\n",
      "epoch: 12 \t iteration 31 \t train loss: 0.404517\n",
      "epoch: 12 \t iteration 32 \t train loss: 0.368686\n",
      "epoch: 12 \t iteration 33 \t train loss: 0.372100\n",
      "epoch: 12 \t iteration 34 \t train loss: 0.363554\n",
      "epoch: 12 \t iteration 35 \t train loss: 0.326495\n",
      "epoch: 12 \t iteration 36 \t train loss: 0.411678\n",
      "epoch: 12 \t iteration 37 \t train loss: 0.393422\n",
      "epoch: 12 \t iteration 38 \t train loss: 0.361542\n",
      "epoch: 12 \t iteration 39 \t train loss: 0.391111\n",
      "epoch: 12 \t iteration 40 \t train loss: 0.425614\n",
      "epoch: 12 \t iteration 41 \t train loss: 0.357374\n",
      "epoch: 12 \t iteration 42 \t train loss: 0.384222\n",
      "epoch: 12 \t iteration 43 \t train loss: 0.440806\n",
      "epoch: 12 \t iteration 44 \t train loss: 0.348679\n",
      "epoch: 12 \t iteration 45 \t train loss: 0.390270\n",
      "epoch: 12 \t iteration 46 \t train loss: 0.393159\n",
      "epoch: 12 \t iteration 47 \t train loss: 0.334249\n",
      "epoch: 12 \t iteration 48 \t train loss: 0.412857\n",
      "epoch: 12 \t iteration 49 \t train loss: 0.400659\n",
      "epoch: 12 \t iteration 50 \t train loss: 0.527500\n",
      "epoch: 12 \t iteration 51 \t train loss: 0.360778\n",
      "epoch: 12 \t iteration 52 \t train loss: 0.412017\n",
      "epoch: 12 \t iteration 53 \t train loss: 0.373584\n",
      "epoch: 12 \t iteration 54 \t train loss: 0.383980\n",
      "epoch: 12 \t iteration 55 \t train loss: 0.407917\n",
      "epoch: 12 \t iteration 56 \t train loss: 0.395723\n",
      "epoch: 12 \t iteration 57 \t train loss: 0.383929\n",
      "epoch: 12 \t iteration 58 \t train loss: 0.408685\n",
      "epoch: 12 \t iteration 59 \t train loss: 0.402916\n",
      "epoch: 12 \t iteration 60 \t train loss: 0.359108\n",
      "epoch: 12 \t iteration 61 \t train loss: 0.362874\n",
      "epoch: 12 \t iteration 62 \t train loss: 0.375749\n",
      "epoch: 12 \t iteration 63 \t train loss: 0.394000\n",
      "epoch: 12 \t iteration 64 \t train loss: 0.348049\n",
      "epoch: 12 \t iteration 65 \t train loss: 0.410400\n",
      "epoch: 12 \t iteration 66 \t train loss: 0.447381\n",
      "epoch: 12 \t iteration 67 \t train loss: 0.384999\n",
      "epoch: 12 \t iteration 68 \t train loss: 0.417365\n",
      "epoch: 12 \t iteration 69 \t train loss: 0.416291\n",
      "epoch: 12 \t iteration 70 \t train loss: 0.378418\n",
      "epoch: 12 \t iteration 71 \t train loss: 0.362156\n",
      "epoch: 12 \t iteration 72 \t train loss: 0.344104\n",
      "epoch: 12 \t iteration 73 \t train loss: 0.397253\n",
      "epoch: 12 \t iteration 74 \t train loss: 0.402993\n",
      "epoch: 12 \t iteration 75 \t train loss: 0.368146\n",
      "epoch: 12 \t iteration 76 \t train loss: 0.430384\n",
      "epoch: 12 \t iteration 77 \t train loss: 0.376728\n",
      "epoch: 12 \t iteration 78 \t train loss: 0.404048\n",
      "epoch: 12 \t iteration 79 \t train loss: 0.458266\n",
      "epoch: 12 \t iteration 80 \t train loss: 0.437176\n",
      "epoch: 12 \t iteration 81 \t train loss: 0.396243\n",
      "epoch: 12 \t iteration 82 \t train loss: 0.437570\n",
      "epoch: 12 \t iteration 83 \t train loss: 0.410064\n",
      "epoch: 12 \t iteration 84 \t train loss: 0.402987\n",
      "epoch: 12 \t iteration 85 \t train loss: 0.449378\n",
      "epoch: 12 \t iteration 86 \t train loss: 0.433049\n",
      "epoch: 12 \t iteration 87 \t train loss: 0.387985\n",
      "epoch: 12 \t iteration 88 \t train loss: 0.412876\n",
      "epoch: 12 \t iteration 89 \t train loss: 0.463936\n",
      "epoch: 12 \t iteration 90 \t train loss: 0.380578\n",
      "epoch: 12 \t iteration 91 \t train loss: 0.376038\n",
      "epoch: 12 \t iteration 92 \t train loss: 0.399194\n",
      "epoch: 12 \t iteration 93 \t train loss: 0.400718\n",
      "epoch: 12 \t iteration 94 \t train loss: 0.348831\n",
      "epoch: 12 \t iteration 95 \t train loss: 0.339175\n",
      "epoch: 12 \t iteration 96 \t train loss: 0.367529\n",
      "epoch: 12 \t iteration 97 \t train loss: 0.373876\n",
      "epoch: 12 \t iteration 98 \t train loss: 0.431405\n",
      "epoch: 12 \t iteration 99 \t train loss: 0.414511\n",
      "epoch: 12 \t iteration 100 \t train loss: 0.390256\n",
      "epoch: 12 \t iteration 101 \t train loss: 0.371708\n",
      "epoch: 12 \t iteration 102 \t train loss: 0.387325\n",
      "epoch: 12 \t iteration 103 \t train loss: 0.385723\n",
      "epoch: 12 \t iteration 104 \t train loss: 0.417117\n",
      "epoch: 12 \t iteration 105 \t train loss: 0.385779\n",
      "epoch: 12 \t iteration 106 \t train loss: 0.365989\n",
      "epoch: 12 \t iteration 107 \t train loss: 0.400785\n",
      "epoch: 12 \t iteration 108 \t train loss: 0.424467\n",
      "epoch: 12 \t iteration 109 \t train loss: 0.499626\n",
      "epoch: 12 \t iteration 110 \t train loss: 0.403972\n",
      "epoch: 12 \t iteration 111 \t train loss: 0.401198\n",
      "epoch: 12 \t iteration 112 \t train loss: 0.362724\n",
      "epoch: 12 \t iteration 113 \t train loss: 0.399440\n",
      "epoch: 12 \t iteration 114 \t train loss: 0.405846\n",
      "epoch: 12 \t iteration 115 \t train loss: 0.335562\n",
      "epoch: 12 \t iteration 116 \t train loss: 0.321617\n",
      "epoch: 12 \t iteration 117 \t train loss: 0.456246\n",
      "epoch: 12 \t iteration 118 \t train loss: 0.420862\n",
      "epoch: 12 \t iteration 119 \t train loss: 0.446297\n",
      "epoch: 12 \t iteration 120 \t train loss: 0.368571\n",
      "epoch: 12 \t iteration 121 \t train loss: 0.404849\n",
      "epoch: 12 \t iteration 122 \t train loss: 0.397704\n",
      "epoch: 12 \t iteration 123 \t train loss: 0.341422\n",
      "epoch: 12 \t iteration 124 \t train loss: 0.394091\n",
      "epoch: 12 \t iteration 125 \t train loss: 0.469434\n",
      "epoch: 12 \t iteration 126 \t train loss: 0.407183\n",
      "epoch: 12 \t iteration 127 \t train loss: 0.386738\n",
      "epoch: 12 \t iteration 128 \t train loss: 0.434161\n",
      "epoch: 12 \t iteration 129 \t train loss: 0.461294\n",
      "epoch: 12 \t iteration 130 \t train loss: 0.407423\n",
      "epoch: 12 \t iteration 131 \t train loss: 0.402243\n",
      "epoch: 12 \t iteration 132 \t train loss: 0.422769\n",
      "epoch: 12 \t iteration 133 \t train loss: 0.338742\n",
      "epoch: 12 \t iteration 134 \t train loss: 0.371695\n",
      "epoch: 12 \t iteration 135 \t train loss: 0.403158\n",
      "epoch: 12 \t iteration 136 \t train loss: 0.409705\n",
      "epoch: 12 \t iteration 137 \t train loss: 0.430558\n",
      "epoch: 12 \t iteration 138 \t train loss: 0.339236\n",
      "epoch: 12 \t iteration 139 \t train loss: 0.434106\n",
      "epoch: 12 \t iteration 140 \t train loss: 0.412051\n",
      "epoch: 12 \t iteration 141 \t train loss: 0.388415\n",
      "epoch: 12 \t iteration 142 \t train loss: 0.406025\n",
      "epoch: 12 \t iteration 143 \t train loss: 0.432170\n",
      "epoch: 12 \t iteration 144 \t train loss: 0.425651\n",
      "epoch: 12 \t iteration 145 \t train loss: 0.430958\n",
      "epoch: 12 \t iteration 146 \t train loss: 0.372329\n",
      "epoch: 12 \t iteration 147 \t train loss: 0.345380\n",
      "epoch: 12 \t iteration 148 \t train loss: 0.367838\n",
      "epoch: 12 \t iteration 149 \t train loss: 0.439940\n",
      "epoch: 12 \t iteration 150 \t train loss: 0.419109\n",
      "epoch: 12 \t iteration 151 \t train loss: 0.379067\n",
      "epoch: 12 \t iteration 152 \t train loss: 0.348647\n",
      "epoch: 12 \t iteration 153 \t train loss: 0.377281\n",
      "epoch: 12 \t iteration 154 \t train loss: 0.373620\n",
      "epoch: 12 \t iteration 155 \t train loss: 0.403442\n",
      "epoch: 12 \t iteration 156 \t train loss: 0.458210\n",
      "epoch: 12 \t iteration 157 \t train loss: 0.383555\n",
      "epoch: 12 \t iteration 158 \t train loss: 0.473555\n",
      "epoch: 12 \t iteration 159 \t train loss: 0.437573\n",
      "epoch: 12 \t iteration 160 \t train loss: 0.378931\n",
      "epoch: 12 \t iteration 161 \t train loss: 0.440914\n",
      "epoch: 12 \t iteration 162 \t train loss: 0.410594\n",
      "epoch: 12 \t iteration 163 \t train loss: 0.369607\n",
      "epoch: 12 \t iteration 164 \t train loss: 0.371484\n",
      "epoch: 12 \t iteration 165 \t train loss: 0.362715\n",
      "epoch: 12 \t iteration 166 \t train loss: 0.342414\n",
      "epoch: 12 \t iteration 167 \t train loss: 0.382290\n",
      "epoch: 12 \t iteration 168 \t train loss: 0.459665\n",
      "epoch: 12 \t iteration 169 \t train loss: 0.354624\n",
      "epoch: 12 \t iteration 170 \t train loss: 0.359869\n",
      "epoch: 12 \t iteration 171 \t train loss: 0.431944\n",
      "epoch: 12 \t iteration 172 \t train loss: 0.393865\n",
      "epoch: 12 \t iteration 173 \t train loss: 0.334645\n",
      "epoch: 12 \t iteration 174 \t train loss: 0.394852\n",
      "epoch: 12 \t iteration 175 \t train loss: 0.372752\n",
      "epoch: 12 \t iteration 176 \t train loss: 0.404645\n",
      "epoch: 12 \t iteration 177 \t train loss: 0.375400\n",
      "epoch: 12 \t iteration 178 \t train loss: 0.349221\n",
      "epoch: 12 \t iteration 179 \t train loss: 0.430774\n",
      "epoch: 12 \t iteration 180 \t train loss: 0.354642\n",
      "epoch: 12 \t iteration 181 \t train loss: 0.362090\n",
      "epoch: 12 \t iteration 182 \t train loss: 0.400766\n",
      "epoch: 12 \t iteration 183 \t train loss: 0.322726\n",
      "epoch: 12 \t iteration 184 \t train loss: 0.383132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 \t iteration 185 \t train loss: 0.409728\n",
      "epoch: 12 \t iteration 186 \t train loss: 0.357782\n",
      "epoch: 12 \t iteration 187 \t train loss: 0.342222\n",
      "epoch: 12 \t iteration 188 \t train loss: 0.370056\n",
      "epoch: 12 \t iteration 189 \t train loss: 0.400342\n",
      "epoch: 12 \t iteration 190 \t train loss: 0.439087\n",
      "epoch: 12 \t iteration 191 \t train loss: 0.346585\n",
      "epoch: 12 \t iteration 192 \t train loss: 0.307618\n",
      "epoch: 12 \t iteration 193 \t train loss: 0.326323\n",
      "epoch: 12 \t iteration 194 \t train loss: 0.341816\n",
      "epoch: 12 \t iteration 195 \t train loss: 0.282370\n",
      "epoch: 12 \t iteration 196 \t train loss: 0.255320\n",
      "epoch: 12 \t iteration 197 \t train loss: 0.435956\n",
      "epoch: 12 \t iteration 198 \t train loss: 0.380346\n",
      "epoch: 12 \t iteration 199 \t train loss: 0.330302\n",
      "epoch:12 \t mean train loss: 0.394424 \t mean train acc: 0.854200\n",
      "epoch: 12 \t iteration 0 \t eval loss: 0.370752\n",
      "epoch: 12 \t iteration 1 \t eval loss: 0.346247\n",
      "epoch: 12 \t iteration 2 \t eval loss: 0.435847\n",
      "epoch: 12 \t iteration 3 \t eval loss: 0.392126\n",
      "epoch: 12 \t iteration 4 \t eval loss: 0.450828\n",
      "epoch: 12 \t iteration 5 \t eval loss: 0.427735\n",
      "epoch: 12 \t iteration 6 \t eval loss: 0.360260\n",
      "epoch: 12 \t iteration 7 \t eval loss: 0.368135\n",
      "epoch: 12 \t iteration 8 \t eval loss: 0.358839\n",
      "epoch: 12 \t iteration 9 \t eval loss: 0.365718\n",
      "epoch: 12 \t iteration 10 \t eval loss: 0.349778\n",
      "epoch: 12 \t iteration 11 \t eval loss: 0.377316\n",
      "epoch: 12 \t iteration 12 \t eval loss: 0.387527\n",
      "epoch: 12 \t iteration 13 \t eval loss: 0.361848\n",
      "epoch: 12 \t iteration 14 \t eval loss: 0.403762\n",
      "epoch: 12 \t iteration 15 \t eval loss: 0.360833\n",
      "epoch: 12 \t iteration 16 \t eval loss: 0.405777\n",
      "epoch: 12 \t iteration 17 \t eval loss: 0.388304\n",
      "epoch: 12 \t iteration 18 \t eval loss: 0.365916\n",
      "epoch: 12 \t iteration 19 \t eval loss: 0.390631\n",
      "epoch: 12 \t iteration 20 \t eval loss: 0.394146\n",
      "epoch: 12 \t iteration 21 \t eval loss: 0.355818\n",
      "epoch: 12 \t iteration 22 \t eval loss: 0.386828\n",
      "epoch: 12 \t iteration 23 \t eval loss: 0.362030\n",
      "epoch: 12 \t iteration 24 \t eval loss: 0.357628\n",
      "epoch: 12 \t iteration 25 \t eval loss: 0.393144\n",
      "epoch: 12 \t iteration 26 \t eval loss: 0.303966\n",
      "epoch: 12 \t iteration 27 \t eval loss: 0.460477\n",
      "epoch: 12 \t iteration 28 \t eval loss: 0.422877\n",
      "epoch: 12 \t iteration 29 \t eval loss: 0.421979\n",
      "epoch: 12 \t iteration 30 \t eval loss: 0.391699\n",
      "epoch: 12 \t iteration 31 \t eval loss: 0.431177\n",
      "epoch: 12 \t iteration 32 \t eval loss: 0.419998\n",
      "epoch: 12 \t iteration 33 \t eval loss: 0.414188\n",
      "epoch: 12 \t iteration 34 \t eval loss: 0.460495\n",
      "epoch: 12 \t iteration 35 \t eval loss: 0.432914\n",
      "epoch: 12 \t iteration 36 \t eval loss: 0.349265\n",
      "epoch: 12 \t iteration 37 \t eval loss: 0.391272\n",
      "epoch: 12 \t iteration 38 \t eval loss: 0.380621\n",
      "epoch: 12 \t iteration 39 \t eval loss: 0.334208\n",
      "epoch:12 \t mean eval loss: 0.388323 \t mean eval acc: 0.855100\n",
      "epoch: 13 \t iteration 0 \t train loss: 0.393298\n",
      "epoch: 13 \t iteration 1 \t train loss: 0.344342\n",
      "epoch: 13 \t iteration 2 \t train loss: 0.362557\n",
      "epoch: 13 \t iteration 3 \t train loss: 0.370518\n",
      "epoch: 13 \t iteration 4 \t train loss: 0.378505\n",
      "epoch: 13 \t iteration 5 \t train loss: 0.366443\n",
      "epoch: 13 \t iteration 6 \t train loss: 0.482260\n",
      "epoch: 13 \t iteration 7 \t train loss: 0.411470\n",
      "epoch: 13 \t iteration 8 \t train loss: 0.376172\n",
      "epoch: 13 \t iteration 9 \t train loss: 0.432831\n",
      "epoch: 13 \t iteration 10 \t train loss: 0.419706\n",
      "epoch: 13 \t iteration 11 \t train loss: 0.422455\n",
      "epoch: 13 \t iteration 12 \t train loss: 0.451013\n",
      "epoch: 13 \t iteration 13 \t train loss: 0.367179\n",
      "epoch: 13 \t iteration 14 \t train loss: 0.395735\n",
      "epoch: 13 \t iteration 15 \t train loss: 0.431568\n",
      "epoch: 13 \t iteration 16 \t train loss: 0.470718\n",
      "epoch: 13 \t iteration 17 \t train loss: 0.439539\n",
      "epoch: 13 \t iteration 18 \t train loss: 0.494425\n",
      "epoch: 13 \t iteration 19 \t train loss: 0.426380\n",
      "epoch: 13 \t iteration 20 \t train loss: 0.381574\n",
      "epoch: 13 \t iteration 21 \t train loss: 0.364315\n",
      "epoch: 13 \t iteration 22 \t train loss: 0.399094\n",
      "epoch: 13 \t iteration 23 \t train loss: 0.438117\n",
      "epoch: 13 \t iteration 24 \t train loss: 0.416406\n",
      "epoch: 13 \t iteration 25 \t train loss: 0.355849\n",
      "epoch: 13 \t iteration 26 \t train loss: 0.375380\n",
      "epoch: 13 \t iteration 27 \t train loss: 0.437527\n",
      "epoch: 13 \t iteration 28 \t train loss: 0.420951\n",
      "epoch: 13 \t iteration 29 \t train loss: 0.372077\n",
      "epoch: 13 \t iteration 30 \t train loss: 0.475009\n",
      "epoch: 13 \t iteration 31 \t train loss: 0.403898\n",
      "epoch: 13 \t iteration 32 \t train loss: 0.368041\n",
      "epoch: 13 \t iteration 33 \t train loss: 0.371498\n",
      "epoch: 13 \t iteration 34 \t train loss: 0.362758\n",
      "epoch: 13 \t iteration 35 \t train loss: 0.325753\n",
      "epoch: 13 \t iteration 36 \t train loss: 0.410700\n",
      "epoch: 13 \t iteration 37 \t train loss: 0.392789\n",
      "epoch: 13 \t iteration 38 \t train loss: 0.360937\n",
      "epoch: 13 \t iteration 39 \t train loss: 0.390263\n",
      "epoch: 13 \t iteration 40 \t train loss: 0.424983\n",
      "epoch: 13 \t iteration 41 \t train loss: 0.356599\n",
      "epoch: 13 \t iteration 42 \t train loss: 0.383634\n",
      "epoch: 13 \t iteration 43 \t train loss: 0.439979\n",
      "epoch: 13 \t iteration 44 \t train loss: 0.348065\n",
      "epoch: 13 \t iteration 45 \t train loss: 0.389676\n",
      "epoch: 13 \t iteration 46 \t train loss: 0.392341\n",
      "epoch: 13 \t iteration 47 \t train loss: 0.333849\n",
      "epoch: 13 \t iteration 48 \t train loss: 0.411922\n",
      "epoch: 13 \t iteration 49 \t train loss: 0.400418\n",
      "epoch: 13 \t iteration 50 \t train loss: 0.526750\n",
      "epoch: 13 \t iteration 51 \t train loss: 0.360260\n",
      "epoch: 13 \t iteration 52 \t train loss: 0.411392\n",
      "epoch: 13 \t iteration 53 \t train loss: 0.372665\n",
      "epoch: 13 \t iteration 54 \t train loss: 0.383111\n",
      "epoch: 13 \t iteration 55 \t train loss: 0.407652\n",
      "epoch: 13 \t iteration 56 \t train loss: 0.395146\n",
      "epoch: 13 \t iteration 57 \t train loss: 0.383243\n",
      "epoch: 13 \t iteration 58 \t train loss: 0.408101\n",
      "epoch: 13 \t iteration 59 \t train loss: 0.402020\n",
      "epoch: 13 \t iteration 60 \t train loss: 0.358355\n",
      "epoch: 13 \t iteration 61 \t train loss: 0.362304\n",
      "epoch: 13 \t iteration 62 \t train loss: 0.375395\n",
      "epoch: 13 \t iteration 63 \t train loss: 0.393774\n",
      "epoch: 13 \t iteration 64 \t train loss: 0.347304\n",
      "epoch: 13 \t iteration 65 \t train loss: 0.409444\n",
      "epoch: 13 \t iteration 66 \t train loss: 0.446790\n",
      "epoch: 13 \t iteration 67 \t train loss: 0.384236\n",
      "epoch: 13 \t iteration 68 \t train loss: 0.416742\n",
      "epoch: 13 \t iteration 69 \t train loss: 0.415660\n",
      "epoch: 13 \t iteration 70 \t train loss: 0.377648\n",
      "epoch: 13 \t iteration 71 \t train loss: 0.361622\n",
      "epoch: 13 \t iteration 72 \t train loss: 0.343738\n",
      "epoch: 13 \t iteration 73 \t train loss: 0.396521\n",
      "epoch: 13 \t iteration 74 \t train loss: 0.402503\n",
      "epoch: 13 \t iteration 75 \t train loss: 0.367883\n",
      "epoch: 13 \t iteration 76 \t train loss: 0.429716\n",
      "epoch: 13 \t iteration 77 \t train loss: 0.376446\n",
      "epoch: 13 \t iteration 78 \t train loss: 0.403289\n",
      "epoch: 13 \t iteration 79 \t train loss: 0.457676\n",
      "epoch: 13 \t iteration 80 \t train loss: 0.436261\n",
      "epoch: 13 \t iteration 81 \t train loss: 0.395627\n",
      "epoch: 13 \t iteration 82 \t train loss: 0.437183\n",
      "epoch: 13 \t iteration 83 \t train loss: 0.409572\n",
      "epoch: 13 \t iteration 84 \t train loss: 0.402484\n",
      "epoch: 13 \t iteration 85 \t train loss: 0.448364\n",
      "epoch: 13 \t iteration 86 \t train loss: 0.432283\n",
      "epoch: 13 \t iteration 87 \t train loss: 0.387346\n",
      "epoch: 13 \t iteration 88 \t train loss: 0.411835\n",
      "epoch: 13 \t iteration 89 \t train loss: 0.463144\n",
      "epoch: 13 \t iteration 90 \t train loss: 0.379734\n",
      "epoch: 13 \t iteration 91 \t train loss: 0.375432\n",
      "epoch: 13 \t iteration 92 \t train loss: 0.397833\n",
      "epoch: 13 \t iteration 93 \t train loss: 0.400184\n",
      "epoch: 13 \t iteration 94 \t train loss: 0.348177\n",
      "epoch: 13 \t iteration 95 \t train loss: 0.338755\n",
      "epoch: 13 \t iteration 96 \t train loss: 0.366889\n",
      "epoch: 13 \t iteration 97 \t train loss: 0.373249\n",
      "epoch: 13 \t iteration 98 \t train loss: 0.430596\n",
      "epoch: 13 \t iteration 99 \t train loss: 0.413673\n",
      "epoch: 13 \t iteration 100 \t train loss: 0.389763\n",
      "epoch: 13 \t iteration 101 \t train loss: 0.371013\n",
      "epoch: 13 \t iteration 102 \t train loss: 0.386885\n",
      "epoch: 13 \t iteration 103 \t train loss: 0.384849\n",
      "epoch: 13 \t iteration 104 \t train loss: 0.416425\n",
      "epoch: 13 \t iteration 105 \t train loss: 0.384819\n",
      "epoch: 13 \t iteration 106 \t train loss: 0.365706\n",
      "epoch: 13 \t iteration 107 \t train loss: 0.400384\n",
      "epoch: 13 \t iteration 108 \t train loss: 0.423980\n",
      "epoch: 13 \t iteration 109 \t train loss: 0.499715\n",
      "epoch: 13 \t iteration 110 \t train loss: 0.403131\n",
      "epoch: 13 \t iteration 111 \t train loss: 0.400706\n",
      "epoch: 13 \t iteration 112 \t train loss: 0.361868\n",
      "epoch: 13 \t iteration 113 \t train loss: 0.398702\n",
      "epoch: 13 \t iteration 114 \t train loss: 0.405114\n",
      "epoch: 13 \t iteration 115 \t train loss: 0.334971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 \t iteration 116 \t train loss: 0.321026\n",
      "epoch: 13 \t iteration 117 \t train loss: 0.455449\n",
      "epoch: 13 \t iteration 118 \t train loss: 0.420051\n",
      "epoch: 13 \t iteration 119 \t train loss: 0.445639\n",
      "epoch: 13 \t iteration 120 \t train loss: 0.367860\n",
      "epoch: 13 \t iteration 121 \t train loss: 0.404434\n",
      "epoch: 13 \t iteration 122 \t train loss: 0.397207\n",
      "epoch: 13 \t iteration 123 \t train loss: 0.340538\n",
      "epoch: 13 \t iteration 124 \t train loss: 0.393416\n",
      "epoch: 13 \t iteration 125 \t train loss: 0.468619\n",
      "epoch: 13 \t iteration 126 \t train loss: 0.406606\n",
      "epoch: 13 \t iteration 127 \t train loss: 0.386047\n",
      "epoch: 13 \t iteration 128 \t train loss: 0.433735\n",
      "epoch: 13 \t iteration 129 \t train loss: 0.460615\n",
      "epoch: 13 \t iteration 130 \t train loss: 0.406978\n",
      "epoch: 13 \t iteration 131 \t train loss: 0.401627\n",
      "epoch: 13 \t iteration 132 \t train loss: 0.422273\n",
      "epoch: 13 \t iteration 133 \t train loss: 0.338387\n",
      "epoch: 13 \t iteration 134 \t train loss: 0.371429\n",
      "epoch: 13 \t iteration 135 \t train loss: 0.402621\n",
      "epoch: 13 \t iteration 136 \t train loss: 0.409320\n",
      "epoch: 13 \t iteration 137 \t train loss: 0.429912\n",
      "epoch: 13 \t iteration 138 \t train loss: 0.338659\n",
      "epoch: 13 \t iteration 139 \t train loss: 0.433876\n",
      "epoch: 13 \t iteration 140 \t train loss: 0.411340\n",
      "epoch: 13 \t iteration 141 \t train loss: 0.387813\n",
      "epoch: 13 \t iteration 142 \t train loss: 0.405700\n",
      "epoch: 13 \t iteration 143 \t train loss: 0.431581\n",
      "epoch: 13 \t iteration 144 \t train loss: 0.425035\n",
      "epoch: 13 \t iteration 145 \t train loss: 0.430343\n",
      "epoch: 13 \t iteration 146 \t train loss: 0.371776\n",
      "epoch: 13 \t iteration 147 \t train loss: 0.344722\n",
      "epoch: 13 \t iteration 148 \t train loss: 0.366974\n",
      "epoch: 13 \t iteration 149 \t train loss: 0.439378\n",
      "epoch: 13 \t iteration 150 \t train loss: 0.418519\n",
      "epoch: 13 \t iteration 151 \t train loss: 0.378423\n",
      "epoch: 13 \t iteration 152 \t train loss: 0.348009\n",
      "epoch: 13 \t iteration 153 \t train loss: 0.376759\n",
      "epoch: 13 \t iteration 154 \t train loss: 0.373029\n",
      "epoch: 13 \t iteration 155 \t train loss: 0.402664\n",
      "epoch: 13 \t iteration 156 \t train loss: 0.457300\n",
      "epoch: 13 \t iteration 157 \t train loss: 0.382977\n",
      "epoch: 13 \t iteration 158 \t train loss: 0.472850\n",
      "epoch: 13 \t iteration 159 \t train loss: 0.436915\n",
      "epoch: 13 \t iteration 160 \t train loss: 0.377988\n",
      "epoch: 13 \t iteration 161 \t train loss: 0.440682\n",
      "epoch: 13 \t iteration 162 \t train loss: 0.409996\n",
      "epoch: 13 \t iteration 163 \t train loss: 0.369331\n",
      "epoch: 13 \t iteration 164 \t train loss: 0.371047\n",
      "epoch: 13 \t iteration 165 \t train loss: 0.362229\n",
      "epoch: 13 \t iteration 166 \t train loss: 0.341822\n",
      "epoch: 13 \t iteration 167 \t train loss: 0.382051\n",
      "epoch: 13 \t iteration 168 \t train loss: 0.458774\n",
      "epoch: 13 \t iteration 169 \t train loss: 0.354060\n",
      "epoch: 13 \t iteration 170 \t train loss: 0.359316\n",
      "epoch: 13 \t iteration 171 \t train loss: 0.431386\n",
      "epoch: 13 \t iteration 172 \t train loss: 0.393309\n",
      "epoch: 13 \t iteration 173 \t train loss: 0.333801\n",
      "epoch: 13 \t iteration 174 \t train loss: 0.394383\n",
      "epoch: 13 \t iteration 175 \t train loss: 0.371875\n",
      "epoch: 13 \t iteration 176 \t train loss: 0.403842\n",
      "epoch: 13 \t iteration 177 \t train loss: 0.374748\n",
      "epoch: 13 \t iteration 178 \t train loss: 0.348586\n",
      "epoch: 13 \t iteration 179 \t train loss: 0.429966\n",
      "epoch: 13 \t iteration 180 \t train loss: 0.354223\n",
      "epoch: 13 \t iteration 181 \t train loss: 0.361392\n",
      "epoch: 13 \t iteration 182 \t train loss: 0.400197\n",
      "epoch: 13 \t iteration 183 \t train loss: 0.322293\n",
      "epoch: 13 \t iteration 184 \t train loss: 0.382718\n",
      "epoch: 13 \t iteration 185 \t train loss: 0.409096\n",
      "epoch: 13 \t iteration 186 \t train loss: 0.356918\n",
      "epoch: 13 \t iteration 187 \t train loss: 0.341650\n",
      "epoch: 13 \t iteration 188 \t train loss: 0.369563\n",
      "epoch: 13 \t iteration 189 \t train loss: 0.400014\n",
      "epoch: 13 \t iteration 190 \t train loss: 0.438761\n",
      "epoch: 13 \t iteration 191 \t train loss: 0.346106\n",
      "epoch: 13 \t iteration 192 \t train loss: 0.307213\n",
      "epoch: 13 \t iteration 193 \t train loss: 0.325673\n",
      "epoch: 13 \t iteration 194 \t train loss: 0.341296\n",
      "epoch: 13 \t iteration 195 \t train loss: 0.282256\n",
      "epoch: 13 \t iteration 196 \t train loss: 0.254796\n",
      "epoch: 13 \t iteration 197 \t train loss: 0.435710\n",
      "epoch: 13 \t iteration 198 \t train loss: 0.379944\n",
      "epoch: 13 \t iteration 199 \t train loss: 0.329622\n",
      "epoch:13 \t mean train loss: 0.393813 \t mean train acc: 0.854380\n",
      "epoch: 13 \t iteration 0 \t eval loss: 0.370324\n",
      "epoch: 13 \t iteration 1 \t eval loss: 0.345888\n",
      "epoch: 13 \t iteration 2 \t eval loss: 0.435408\n",
      "epoch: 13 \t iteration 3 \t eval loss: 0.391644\n",
      "epoch: 13 \t iteration 4 \t eval loss: 0.450544\n",
      "epoch: 13 \t iteration 5 \t eval loss: 0.427693\n",
      "epoch: 13 \t iteration 6 \t eval loss: 0.359723\n",
      "epoch: 13 \t iteration 7 \t eval loss: 0.367532\n",
      "epoch: 13 \t iteration 8 \t eval loss: 0.358721\n",
      "epoch: 13 \t iteration 9 \t eval loss: 0.365161\n",
      "epoch: 13 \t iteration 10 \t eval loss: 0.349203\n",
      "epoch: 13 \t iteration 11 \t eval loss: 0.376975\n",
      "epoch: 13 \t iteration 12 \t eval loss: 0.387057\n",
      "epoch: 13 \t iteration 13 \t eval loss: 0.361151\n",
      "epoch: 13 \t iteration 14 \t eval loss: 0.402957\n",
      "epoch: 13 \t iteration 15 \t eval loss: 0.360288\n",
      "epoch: 13 \t iteration 16 \t eval loss: 0.405522\n",
      "epoch: 13 \t iteration 17 \t eval loss: 0.387702\n",
      "epoch: 13 \t iteration 18 \t eval loss: 0.365329\n",
      "epoch: 13 \t iteration 19 \t eval loss: 0.390339\n",
      "epoch: 13 \t iteration 20 \t eval loss: 0.393790\n",
      "epoch: 13 \t iteration 21 \t eval loss: 0.355442\n",
      "epoch: 13 \t iteration 22 \t eval loss: 0.386254\n",
      "epoch: 13 \t iteration 23 \t eval loss: 0.361554\n",
      "epoch: 13 \t iteration 24 \t eval loss: 0.357212\n",
      "epoch: 13 \t iteration 25 \t eval loss: 0.392828\n",
      "epoch: 13 \t iteration 26 \t eval loss: 0.303620\n",
      "epoch: 13 \t iteration 27 \t eval loss: 0.460449\n",
      "epoch: 13 \t iteration 28 \t eval loss: 0.422260\n",
      "epoch: 13 \t iteration 29 \t eval loss: 0.421428\n",
      "epoch: 13 \t iteration 30 \t eval loss: 0.390966\n",
      "epoch: 13 \t iteration 31 \t eval loss: 0.430824\n",
      "epoch: 13 \t iteration 32 \t eval loss: 0.419541\n",
      "epoch: 13 \t iteration 33 \t eval loss: 0.413945\n",
      "epoch: 13 \t iteration 34 \t eval loss: 0.460341\n",
      "epoch: 13 \t iteration 35 \t eval loss: 0.432324\n",
      "epoch: 13 \t iteration 36 \t eval loss: 0.348805\n",
      "epoch: 13 \t iteration 37 \t eval loss: 0.390903\n",
      "epoch: 13 \t iteration 38 \t eval loss: 0.380336\n",
      "epoch: 13 \t iteration 39 \t eval loss: 0.333593\n",
      "epoch:13 \t mean eval loss: 0.387889 \t mean eval acc: 0.854600\n",
      "epoch: 14 \t iteration 0 \t train loss: 0.392864\n",
      "epoch: 14 \t iteration 1 \t train loss: 0.343855\n",
      "epoch: 14 \t iteration 2 \t train loss: 0.362002\n",
      "epoch: 14 \t iteration 3 \t train loss: 0.369912\n",
      "epoch: 14 \t iteration 4 \t train loss: 0.378080\n",
      "epoch: 14 \t iteration 5 \t train loss: 0.366120\n",
      "epoch: 14 \t iteration 6 \t train loss: 0.481871\n",
      "epoch: 14 \t iteration 7 \t train loss: 0.411195\n",
      "epoch: 14 \t iteration 8 \t train loss: 0.375983\n",
      "epoch: 14 \t iteration 9 \t train loss: 0.432346\n",
      "epoch: 14 \t iteration 10 \t train loss: 0.419194\n",
      "epoch: 14 \t iteration 11 \t train loss: 0.421912\n",
      "epoch: 14 \t iteration 12 \t train loss: 0.450540\n",
      "epoch: 14 \t iteration 13 \t train loss: 0.366531\n",
      "epoch: 14 \t iteration 14 \t train loss: 0.395282\n",
      "epoch: 14 \t iteration 15 \t train loss: 0.430682\n",
      "epoch: 14 \t iteration 16 \t train loss: 0.470098\n",
      "epoch: 14 \t iteration 17 \t train loss: 0.438914\n",
      "epoch: 14 \t iteration 18 \t train loss: 0.493804\n",
      "epoch: 14 \t iteration 19 \t train loss: 0.425958\n",
      "epoch: 14 \t iteration 20 \t train loss: 0.381122\n",
      "epoch: 14 \t iteration 21 \t train loss: 0.363720\n",
      "epoch: 14 \t iteration 22 \t train loss: 0.398586\n",
      "epoch: 14 \t iteration 23 \t train loss: 0.437216\n",
      "epoch: 14 \t iteration 24 \t train loss: 0.415542\n",
      "epoch: 14 \t iteration 25 \t train loss: 0.355218\n",
      "epoch: 14 \t iteration 26 \t train loss: 0.375139\n",
      "epoch: 14 \t iteration 27 \t train loss: 0.437021\n",
      "epoch: 14 \t iteration 28 \t train loss: 0.420199\n",
      "epoch: 14 \t iteration 29 \t train loss: 0.371520\n",
      "epoch: 14 \t iteration 30 \t train loss: 0.474584\n",
      "epoch: 14 \t iteration 31 \t train loss: 0.403347\n",
      "epoch: 14 \t iteration 32 \t train loss: 0.367465\n",
      "epoch: 14 \t iteration 33 \t train loss: 0.370975\n",
      "epoch: 14 \t iteration 34 \t train loss: 0.362061\n",
      "epoch: 14 \t iteration 35 \t train loss: 0.325101\n",
      "epoch: 14 \t iteration 36 \t train loss: 0.409831\n",
      "epoch: 14 \t iteration 37 \t train loss: 0.392231\n",
      "epoch: 14 \t iteration 38 \t train loss: 0.360403\n",
      "epoch: 14 \t iteration 39 \t train loss: 0.389496\n",
      "epoch: 14 \t iteration 40 \t train loss: 0.424425\n",
      "epoch: 14 \t iteration 41 \t train loss: 0.355918\n",
      "epoch: 14 \t iteration 42 \t train loss: 0.383117\n",
      "epoch: 14 \t iteration 43 \t train loss: 0.439250\n",
      "epoch: 14 \t iteration 44 \t train loss: 0.347528\n",
      "epoch: 14 \t iteration 45 \t train loss: 0.389168\n",
      "epoch: 14 \t iteration 46 \t train loss: 0.391603\n",
      "epoch: 14 \t iteration 47 \t train loss: 0.333483\n",
      "epoch: 14 \t iteration 48 \t train loss: 0.411071\n",
      "epoch: 14 \t iteration 49 \t train loss: 0.400234\n",
      "epoch: 14 \t iteration 50 \t train loss: 0.526060\n",
      "epoch: 14 \t iteration 51 \t train loss: 0.359817\n",
      "epoch: 14 \t iteration 52 \t train loss: 0.410838\n",
      "epoch: 14 \t iteration 53 \t train loss: 0.371844\n",
      "epoch: 14 \t iteration 54 \t train loss: 0.382342\n",
      "epoch: 14 \t iteration 55 \t train loss: 0.407444\n",
      "epoch: 14 \t iteration 56 \t train loss: 0.394641\n",
      "epoch: 14 \t iteration 57 \t train loss: 0.382642\n",
      "epoch: 14 \t iteration 58 \t train loss: 0.407594\n",
      "epoch: 14 \t iteration 59 \t train loss: 0.401238\n",
      "epoch: 14 \t iteration 60 \t train loss: 0.357693\n",
      "epoch: 14 \t iteration 61 \t train loss: 0.361789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 \t iteration 62 \t train loss: 0.375099\n",
      "epoch: 14 \t iteration 63 \t train loss: 0.393608\n",
      "epoch: 14 \t iteration 64 \t train loss: 0.346655\n",
      "epoch: 14 \t iteration 65 \t train loss: 0.408603\n",
      "epoch: 14 \t iteration 66 \t train loss: 0.446263\n",
      "epoch: 14 \t iteration 67 \t train loss: 0.383559\n",
      "epoch: 14 \t iteration 68 \t train loss: 0.416203\n",
      "epoch: 14 \t iteration 69 \t train loss: 0.415109\n",
      "epoch: 14 \t iteration 70 \t train loss: 0.376969\n",
      "epoch: 14 \t iteration 71 \t train loss: 0.361149\n",
      "epoch: 14 \t iteration 72 \t train loss: 0.343429\n",
      "epoch: 14 \t iteration 73 \t train loss: 0.395874\n",
      "epoch: 14 \t iteration 74 \t train loss: 0.402087\n",
      "epoch: 14 \t iteration 75 \t train loss: 0.367672\n",
      "epoch: 14 \t iteration 76 \t train loss: 0.429129\n",
      "epoch: 14 \t iteration 77 \t train loss: 0.376228\n",
      "epoch: 14 \t iteration 78 \t train loss: 0.402608\n",
      "epoch: 14 \t iteration 79 \t train loss: 0.457154\n",
      "epoch: 14 \t iteration 80 \t train loss: 0.435456\n",
      "epoch: 14 \t iteration 81 \t train loss: 0.395082\n",
      "epoch: 14 \t iteration 82 \t train loss: 0.436855\n",
      "epoch: 14 \t iteration 83 \t train loss: 0.409148\n",
      "epoch: 14 \t iteration 84 \t train loss: 0.402036\n",
      "epoch: 14 \t iteration 85 \t train loss: 0.447463\n",
      "epoch: 14 \t iteration 86 \t train loss: 0.431609\n",
      "epoch: 14 \t iteration 87 \t train loss: 0.386786\n",
      "epoch: 14 \t iteration 88 \t train loss: 0.410909\n",
      "epoch: 14 \t iteration 89 \t train loss: 0.462447\n",
      "epoch: 14 \t iteration 90 \t train loss: 0.378985\n",
      "epoch: 14 \t iteration 91 \t train loss: 0.374905\n",
      "epoch: 14 \t iteration 92 \t train loss: 0.396631\n",
      "epoch: 14 \t iteration 93 \t train loss: 0.399712\n",
      "epoch: 14 \t iteration 94 \t train loss: 0.347608\n",
      "epoch: 14 \t iteration 95 \t train loss: 0.338382\n",
      "epoch: 14 \t iteration 96 \t train loss: 0.366332\n",
      "epoch: 14 \t iteration 97 \t train loss: 0.372694\n",
      "epoch: 14 \t iteration 98 \t train loss: 0.429884\n",
      "epoch: 14 \t iteration 99 \t train loss: 0.412942\n",
      "epoch: 14 \t iteration 100 \t train loss: 0.389342\n",
      "epoch: 14 \t iteration 101 \t train loss: 0.370417\n",
      "epoch: 14 \t iteration 102 \t train loss: 0.386506\n",
      "epoch: 14 \t iteration 103 \t train loss: 0.384064\n",
      "epoch: 14 \t iteration 104 \t train loss: 0.415813\n",
      "epoch: 14 \t iteration 105 \t train loss: 0.383975\n",
      "epoch: 14 \t iteration 106 \t train loss: 0.365462\n",
      "epoch: 14 \t iteration 107 \t train loss: 0.400024\n",
      "epoch: 14 \t iteration 108 \t train loss: 0.423562\n",
      "epoch: 14 \t iteration 109 \t train loss: 0.499815\n",
      "epoch: 14 \t iteration 110 \t train loss: 0.402371\n",
      "epoch: 14 \t iteration 111 \t train loss: 0.400280\n",
      "epoch: 14 \t iteration 112 \t train loss: 0.361103\n",
      "epoch: 14 \t iteration 113 \t train loss: 0.398047\n",
      "epoch: 14 \t iteration 114 \t train loss: 0.404474\n",
      "epoch: 14 \t iteration 115 \t train loss: 0.334457\n",
      "epoch: 14 \t iteration 116 \t train loss: 0.320515\n",
      "epoch: 14 \t iteration 117 \t train loss: 0.454752\n",
      "epoch: 14 \t iteration 118 \t train loss: 0.419336\n",
      "epoch: 14 \t iteration 119 \t train loss: 0.445059\n",
      "epoch: 14 \t iteration 120 \t train loss: 0.367229\n",
      "epoch: 14 \t iteration 121 \t train loss: 0.404076\n",
      "epoch: 14 \t iteration 122 \t train loss: 0.396784\n",
      "epoch: 14 \t iteration 123 \t train loss: 0.339760\n",
      "epoch: 14 \t iteration 124 \t train loss: 0.392824\n",
      "epoch: 14 \t iteration 125 \t train loss: 0.467889\n",
      "epoch: 14 \t iteration 126 \t train loss: 0.406114\n",
      "epoch: 14 \t iteration 127 \t train loss: 0.385445\n",
      "epoch: 14 \t iteration 128 \t train loss: 0.433355\n",
      "epoch: 14 \t iteration 129 \t train loss: 0.460008\n",
      "epoch: 14 \t iteration 130 \t train loss: 0.406590\n",
      "epoch: 14 \t iteration 131 \t train loss: 0.401088\n",
      "epoch: 14 \t iteration 132 \t train loss: 0.421833\n",
      "epoch: 14 \t iteration 133 \t train loss: 0.338081\n",
      "epoch: 14 \t iteration 134 \t train loss: 0.371213\n",
      "epoch: 14 \t iteration 135 \t train loss: 0.402143\n",
      "epoch: 14 \t iteration 136 \t train loss: 0.408985\n",
      "epoch: 14 \t iteration 137 \t train loss: 0.429339\n",
      "epoch: 14 \t iteration 138 \t train loss: 0.338153\n",
      "epoch: 14 \t iteration 139 \t train loss: 0.433692\n",
      "epoch: 14 \t iteration 140 \t train loss: 0.410707\n",
      "epoch: 14 \t iteration 141 \t train loss: 0.387286\n",
      "epoch: 14 \t iteration 142 \t train loss: 0.405427\n",
      "epoch: 14 \t iteration 143 \t train loss: 0.431061\n",
      "epoch: 14 \t iteration 144 \t train loss: 0.424486\n",
      "epoch: 14 \t iteration 145 \t train loss: 0.429795\n",
      "epoch: 14 \t iteration 146 \t train loss: 0.371294\n",
      "epoch: 14 \t iteration 147 \t train loss: 0.344142\n",
      "epoch: 14 \t iteration 148 \t train loss: 0.366207\n",
      "epoch: 14 \t iteration 149 \t train loss: 0.438892\n",
      "epoch: 14 \t iteration 150 \t train loss: 0.418003\n",
      "epoch: 14 \t iteration 151 \t train loss: 0.377861\n",
      "epoch: 14 \t iteration 152 \t train loss: 0.347439\n",
      "epoch: 14 \t iteration 153 \t train loss: 0.376293\n",
      "epoch: 14 \t iteration 154 \t train loss: 0.372518\n",
      "epoch: 14 \t iteration 155 \t train loss: 0.401974\n",
      "epoch: 14 \t iteration 156 \t train loss: 0.456490\n",
      "epoch: 14 \t iteration 157 \t train loss: 0.382462\n",
      "epoch: 14 \t iteration 158 \t train loss: 0.472229\n",
      "epoch: 14 \t iteration 159 \t train loss: 0.436321\n",
      "epoch: 14 \t iteration 160 \t train loss: 0.377145\n",
      "epoch: 14 \t iteration 161 \t train loss: 0.440476\n",
      "epoch: 14 \t iteration 162 \t train loss: 0.409487\n",
      "epoch: 14 \t iteration 163 \t train loss: 0.369104\n",
      "epoch: 14 \t iteration 164 \t train loss: 0.370669\n",
      "epoch: 14 \t iteration 165 \t train loss: 0.361805\n",
      "epoch: 14 \t iteration 166 \t train loss: 0.341317\n",
      "epoch: 14 \t iteration 167 \t train loss: 0.381861\n",
      "epoch: 14 \t iteration 168 \t train loss: 0.457970\n",
      "epoch: 14 \t iteration 169 \t train loss: 0.353561\n",
      "epoch: 14 \t iteration 170 \t train loss: 0.358833\n",
      "epoch: 14 \t iteration 171 \t train loss: 0.430908\n",
      "epoch: 14 \t iteration 172 \t train loss: 0.392814\n",
      "epoch: 14 \t iteration 173 \t train loss: 0.333051\n",
      "epoch: 14 \t iteration 174 \t train loss: 0.393966\n",
      "epoch: 14 \t iteration 175 \t train loss: 0.371093\n",
      "epoch: 14 \t iteration 176 \t train loss: 0.403119\n",
      "epoch: 14 \t iteration 177 \t train loss: 0.374176\n",
      "epoch: 14 \t iteration 178 \t train loss: 0.348028\n",
      "epoch: 14 \t iteration 179 \t train loss: 0.429249\n",
      "epoch: 14 \t iteration 180 \t train loss: 0.353861\n",
      "epoch: 14 \t iteration 181 \t train loss: 0.360776\n",
      "epoch: 14 \t iteration 182 \t train loss: 0.399698\n",
      "epoch: 14 \t iteration 183 \t train loss: 0.321931\n",
      "epoch: 14 \t iteration 184 \t train loss: 0.382354\n",
      "epoch: 14 \t iteration 185 \t train loss: 0.408540\n",
      "epoch: 14 \t iteration 186 \t train loss: 0.356125\n",
      "epoch: 14 \t iteration 187 \t train loss: 0.341145\n",
      "epoch: 14 \t iteration 188 \t train loss: 0.369121\n",
      "epoch: 14 \t iteration 189 \t train loss: 0.399747\n",
      "epoch: 14 \t iteration 190 \t train loss: 0.438468\n",
      "epoch: 14 \t iteration 191 \t train loss: 0.345677\n",
      "epoch: 14 \t iteration 192 \t train loss: 0.306867\n",
      "epoch: 14 \t iteration 193 \t train loss: 0.325103\n",
      "epoch: 14 \t iteration 194 \t train loss: 0.340842\n",
      "epoch: 14 \t iteration 195 \t train loss: 0.282185\n",
      "epoch: 14 \t iteration 196 \t train loss: 0.254332\n",
      "epoch: 14 \t iteration 197 \t train loss: 0.435456\n",
      "epoch: 14 \t iteration 198 \t train loss: 0.379582\n",
      "epoch: 14 \t iteration 199 \t train loss: 0.329021\n",
      "epoch:14 \t mean train loss: 0.393276 \t mean train acc: 0.854260\n",
      "epoch: 14 \t iteration 0 \t eval loss: 0.369960\n",
      "epoch: 14 \t iteration 1 \t eval loss: 0.345580\n",
      "epoch: 14 \t iteration 2 \t eval loss: 0.435031\n",
      "epoch: 14 \t iteration 3 \t eval loss: 0.391236\n",
      "epoch: 14 \t iteration 4 \t eval loss: 0.450303\n",
      "epoch: 14 \t iteration 5 \t eval loss: 0.427662\n",
      "epoch: 14 \t iteration 6 \t eval loss: 0.359254\n",
      "epoch: 14 \t iteration 7 \t eval loss: 0.367002\n",
      "epoch: 14 \t iteration 8 \t eval loss: 0.358645\n",
      "epoch: 14 \t iteration 9 \t eval loss: 0.364670\n",
      "epoch: 14 \t iteration 10 \t eval loss: 0.348698\n",
      "epoch: 14 \t iteration 11 \t eval loss: 0.376694\n",
      "epoch: 14 \t iteration 12 \t eval loss: 0.386655\n",
      "epoch: 14 \t iteration 13 \t eval loss: 0.360552\n",
      "epoch: 14 \t iteration 14 \t eval loss: 0.402234\n",
      "epoch: 14 \t iteration 15 \t eval loss: 0.359817\n",
      "epoch: 14 \t iteration 16 \t eval loss: 0.405316\n",
      "epoch: 14 \t iteration 17 \t eval loss: 0.387171\n",
      "epoch: 14 \t iteration 18 \t eval loss: 0.364821\n",
      "epoch: 14 \t iteration 19 \t eval loss: 0.390104\n",
      "epoch: 14 \t iteration 20 \t eval loss: 0.393480\n",
      "epoch: 14 \t iteration 21 \t eval loss: 0.355119\n",
      "epoch: 14 \t iteration 22 \t eval loss: 0.385753\n",
      "epoch: 14 \t iteration 23 \t eval loss: 0.361156\n",
      "epoch: 14 \t iteration 24 \t eval loss: 0.356849\n",
      "epoch: 14 \t iteration 25 \t eval loss: 0.392576\n",
      "epoch: 14 \t iteration 26 \t eval loss: 0.303327\n",
      "epoch: 14 \t iteration 27 \t eval loss: 0.460429\n",
      "epoch: 14 \t iteration 28 \t eval loss: 0.421711\n",
      "epoch: 14 \t iteration 29 \t eval loss: 0.420956\n",
      "epoch: 14 \t iteration 30 \t eval loss: 0.390313\n",
      "epoch: 14 \t iteration 31 \t eval loss: 0.430554\n",
      "epoch: 14 \t iteration 32 \t eval loss: 0.419136\n",
      "epoch: 14 \t iteration 33 \t eval loss: 0.413757\n",
      "epoch: 14 \t iteration 34 \t eval loss: 0.460228\n",
      "epoch: 14 \t iteration 35 \t eval loss: 0.431812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 \t iteration 36 \t eval loss: 0.348401\n",
      "epoch: 14 \t iteration 37 \t eval loss: 0.390599\n",
      "epoch: 14 \t iteration 38 \t eval loss: 0.380116\n",
      "epoch: 14 \t iteration 39 \t eval loss: 0.333053\n",
      "epoch:14 \t mean eval loss: 0.387518 \t mean eval acc: 0.854300\n",
      "epoch: 15 \t iteration 0 \t train loss: 0.392477\n",
      "epoch: 15 \t iteration 1 \t train loss: 0.343421\n",
      "epoch: 15 \t iteration 2 \t train loss: 0.361494\n",
      "epoch: 15 \t iteration 3 \t train loss: 0.369382\n",
      "epoch: 15 \t iteration 4 \t train loss: 0.377723\n",
      "epoch: 15 \t iteration 5 \t train loss: 0.365837\n",
      "epoch: 15 \t iteration 6 \t train loss: 0.481537\n",
      "epoch: 15 \t iteration 7 \t train loss: 0.410974\n",
      "epoch: 15 \t iteration 8 \t train loss: 0.375840\n",
      "epoch: 15 \t iteration 9 \t train loss: 0.431932\n",
      "epoch: 15 \t iteration 10 \t train loss: 0.418753\n",
      "epoch: 15 \t iteration 11 \t train loss: 0.421440\n",
      "epoch: 15 \t iteration 12 \t train loss: 0.450122\n",
      "epoch: 15 \t iteration 13 \t train loss: 0.365958\n",
      "epoch: 15 \t iteration 14 \t train loss: 0.394878\n",
      "epoch: 15 \t iteration 15 \t train loss: 0.429884\n",
      "epoch: 15 \t iteration 16 \t train loss: 0.469537\n",
      "epoch: 15 \t iteration 17 \t train loss: 0.438363\n",
      "epoch: 15 \t iteration 18 \t train loss: 0.493249\n",
      "epoch: 15 \t iteration 19 \t train loss: 0.425583\n",
      "epoch: 15 \t iteration 20 \t train loss: 0.380731\n",
      "epoch: 15 \t iteration 21 \t train loss: 0.363186\n",
      "epoch: 15 \t iteration 22 \t train loss: 0.398139\n",
      "epoch: 15 \t iteration 23 \t train loss: 0.436396\n",
      "epoch: 15 \t iteration 24 \t train loss: 0.414777\n",
      "epoch: 15 \t iteration 25 \t train loss: 0.354654\n",
      "epoch: 15 \t iteration 26 \t train loss: 0.374933\n",
      "epoch: 15 \t iteration 27 \t train loss: 0.436569\n",
      "epoch: 15 \t iteration 28 \t train loss: 0.419535\n",
      "epoch: 15 \t iteration 29 \t train loss: 0.371022\n",
      "epoch: 15 \t iteration 30 \t train loss: 0.474225\n",
      "epoch: 15 \t iteration 31 \t train loss: 0.402854\n",
      "epoch: 15 \t iteration 32 \t train loss: 0.366945\n",
      "epoch: 15 \t iteration 33 \t train loss: 0.370515\n",
      "epoch: 15 \t iteration 34 \t train loss: 0.361444\n",
      "epoch: 15 \t iteration 35 \t train loss: 0.324524\n",
      "epoch: 15 \t iteration 36 \t train loss: 0.409052\n",
      "epoch: 15 \t iteration 37 \t train loss: 0.391737\n",
      "epoch: 15 \t iteration 38 \t train loss: 0.359928\n",
      "epoch: 15 \t iteration 39 \t train loss: 0.388796\n",
      "epoch: 15 \t iteration 40 \t train loss: 0.423927\n",
      "epoch: 15 \t iteration 41 \t train loss: 0.355314\n",
      "epoch: 15 \t iteration 42 \t train loss: 0.382656\n",
      "epoch: 15 \t iteration 43 \t train loss: 0.438601\n",
      "epoch: 15 \t iteration 44 \t train loss: 0.347056\n",
      "epoch: 15 \t iteration 45 \t train loss: 0.388730\n",
      "epoch: 15 \t iteration 46 \t train loss: 0.390934\n",
      "epoch: 15 \t iteration 47 \t train loss: 0.333148\n",
      "epoch: 15 \t iteration 48 \t train loss: 0.410290\n",
      "epoch: 15 \t iteration 49 \t train loss: 0.400094\n",
      "epoch: 15 \t iteration 50 \t train loss: 0.525424\n",
      "epoch: 15 \t iteration 51 \t train loss: 0.359436\n",
      "epoch: 15 \t iteration 52 \t train loss: 0.410341\n",
      "epoch: 15 \t iteration 53 \t train loss: 0.371106\n",
      "epoch: 15 \t iteration 54 \t train loss: 0.381657\n",
      "epoch: 15 \t iteration 55 \t train loss: 0.407280\n",
      "epoch: 15 \t iteration 56 \t train loss: 0.394193\n",
      "epoch: 15 \t iteration 57 \t train loss: 0.382111\n",
      "epoch: 15 \t iteration 58 \t train loss: 0.407151\n",
      "epoch: 15 \t iteration 59 \t train loss: 0.400552\n",
      "epoch: 15 \t iteration 60 \t train loss: 0.357109\n",
      "epoch: 15 \t iteration 61 \t train loss: 0.361320\n",
      "epoch: 15 \t iteration 62 \t train loss: 0.374850\n",
      "epoch: 15 \t iteration 63 \t train loss: 0.393489\n",
      "epoch: 15 \t iteration 64 \t train loss: 0.346086\n",
      "epoch: 15 \t iteration 65 \t train loss: 0.407858\n",
      "epoch: 15 \t iteration 66 \t train loss: 0.445789\n",
      "epoch: 15 \t iteration 67 \t train loss: 0.382955\n",
      "epoch: 15 \t iteration 68 \t train loss: 0.415734\n",
      "epoch: 15 \t iteration 69 \t train loss: 0.414621\n",
      "epoch: 15 \t iteration 70 \t train loss: 0.376364\n",
      "epoch: 15 \t iteration 71 \t train loss: 0.360728\n",
      "epoch: 15 \t iteration 72 \t train loss: 0.343165\n",
      "epoch: 15 \t iteration 73 \t train loss: 0.395297\n",
      "epoch: 15 \t iteration 74 \t train loss: 0.401730\n",
      "epoch: 15 \t iteration 75 \t train loss: 0.367501\n",
      "epoch: 15 \t iteration 76 \t train loss: 0.428610\n",
      "epoch: 15 \t iteration 77 \t train loss: 0.376062\n",
      "epoch: 15 \t iteration 78 \t train loss: 0.401992\n",
      "epoch: 15 \t iteration 79 \t train loss: 0.456686\n",
      "epoch: 15 \t iteration 80 \t train loss: 0.434742\n",
      "epoch: 15 \t iteration 81 \t train loss: 0.394594\n",
      "epoch: 15 \t iteration 82 \t train loss: 0.436573\n",
      "epoch: 15 \t iteration 83 \t train loss: 0.408782\n",
      "epoch: 15 \t iteration 84 \t train loss: 0.401634\n",
      "epoch: 15 \t iteration 85 \t train loss: 0.446657\n",
      "epoch: 15 \t iteration 86 \t train loss: 0.431012\n",
      "epoch: 15 \t iteration 87 \t train loss: 0.386290\n",
      "epoch: 15 \t iteration 88 \t train loss: 0.410079\n",
      "epoch: 15 \t iteration 89 \t train loss: 0.461828\n",
      "epoch: 15 \t iteration 90 \t train loss: 0.378313\n",
      "epoch: 15 \t iteration 91 \t train loss: 0.374444\n",
      "epoch: 15 \t iteration 92 \t train loss: 0.395563\n",
      "epoch: 15 \t iteration 93 \t train loss: 0.399290\n",
      "epoch: 15 \t iteration 94 \t train loss: 0.347107\n",
      "epoch: 15 \t iteration 95 \t train loss: 0.338047\n",
      "epoch: 15 \t iteration 96 \t train loss: 0.365846\n",
      "epoch: 15 \t iteration 97 \t train loss: 0.372199\n",
      "epoch: 15 \t iteration 98 \t train loss: 0.429252\n",
      "epoch: 15 \t iteration 99 \t train loss: 0.412300\n",
      "epoch: 15 \t iteration 100 \t train loss: 0.388979\n",
      "epoch: 15 \t iteration 101 \t train loss: 0.369905\n",
      "epoch: 15 \t iteration 102 \t train loss: 0.386178\n",
      "epoch: 15 \t iteration 103 \t train loss: 0.383355\n",
      "epoch: 15 \t iteration 104 \t train loss: 0.415265\n",
      "epoch: 15 \t iteration 105 \t train loss: 0.383228\n",
      "epoch: 15 \t iteration 106 \t train loss: 0.365249\n",
      "epoch: 15 \t iteration 107 \t train loss: 0.399699\n",
      "epoch: 15 \t iteration 108 \t train loss: 0.423200\n",
      "epoch: 15 \t iteration 109 \t train loss: 0.499923\n",
      "epoch: 15 \t iteration 110 \t train loss: 0.401680\n",
      "epoch: 15 \t iteration 111 \t train loss: 0.399907\n",
      "epoch: 15 \t iteration 112 \t train loss: 0.360417\n",
      "epoch: 15 \t iteration 113 \t train loss: 0.397462\n",
      "epoch: 15 \t iteration 114 \t train loss: 0.403911\n",
      "epoch: 15 \t iteration 115 \t train loss: 0.334007\n",
      "epoch: 15 \t iteration 116 \t train loss: 0.320070\n",
      "epoch: 15 \t iteration 117 \t train loss: 0.454138\n",
      "epoch: 15 \t iteration 118 \t train loss: 0.418700\n",
      "epoch: 15 \t iteration 119 \t train loss: 0.444543\n",
      "epoch: 15 \t iteration 120 \t train loss: 0.366667\n",
      "epoch: 15 \t iteration 121 \t train loss: 0.403765\n",
      "epoch: 15 \t iteration 122 \t train loss: 0.396422\n",
      "epoch: 15 \t iteration 123 \t train loss: 0.339070\n",
      "epoch: 15 \t iteration 124 \t train loss: 0.392302\n",
      "epoch: 15 \t iteration 125 \t train loss: 0.467229\n",
      "epoch: 15 \t iteration 126 \t train loss: 0.405691\n",
      "epoch: 15 \t iteration 127 \t train loss: 0.384916\n",
      "epoch: 15 \t iteration 128 \t train loss: 0.433012\n",
      "epoch: 15 \t iteration 129 \t train loss: 0.459463\n",
      "epoch: 15 \t iteration 130 \t train loss: 0.406246\n",
      "epoch: 15 \t iteration 131 \t train loss: 0.400615\n",
      "epoch: 15 \t iteration 132 \t train loss: 0.421440\n",
      "epoch: 15 \t iteration 133 \t train loss: 0.337812\n",
      "epoch: 15 \t iteration 134 \t train loss: 0.371036\n",
      "epoch: 15 \t iteration 135 \t train loss: 0.401713\n",
      "epoch: 15 \t iteration 136 \t train loss: 0.408687\n",
      "epoch: 15 \t iteration 137 \t train loss: 0.428826\n",
      "epoch: 15 \t iteration 138 \t train loss: 0.337707\n",
      "epoch: 15 \t iteration 139 \t train loss: 0.433544\n",
      "epoch: 15 \t iteration 140 \t train loss: 0.410138\n",
      "epoch: 15 \t iteration 141 \t train loss: 0.386820\n",
      "epoch: 15 \t iteration 142 \t train loss: 0.405196\n",
      "epoch: 15 \t iteration 143 \t train loss: 0.430597\n",
      "epoch: 15 \t iteration 144 \t train loss: 0.423994\n",
      "epoch: 15 \t iteration 145 \t train loss: 0.429301\n",
      "epoch: 15 \t iteration 146 \t train loss: 0.370870\n",
      "epoch: 15 \t iteration 147 \t train loss: 0.343629\n",
      "epoch: 15 \t iteration 148 \t train loss: 0.365523\n",
      "epoch: 15 \t iteration 149 \t train loss: 0.438470\n",
      "epoch: 15 \t iteration 150 \t train loss: 0.417548\n",
      "epoch: 15 \t iteration 151 \t train loss: 0.377366\n",
      "epoch: 15 \t iteration 152 \t train loss: 0.346925\n",
      "epoch: 15 \t iteration 153 \t train loss: 0.375872\n",
      "epoch: 15 \t iteration 154 \t train loss: 0.372073\n",
      "epoch: 15 \t iteration 155 \t train loss: 0.401358\n",
      "epoch: 15 \t iteration 156 \t train loss: 0.455763\n",
      "epoch: 15 \t iteration 157 \t train loss: 0.382001\n",
      "epoch: 15 \t iteration 158 \t train loss: 0.471679\n",
      "epoch: 15 \t iteration 159 \t train loss: 0.435783\n",
      "epoch: 15 \t iteration 160 \t train loss: 0.376389\n",
      "epoch: 15 \t iteration 161 \t train loss: 0.440292\n",
      "epoch: 15 \t iteration 162 \t train loss: 0.409050\n",
      "epoch: 15 \t iteration 163 \t train loss: 0.368916\n",
      "epoch: 15 \t iteration 164 \t train loss: 0.370340\n",
      "epoch: 15 \t iteration 165 \t train loss: 0.361429\n",
      "epoch: 15 \t iteration 166 \t train loss: 0.340886\n",
      "epoch: 15 \t iteration 167 \t train loss: 0.381709\n",
      "epoch: 15 \t iteration 168 \t train loss: 0.457239\n",
      "epoch: 15 \t iteration 169 \t train loss: 0.353114\n",
      "epoch: 15 \t iteration 170 \t train loss: 0.358407\n",
      "epoch: 15 \t iteration 171 \t train loss: 0.430496\n",
      "epoch: 15 \t iteration 172 \t train loss: 0.392369\n",
      "epoch: 15 \t iteration 173 \t train loss: 0.332378\n",
      "epoch: 15 \t iteration 174 \t train loss: 0.393592\n",
      "epoch: 15 \t iteration 175 \t train loss: 0.370393\n",
      "epoch: 15 \t iteration 176 \t train loss: 0.402464\n",
      "epoch: 15 \t iteration 177 \t train loss: 0.373672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 \t iteration 178 \t train loss: 0.347535\n",
      "epoch: 15 \t iteration 179 \t train loss: 0.428611\n",
      "epoch: 15 \t iteration 180 \t train loss: 0.353546\n",
      "epoch: 15 \t iteration 181 \t train loss: 0.360230\n",
      "epoch: 15 \t iteration 182 \t train loss: 0.399259\n",
      "epoch: 15 \t iteration 183 \t train loss: 0.321629\n",
      "epoch: 15 \t iteration 184 \t train loss: 0.382030\n",
      "epoch: 15 \t iteration 185 \t train loss: 0.408049\n",
      "epoch: 15 \t iteration 186 \t train loss: 0.355394\n",
      "epoch: 15 \t iteration 187 \t train loss: 0.340696\n",
      "epoch: 15 \t iteration 188 \t train loss: 0.368720\n",
      "epoch: 15 \t iteration 189 \t train loss: 0.399527\n",
      "epoch: 15 \t iteration 190 \t train loss: 0.438204\n",
      "epoch: 15 \t iteration 191 \t train loss: 0.345288\n",
      "epoch: 15 \t iteration 192 \t train loss: 0.306568\n",
      "epoch: 15 \t iteration 193 \t train loss: 0.324598\n",
      "epoch: 15 \t iteration 194 \t train loss: 0.340442\n",
      "epoch: 15 \t iteration 195 \t train loss: 0.282148\n",
      "epoch: 15 \t iteration 196 \t train loss: 0.253916\n",
      "epoch: 15 \t iteration 197 \t train loss: 0.435197\n",
      "epoch: 15 \t iteration 198 \t train loss: 0.379254\n",
      "epoch: 15 \t iteration 199 \t train loss: 0.328485\n",
      "epoch:15 \t mean train loss: 0.392801 \t mean train acc: 0.854240\n",
      "epoch: 15 \t iteration 0 \t eval loss: 0.369649\n",
      "epoch: 15 \t iteration 1 \t eval loss: 0.345313\n",
      "epoch: 15 \t iteration 2 \t eval loss: 0.434705\n",
      "epoch: 15 \t iteration 3 \t eval loss: 0.390890\n",
      "epoch: 15 \t iteration 4 \t eval loss: 0.450097\n",
      "epoch: 15 \t iteration 5 \t eval loss: 0.427639\n",
      "epoch: 15 \t iteration 6 \t eval loss: 0.358841\n",
      "epoch: 15 \t iteration 7 \t eval loss: 0.366534\n",
      "epoch: 15 \t iteration 8 \t eval loss: 0.358603\n",
      "epoch: 15 \t iteration 9 \t eval loss: 0.364233\n",
      "epoch: 15 \t iteration 10 \t eval loss: 0.348253\n",
      "epoch: 15 \t iteration 11 \t eval loss: 0.376462\n",
      "epoch: 15 \t iteration 12 \t eval loss: 0.386309\n",
      "epoch: 15 \t iteration 13 \t eval loss: 0.360032\n",
      "epoch: 15 \t iteration 14 \t eval loss: 0.401579\n",
      "epoch: 15 \t iteration 15 \t eval loss: 0.359407\n",
      "epoch: 15 \t iteration 16 \t eval loss: 0.405149\n",
      "epoch: 15 \t iteration 17 \t eval loss: 0.386701\n",
      "epoch: 15 \t iteration 18 \t eval loss: 0.364378\n",
      "epoch: 15 \t iteration 19 \t eval loss: 0.389913\n",
      "epoch: 15 \t iteration 20 \t eval loss: 0.393208\n",
      "epoch: 15 \t iteration 21 \t eval loss: 0.354841\n",
      "epoch: 15 \t iteration 22 \t eval loss: 0.385310\n",
      "epoch: 15 \t iteration 23 \t eval loss: 0.360822\n",
      "epoch: 15 \t iteration 24 \t eval loss: 0.356529\n",
      "epoch: 15 \t iteration 25 \t eval loss: 0.392376\n",
      "epoch: 15 \t iteration 26 \t eval loss: 0.303078\n",
      "epoch: 15 \t iteration 27 \t eval loss: 0.460413\n",
      "epoch: 15 \t iteration 28 \t eval loss: 0.421219\n",
      "epoch: 15 \t iteration 29 \t eval loss: 0.420547\n",
      "epoch: 15 \t iteration 30 \t eval loss: 0.389727\n",
      "epoch: 15 \t iteration 31 \t eval loss: 0.430350\n",
      "epoch: 15 \t iteration 32 \t eval loss: 0.418775\n",
      "epoch: 15 \t iteration 33 \t eval loss: 0.413613\n",
      "epoch: 15 \t iteration 34 \t eval loss: 0.460147\n",
      "epoch: 15 \t iteration 35 \t eval loss: 0.431364\n",
      "epoch: 15 \t iteration 36 \t eval loss: 0.348045\n",
      "epoch: 15 \t iteration 37 \t eval loss: 0.390345\n",
      "epoch: 15 \t iteration 38 \t eval loss: 0.379949\n",
      "epoch: 15 \t iteration 39 \t eval loss: 0.332574\n",
      "epoch:15 \t mean eval loss: 0.387198 \t mean eval acc: 0.853700\n",
      "epoch: 16 \t iteration 0 \t train loss: 0.392129\n",
      "epoch: 16 \t iteration 1 \t train loss: 0.343031\n",
      "epoch: 16 \t iteration 2 \t train loss: 0.361025\n",
      "epoch: 16 \t iteration 3 \t train loss: 0.368915\n",
      "epoch: 16 \t iteration 4 \t train loss: 0.377421\n",
      "epoch: 16 \t iteration 5 \t train loss: 0.365587\n",
      "epoch: 16 \t iteration 6 \t train loss: 0.481247\n",
      "epoch: 16 \t iteration 7 \t train loss: 0.410796\n",
      "epoch: 16 \t iteration 8 \t train loss: 0.375732\n",
      "epoch: 16 \t iteration 9 \t train loss: 0.431575\n",
      "epoch: 16 \t iteration 10 \t train loss: 0.418370\n",
      "epoch: 16 \t iteration 11 \t train loss: 0.421027\n",
      "epoch: 16 \t iteration 12 \t train loss: 0.449747\n",
      "epoch: 16 \t iteration 13 \t train loss: 0.365446\n",
      "epoch: 16 \t iteration 14 \t train loss: 0.394516\n",
      "epoch: 16 \t iteration 15 \t train loss: 0.429162\n",
      "epoch: 16 \t iteration 16 \t train loss: 0.469027\n",
      "epoch: 16 \t iteration 17 \t train loss: 0.437873\n",
      "epoch: 16 \t iteration 18 \t train loss: 0.492748\n",
      "epoch: 16 \t iteration 19 \t train loss: 0.425247\n",
      "epoch: 16 \t iteration 20 \t train loss: 0.380389\n",
      "epoch: 16 \t iteration 21 \t train loss: 0.362705\n",
      "epoch: 16 \t iteration 22 \t train loss: 0.397743\n",
      "epoch: 16 \t iteration 23 \t train loss: 0.435646\n",
      "epoch: 16 \t iteration 24 \t train loss: 0.414093\n",
      "epoch: 16 \t iteration 25 \t train loss: 0.354146\n",
      "epoch: 16 \t iteration 26 \t train loss: 0.374757\n",
      "epoch: 16 \t iteration 27 \t train loss: 0.436161\n",
      "epoch: 16 \t iteration 28 \t train loss: 0.418945\n",
      "epoch: 16 \t iteration 29 \t train loss: 0.370572\n",
      "epoch: 16 \t iteration 30 \t train loss: 0.473919\n",
      "epoch: 16 \t iteration 31 \t train loss: 0.402408\n",
      "epoch: 16 \t iteration 32 \t train loss: 0.366472\n",
      "epoch: 16 \t iteration 33 \t train loss: 0.370109\n",
      "epoch: 16 \t iteration 34 \t train loss: 0.360895\n",
      "epoch: 16 \t iteration 35 \t train loss: 0.324008\n",
      "epoch: 16 \t iteration 36 \t train loss: 0.408351\n",
      "epoch: 16 \t iteration 37 \t train loss: 0.391295\n",
      "epoch: 16 \t iteration 38 \t train loss: 0.359503\n",
      "epoch: 16 \t iteration 39 \t train loss: 0.388154\n",
      "epoch: 16 \t iteration 40 \t train loss: 0.423478\n",
      "epoch: 16 \t iteration 41 \t train loss: 0.354774\n",
      "epoch: 16 \t iteration 42 \t train loss: 0.382243\n",
      "epoch: 16 \t iteration 43 \t train loss: 0.438021\n",
      "epoch: 16 \t iteration 44 \t train loss: 0.346637\n",
      "epoch: 16 \t iteration 45 \t train loss: 0.388349\n",
      "epoch: 16 \t iteration 46 \t train loss: 0.390324\n",
      "epoch: 16 \t iteration 47 \t train loss: 0.332839\n",
      "epoch: 16 \t iteration 48 \t train loss: 0.409571\n",
      "epoch: 16 \t iteration 49 \t train loss: 0.399989\n",
      "epoch: 16 \t iteration 50 \t train loss: 0.524832\n",
      "epoch: 16 \t iteration 51 \t train loss: 0.359107\n",
      "epoch: 16 \t iteration 52 \t train loss: 0.409893\n",
      "epoch: 16 \t iteration 53 \t train loss: 0.370437\n",
      "epoch: 16 \t iteration 54 \t train loss: 0.381043\n",
      "epoch: 16 \t iteration 55 \t train loss: 0.407149\n",
      "epoch: 16 \t iteration 56 \t train loss: 0.393794\n",
      "epoch: 16 \t iteration 57 \t train loss: 0.381638\n",
      "epoch: 16 \t iteration 58 \t train loss: 0.406760\n",
      "epoch: 16 \t iteration 59 \t train loss: 0.399944\n",
      "epoch: 16 \t iteration 60 \t train loss: 0.356589\n",
      "epoch: 16 \t iteration 61 \t train loss: 0.360890\n",
      "epoch: 16 \t iteration 62 \t train loss: 0.374639\n",
      "epoch: 16 \t iteration 63 \t train loss: 0.393406\n",
      "epoch: 16 \t iteration 64 \t train loss: 0.345583\n",
      "epoch: 16 \t iteration 65 \t train loss: 0.407194\n",
      "epoch: 16 \t iteration 66 \t train loss: 0.445360\n",
      "epoch: 16 \t iteration 67 \t train loss: 0.382412\n",
      "epoch: 16 \t iteration 68 \t train loss: 0.415325\n",
      "epoch: 16 \t iteration 69 \t train loss: 0.414187\n",
      "epoch: 16 \t iteration 70 \t train loss: 0.375822\n",
      "epoch: 16 \t iteration 71 \t train loss: 0.360350\n",
      "epoch: 16 \t iteration 72 \t train loss: 0.342937\n",
      "epoch: 16 \t iteration 73 \t train loss: 0.394779\n",
      "epoch: 16 \t iteration 74 \t train loss: 0.401420\n",
      "epoch: 16 \t iteration 75 \t train loss: 0.367360\n",
      "epoch: 16 \t iteration 76 \t train loss: 0.428145\n",
      "epoch: 16 \t iteration 77 \t train loss: 0.375937\n",
      "epoch: 16 \t iteration 78 \t train loss: 0.401430\n",
      "epoch: 16 \t iteration 79 \t train loss: 0.456263\n",
      "epoch: 16 \t iteration 80 \t train loss: 0.434103\n",
      "epoch: 16 \t iteration 81 \t train loss: 0.394155\n",
      "epoch: 16 \t iteration 82 \t train loss: 0.436329\n",
      "epoch: 16 \t iteration 83 \t train loss: 0.408462\n",
      "epoch: 16 \t iteration 84 \t train loss: 0.401270\n",
      "epoch: 16 \t iteration 85 \t train loss: 0.445932\n",
      "epoch: 16 \t iteration 86 \t train loss: 0.430478\n",
      "epoch: 16 \t iteration 87 \t train loss: 0.385847\n",
      "epoch: 16 \t iteration 88 \t train loss: 0.409331\n",
      "epoch: 16 \t iteration 89 \t train loss: 0.461275\n",
      "epoch: 16 \t iteration 90 \t train loss: 0.377707\n",
      "epoch: 16 \t iteration 91 \t train loss: 0.374039\n",
      "epoch: 16 \t iteration 92 \t train loss: 0.394609\n",
      "epoch: 16 \t iteration 93 \t train loss: 0.398909\n",
      "epoch: 16 \t iteration 94 \t train loss: 0.346664\n",
      "epoch: 16 \t iteration 95 \t train loss: 0.337744\n",
      "epoch: 16 \t iteration 96 \t train loss: 0.365418\n",
      "epoch: 16 \t iteration 97 \t train loss: 0.371754\n",
      "epoch: 16 \t iteration 98 \t train loss: 0.428687\n",
      "epoch: 16 \t iteration 99 \t train loss: 0.411732\n",
      "epoch: 16 \t iteration 100 \t train loss: 0.388664\n",
      "epoch: 16 \t iteration 101 \t train loss: 0.369461\n",
      "epoch: 16 \t iteration 102 \t train loss: 0.385892\n",
      "epoch: 16 \t iteration 103 \t train loss: 0.382711\n",
      "epoch: 16 \t iteration 104 \t train loss: 0.414773\n",
      "epoch: 16 \t iteration 105 \t train loss: 0.382563\n",
      "epoch: 16 \t iteration 106 \t train loss: 0.365061\n",
      "epoch: 16 \t iteration 107 \t train loss: 0.399402\n",
      "epoch: 16 \t iteration 108 \t train loss: 0.422885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 \t iteration 109 \t train loss: 0.500034\n",
      "epoch: 16 \t iteration 110 \t train loss: 0.401048\n",
      "epoch: 16 \t iteration 111 \t train loss: 0.399578\n",
      "epoch: 16 \t iteration 112 \t train loss: 0.359797\n",
      "epoch: 16 \t iteration 113 \t train loss: 0.396937\n",
      "epoch: 16 \t iteration 114 \t train loss: 0.403412\n",
      "epoch: 16 \t iteration 115 \t train loss: 0.333611\n",
      "epoch: 16 \t iteration 116 \t train loss: 0.319681\n",
      "epoch: 16 \t iteration 117 \t train loss: 0.453592\n",
      "epoch: 16 \t iteration 118 \t train loss: 0.418131\n",
      "epoch: 16 \t iteration 119 \t train loss: 0.444083\n",
      "epoch: 16 \t iteration 120 \t train loss: 0.366162\n",
      "epoch: 16 \t iteration 121 \t train loss: 0.403492\n",
      "epoch: 16 \t iteration 122 \t train loss: 0.396110\n",
      "epoch: 16 \t iteration 123 \t train loss: 0.338455\n",
      "epoch: 16 \t iteration 124 \t train loss: 0.391837\n",
      "epoch: 16 \t iteration 125 \t train loss: 0.466628\n",
      "epoch: 16 \t iteration 126 \t train loss: 0.405323\n",
      "epoch: 16 \t iteration 127 \t train loss: 0.384447\n",
      "epoch: 16 \t iteration 128 \t train loss: 0.432698\n",
      "epoch: 16 \t iteration 129 \t train loss: 0.458970\n",
      "epoch: 16 \t iteration 130 \t train loss: 0.405939\n",
      "epoch: 16 \t iteration 131 \t train loss: 0.400196\n",
      "epoch: 16 \t iteration 132 \t train loss: 0.421087\n",
      "epoch: 16 \t iteration 133 \t train loss: 0.337574\n",
      "epoch: 16 \t iteration 134 \t train loss: 0.370889\n",
      "epoch: 16 \t iteration 135 \t train loss: 0.401325\n",
      "epoch: 16 \t iteration 136 \t train loss: 0.408421\n",
      "epoch: 16 \t iteration 137 \t train loss: 0.428363\n",
      "epoch: 16 \t iteration 138 \t train loss: 0.337310\n",
      "epoch: 16 \t iteration 139 \t train loss: 0.433424\n",
      "epoch: 16 \t iteration 140 \t train loss: 0.409624\n",
      "epoch: 16 \t iteration 141 \t train loss: 0.386406\n",
      "epoch: 16 \t iteration 142 \t train loss: 0.405001\n",
      "epoch: 16 \t iteration 143 \t train loss: 0.430182\n",
      "epoch: 16 \t iteration 144 \t train loss: 0.423549\n",
      "epoch: 16 \t iteration 145 \t train loss: 0.428852\n",
      "epoch: 16 \t iteration 146 \t train loss: 0.370495\n",
      "epoch: 16 \t iteration 147 \t train loss: 0.343172\n",
      "epoch: 16 \t iteration 148 \t train loss: 0.364907\n",
      "epoch: 16 \t iteration 149 \t train loss: 0.438098\n",
      "epoch: 16 \t iteration 150 \t train loss: 0.417144\n",
      "epoch: 16 \t iteration 151 \t train loss: 0.376926\n",
      "epoch: 16 \t iteration 152 \t train loss: 0.346459\n",
      "epoch: 16 \t iteration 153 \t train loss: 0.375489\n",
      "epoch: 16 \t iteration 154 \t train loss: 0.371685\n",
      "epoch: 16 \t iteration 155 \t train loss: 0.400806\n",
      "epoch: 16 \t iteration 156 \t train loss: 0.455106\n",
      "epoch: 16 \t iteration 157 \t train loss: 0.381586\n",
      "epoch: 16 \t iteration 158 \t train loss: 0.471186\n",
      "epoch: 16 \t iteration 159 \t train loss: 0.435292\n",
      "epoch: 16 \t iteration 160 \t train loss: 0.375706\n",
      "epoch: 16 \t iteration 161 \t train loss: 0.440125\n",
      "epoch: 16 \t iteration 162 \t train loss: 0.408672\n",
      "epoch: 16 \t iteration 163 \t train loss: 0.368759\n",
      "epoch: 16 \t iteration 164 \t train loss: 0.370051\n",
      "epoch: 16 \t iteration 165 \t train loss: 0.361095\n",
      "epoch: 16 \t iteration 166 \t train loss: 0.340515\n",
      "epoch: 16 \t iteration 167 \t train loss: 0.381587\n",
      "epoch: 16 \t iteration 168 \t train loss: 0.456571\n",
      "epoch: 16 \t iteration 169 \t train loss: 0.352711\n",
      "epoch: 16 \t iteration 170 \t train loss: 0.358028\n",
      "epoch: 16 \t iteration 171 \t train loss: 0.430138\n",
      "epoch: 16 \t iteration 172 \t train loss: 0.391967\n",
      "epoch: 16 \t iteration 173 \t train loss: 0.331773\n",
      "epoch: 16 \t iteration 174 \t train loss: 0.393253\n",
      "epoch: 16 \t iteration 175 \t train loss: 0.369761\n",
      "epoch: 16 \t iteration 176 \t train loss: 0.401870\n",
      "epoch: 16 \t iteration 177 \t train loss: 0.373224\n",
      "epoch: 16 \t iteration 178 \t train loss: 0.347095\n",
      "epoch: 16 \t iteration 179 \t train loss: 0.428038\n",
      "epoch: 16 \t iteration 180 \t train loss: 0.353268\n",
      "epoch: 16 \t iteration 181 \t train loss: 0.359740\n",
      "epoch: 16 \t iteration 182 \t train loss: 0.398872\n",
      "epoch: 16 \t iteration 183 \t train loss: 0.321375\n",
      "epoch: 16 \t iteration 184 \t train loss: 0.381741\n",
      "epoch: 16 \t iteration 185 \t train loss: 0.407612\n",
      "epoch: 16 \t iteration 186 \t train loss: 0.354717\n",
      "epoch: 16 \t iteration 187 \t train loss: 0.340293\n",
      "epoch: 16 \t iteration 188 \t train loss: 0.368356\n",
      "epoch: 16 \t iteration 189 \t train loss: 0.399345\n",
      "epoch: 16 \t iteration 190 \t train loss: 0.437963\n",
      "epoch: 16 \t iteration 191 \t train loss: 0.344932\n",
      "epoch: 16 \t iteration 192 \t train loss: 0.306307\n",
      "epoch: 16 \t iteration 193 \t train loss: 0.324150\n",
      "epoch: 16 \t iteration 194 \t train loss: 0.340088\n",
      "epoch: 16 \t iteration 195 \t train loss: 0.282138\n",
      "epoch: 16 \t iteration 196 \t train loss: 0.253542\n",
      "epoch: 16 \t iteration 197 \t train loss: 0.434934\n",
      "epoch: 16 \t iteration 198 \t train loss: 0.378952\n",
      "epoch: 16 \t iteration 199 \t train loss: 0.328006\n",
      "epoch:16 \t mean train loss: 0.392377 \t mean train acc: 0.854540\n",
      "epoch: 16 \t iteration 0 \t eval loss: 0.369380\n",
      "epoch: 16 \t iteration 1 \t eval loss: 0.345079\n",
      "epoch: 16 \t iteration 2 \t eval loss: 0.434420\n",
      "epoch: 16 \t iteration 3 \t eval loss: 0.390595\n",
      "epoch: 16 \t iteration 4 \t eval loss: 0.449920\n",
      "epoch: 16 \t iteration 5 \t eval loss: 0.427623\n",
      "epoch: 16 \t iteration 6 \t eval loss: 0.358477\n",
      "epoch: 16 \t iteration 7 \t eval loss: 0.366118\n",
      "epoch: 16 \t iteration 8 \t eval loss: 0.358588\n",
      "epoch: 16 \t iteration 9 \t eval loss: 0.363842\n",
      "epoch: 16 \t iteration 10 \t eval loss: 0.347858\n",
      "epoch: 16 \t iteration 11 \t eval loss: 0.376271\n",
      "epoch: 16 \t iteration 12 \t eval loss: 0.386009\n",
      "epoch: 16 \t iteration 13 \t eval loss: 0.359580\n",
      "epoch: 16 \t iteration 14 \t eval loss: 0.400984\n",
      "epoch: 16 \t iteration 15 \t eval loss: 0.359047\n",
      "epoch: 16 \t iteration 16 \t eval loss: 0.405014\n",
      "epoch: 16 \t iteration 17 \t eval loss: 0.386280\n",
      "epoch: 16 \t iteration 18 \t eval loss: 0.363989\n",
      "epoch: 16 \t iteration 19 \t eval loss: 0.389759\n",
      "epoch: 16 \t iteration 20 \t eval loss: 0.392967\n",
      "epoch: 16 \t iteration 21 \t eval loss: 0.354600\n",
      "epoch: 16 \t iteration 22 \t eval loss: 0.384917\n",
      "epoch: 16 \t iteration 23 \t eval loss: 0.360541\n",
      "epoch: 16 \t iteration 24 \t eval loss: 0.356246\n",
      "epoch: 16 \t iteration 25 \t eval loss: 0.392219\n",
      "epoch: 16 \t iteration 26 \t eval loss: 0.302863\n",
      "epoch: 16 \t iteration 27 \t eval loss: 0.460401\n",
      "epoch: 16 \t iteration 28 \t eval loss: 0.420775\n",
      "epoch: 16 \t iteration 29 \t eval loss: 0.420190\n",
      "epoch: 16 \t iteration 30 \t eval loss: 0.389199\n",
      "epoch: 16 \t iteration 31 \t eval loss: 0.430201\n",
      "epoch: 16 \t iteration 32 \t eval loss: 0.418450\n",
      "epoch: 16 \t iteration 33 \t eval loss: 0.413503\n",
      "epoch: 16 \t iteration 34 \t eval loss: 0.460092\n",
      "epoch: 16 \t iteration 35 \t eval loss: 0.430971\n",
      "epoch: 16 \t iteration 36 \t eval loss: 0.347728\n",
      "epoch: 16 \t iteration 37 \t eval loss: 0.390134\n",
      "epoch: 16 \t iteration 38 \t eval loss: 0.379826\n",
      "epoch: 16 \t iteration 39 \t eval loss: 0.332146\n",
      "epoch:16 \t mean eval loss: 0.386920 \t mean eval acc: 0.853600\n",
      "epoch: 17 \t iteration 0 \t train loss: 0.391815\n",
      "epoch: 17 \t iteration 1 \t train loss: 0.342678\n",
      "epoch: 17 \t iteration 2 \t train loss: 0.360589\n",
      "epoch: 17 \t iteration 3 \t train loss: 0.368500\n",
      "epoch: 17 \t iteration 4 \t train loss: 0.377164\n",
      "epoch: 17 \t iteration 5 \t train loss: 0.365367\n",
      "epoch: 17 \t iteration 6 \t train loss: 0.480994\n",
      "epoch: 17 \t iteration 7 \t train loss: 0.410652\n",
      "epoch: 17 \t iteration 8 \t train loss: 0.375653\n",
      "epoch: 17 \t iteration 9 \t train loss: 0.431264\n",
      "epoch: 17 \t iteration 10 \t train loss: 0.418034\n",
      "epoch: 17 \t iteration 11 \t train loss: 0.420661\n",
      "epoch: 17 \t iteration 12 \t train loss: 0.449408\n",
      "epoch: 17 \t iteration 13 \t train loss: 0.364987\n",
      "epoch: 17 \t iteration 14 \t train loss: 0.394189\n",
      "epoch: 17 \t iteration 15 \t train loss: 0.428505\n",
      "epoch: 17 \t iteration 16 \t train loss: 0.468560\n",
      "epoch: 17 \t iteration 17 \t train loss: 0.437435\n",
      "epoch: 17 \t iteration 18 \t train loss: 0.492292\n",
      "epoch: 17 \t iteration 19 \t train loss: 0.424942\n",
      "epoch: 17 \t iteration 20 \t train loss: 0.380090\n",
      "epoch: 17 \t iteration 21 \t train loss: 0.362269\n",
      "epoch: 17 \t iteration 22 \t train loss: 0.397390\n",
      "epoch: 17 \t iteration 23 \t train loss: 0.434956\n",
      "epoch: 17 \t iteration 24 \t train loss: 0.413480\n",
      "epoch: 17 \t iteration 25 \t train loss: 0.353683\n",
      "epoch: 17 \t iteration 26 \t train loss: 0.374605\n",
      "epoch: 17 \t iteration 27 \t train loss: 0.435789\n",
      "epoch: 17 \t iteration 28 \t train loss: 0.418418\n",
      "epoch: 17 \t iteration 29 \t train loss: 0.370165\n",
      "epoch: 17 \t iteration 30 \t train loss: 0.473656\n",
      "epoch: 17 \t iteration 31 \t train loss: 0.402003\n",
      "epoch: 17 \t iteration 32 \t train loss: 0.366040\n",
      "epoch: 17 \t iteration 33 \t train loss: 0.369748\n",
      "epoch: 17 \t iteration 34 \t train loss: 0.360402\n",
      "epoch: 17 \t iteration 35 \t train loss: 0.323544\n",
      "epoch: 17 \t iteration 36 \t train loss: 0.407715\n",
      "epoch: 17 \t iteration 37 \t train loss: 0.390897\n",
      "epoch: 17 \t iteration 38 \t train loss: 0.359121\n",
      "epoch: 17 \t iteration 39 \t train loss: 0.387559\n",
      "epoch: 17 \t iteration 40 \t train loss: 0.423070\n",
      "epoch: 17 \t iteration 41 \t train loss: 0.354287\n",
      "epoch: 17 \t iteration 42 \t train loss: 0.381870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 \t iteration 43 \t train loss: 0.437498\n",
      "epoch: 17 \t iteration 44 \t train loss: 0.346263\n",
      "epoch: 17 \t iteration 45 \t train loss: 0.388018\n",
      "epoch: 17 \t iteration 46 \t train loss: 0.389763\n",
      "epoch: 17 \t iteration 47 \t train loss: 0.332555\n",
      "epoch: 17 \t iteration 48 \t train loss: 0.408904\n",
      "epoch: 17 \t iteration 49 \t train loss: 0.399911\n",
      "epoch: 17 \t iteration 50 \t train loss: 0.524281\n",
      "epoch: 17 \t iteration 51 \t train loss: 0.358821\n",
      "epoch: 17 \t iteration 52 \t train loss: 0.409486\n",
      "epoch: 17 \t iteration 53 \t train loss: 0.369828\n",
      "epoch: 17 \t iteration 54 \t train loss: 0.380488\n",
      "epoch: 17 \t iteration 55 \t train loss: 0.407046\n",
      "epoch: 17 \t iteration 56 \t train loss: 0.393435\n",
      "epoch: 17 \t iteration 57 \t train loss: 0.381213\n",
      "epoch: 17 \t iteration 58 \t train loss: 0.406413\n",
      "epoch: 17 \t iteration 59 \t train loss: 0.399402\n",
      "epoch: 17 \t iteration 60 \t train loss: 0.356124\n",
      "epoch: 17 \t iteration 61 \t train loss: 0.360494\n",
      "epoch: 17 \t iteration 62 \t train loss: 0.374462\n",
      "epoch: 17 \t iteration 63 \t train loss: 0.393353\n",
      "epoch: 17 \t iteration 64 \t train loss: 0.345136\n",
      "epoch: 17 \t iteration 65 \t train loss: 0.406599\n",
      "epoch: 17 \t iteration 66 \t train loss: 0.444970\n",
      "epoch: 17 \t iteration 67 \t train loss: 0.381922\n",
      "epoch: 17 \t iteration 68 \t train loss: 0.414968\n",
      "epoch: 17 \t iteration 69 \t train loss: 0.413795\n",
      "epoch: 17 \t iteration 70 \t train loss: 0.375334\n",
      "epoch: 17 \t iteration 71 \t train loss: 0.360009\n",
      "epoch: 17 \t iteration 72 \t train loss: 0.342740\n",
      "epoch: 17 \t iteration 73 \t train loss: 0.394312\n",
      "epoch: 17 \t iteration 74 \t train loss: 0.401149\n",
      "epoch: 17 \t iteration 75 \t train loss: 0.367242\n",
      "epoch: 17 \t iteration 76 \t train loss: 0.427728\n",
      "epoch: 17 \t iteration 77 \t train loss: 0.375845\n",
      "epoch: 17 \t iteration 78 \t train loss: 0.400916\n",
      "epoch: 17 \t iteration 79 \t train loss: 0.455878\n",
      "epoch: 17 \t iteration 80 \t train loss: 0.433529\n",
      "epoch: 17 \t iteration 81 \t train loss: 0.393756\n",
      "epoch: 17 \t iteration 82 \t train loss: 0.436117\n",
      "epoch: 17 \t iteration 83 \t train loss: 0.408182\n",
      "epoch: 17 \t iteration 84 \t train loss: 0.400937\n",
      "epoch: 17 \t iteration 85 \t train loss: 0.445277\n",
      "epoch: 17 \t iteration 86 \t train loss: 0.429999\n",
      "epoch: 17 \t iteration 87 \t train loss: 0.385449\n",
      "epoch: 17 \t iteration 88 \t train loss: 0.408653\n",
      "epoch: 17 \t iteration 89 \t train loss: 0.460779\n",
      "epoch: 17 \t iteration 90 \t train loss: 0.377156\n",
      "epoch: 17 \t iteration 91 \t train loss: 0.373680\n",
      "epoch: 17 \t iteration 92 \t train loss: 0.393752\n",
      "epoch: 17 \t iteration 93 \t train loss: 0.398564\n",
      "epoch: 17 \t iteration 94 \t train loss: 0.346270\n",
      "epoch: 17 \t iteration 95 \t train loss: 0.337468\n",
      "epoch: 17 \t iteration 96 \t train loss: 0.365039\n",
      "epoch: 17 \t iteration 97 \t train loss: 0.371351\n",
      "epoch: 17 \t iteration 98 \t train loss: 0.428180\n",
      "epoch: 17 \t iteration 99 \t train loss: 0.411227\n",
      "epoch: 17 \t iteration 100 \t train loss: 0.388389\n",
      "epoch: 17 \t iteration 101 \t train loss: 0.369074\n",
      "epoch: 17 \t iteration 102 \t train loss: 0.385640\n",
      "epoch: 17 \t iteration 103 \t train loss: 0.382121\n",
      "epoch: 17 \t iteration 104 \t train loss: 0.414327\n",
      "epoch: 17 \t iteration 105 \t train loss: 0.381968\n",
      "epoch: 17 \t iteration 106 \t train loss: 0.364894\n",
      "epoch: 17 \t iteration 107 \t train loss: 0.399130\n",
      "epoch: 17 \t iteration 108 \t train loss: 0.422610\n",
      "epoch: 17 \t iteration 109 \t train loss: 0.500148\n",
      "epoch: 17 \t iteration 110 \t train loss: 0.400467\n",
      "epoch: 17 \t iteration 111 \t train loss: 0.399287\n",
      "epoch: 17 \t iteration 112 \t train loss: 0.359233\n",
      "epoch: 17 \t iteration 113 \t train loss: 0.396462\n",
      "epoch: 17 \t iteration 114 \t train loss: 0.402967\n",
      "epoch: 17 \t iteration 115 \t train loss: 0.333260\n",
      "epoch: 17 \t iteration 116 \t train loss: 0.319338\n",
      "epoch: 17 \t iteration 117 \t train loss: 0.453105\n",
      "epoch: 17 \t iteration 118 \t train loss: 0.417621\n",
      "epoch: 17 \t iteration 119 \t train loss: 0.443669\n",
      "epoch: 17 \t iteration 120 \t train loss: 0.365707\n",
      "epoch: 17 \t iteration 121 \t train loss: 0.403251\n",
      "epoch: 17 \t iteration 122 \t train loss: 0.395840\n",
      "epoch: 17 \t iteration 123 \t train loss: 0.337906\n",
      "epoch: 17 \t iteration 124 \t train loss: 0.391422\n",
      "epoch: 17 \t iteration 125 \t train loss: 0.466078\n",
      "epoch: 17 \t iteration 126 \t train loss: 0.405002\n",
      "epoch: 17 \t iteration 127 \t train loss: 0.384029\n",
      "epoch: 17 \t iteration 128 \t train loss: 0.432410\n",
      "epoch: 17 \t iteration 129 \t train loss: 0.458522\n",
      "epoch: 17 \t iteration 130 \t train loss: 0.405663\n",
      "epoch: 17 \t iteration 131 \t train loss: 0.399823\n",
      "epoch: 17 \t iteration 132 \t train loss: 0.420767\n",
      "epoch: 17 \t iteration 133 \t train loss: 0.337361\n",
      "epoch: 17 \t iteration 134 \t train loss: 0.370767\n",
      "epoch: 17 \t iteration 135 \t train loss: 0.400973\n",
      "epoch: 17 \t iteration 136 \t train loss: 0.408179\n",
      "epoch: 17 \t iteration 137 \t train loss: 0.427943\n",
      "epoch: 17 \t iteration 138 \t train loss: 0.336955\n",
      "epoch: 17 \t iteration 139 \t train loss: 0.433327\n",
      "epoch: 17 \t iteration 140 \t train loss: 0.409157\n",
      "epoch: 17 \t iteration 141 \t train loss: 0.386037\n",
      "epoch: 17 \t iteration 142 \t train loss: 0.404833\n",
      "epoch: 17 \t iteration 143 \t train loss: 0.429807\n",
      "epoch: 17 \t iteration 144 \t train loss: 0.423144\n",
      "epoch: 17 \t iteration 145 \t train loss: 0.428443\n",
      "epoch: 17 \t iteration 146 \t train loss: 0.370160\n",
      "epoch: 17 \t iteration 147 \t train loss: 0.342764\n",
      "epoch: 17 \t iteration 148 \t train loss: 0.364350\n",
      "epoch: 17 \t iteration 149 \t train loss: 0.437770\n",
      "epoch: 17 \t iteration 150 \t train loss: 0.416781\n",
      "epoch: 17 \t iteration 151 \t train loss: 0.376533\n",
      "epoch: 17 \t iteration 152 \t train loss: 0.346033\n",
      "epoch: 17 \t iteration 153 \t train loss: 0.375138\n",
      "epoch: 17 \t iteration 154 \t train loss: 0.371343\n",
      "epoch: 17 \t iteration 155 \t train loss: 0.400308\n",
      "epoch: 17 \t iteration 156 \t train loss: 0.454509\n",
      "epoch: 17 \t iteration 157 \t train loss: 0.381212\n",
      "epoch: 17 \t iteration 158 \t train loss: 0.470742\n",
      "epoch: 17 \t iteration 159 \t train loss: 0.434843\n",
      "epoch: 17 \t iteration 160 \t train loss: 0.375087\n",
      "epoch: 17 \t iteration 161 \t train loss: 0.439973\n",
      "epoch: 17 \t iteration 162 \t train loss: 0.408343\n",
      "epoch: 17 \t iteration 163 \t train loss: 0.368627\n",
      "epoch: 17 \t iteration 164 \t train loss: 0.369795\n",
      "epoch: 17 \t iteration 165 \t train loss: 0.360794\n",
      "epoch: 17 \t iteration 166 \t train loss: 0.340193\n",
      "epoch: 17 \t iteration 167 \t train loss: 0.381489\n",
      "epoch: 17 \t iteration 168 \t train loss: 0.455956\n",
      "epoch: 17 \t iteration 169 \t train loss: 0.352346\n",
      "epoch: 17 \t iteration 170 \t train loss: 0.357689\n",
      "epoch: 17 \t iteration 171 \t train loss: 0.429823\n",
      "epoch: 17 \t iteration 172 \t train loss: 0.391601\n",
      "epoch: 17 \t iteration 173 \t train loss: 0.331225\n",
      "epoch: 17 \t iteration 174 \t train loss: 0.392945\n",
      "epoch: 17 \t iteration 175 \t train loss: 0.369189\n",
      "epoch: 17 \t iteration 176 \t train loss: 0.401327\n",
      "epoch: 17 \t iteration 177 \t train loss: 0.372825\n",
      "epoch: 17 \t iteration 178 \t train loss: 0.346703\n",
      "epoch: 17 \t iteration 179 \t train loss: 0.427522\n",
      "epoch: 17 \t iteration 180 \t train loss: 0.353022\n",
      "epoch: 17 \t iteration 181 \t train loss: 0.359300\n",
      "epoch: 17 \t iteration 182 \t train loss: 0.398530\n",
      "epoch: 17 \t iteration 183 \t train loss: 0.321163\n",
      "epoch: 17 \t iteration 184 \t train loss: 0.381479\n",
      "epoch: 17 \t iteration 185 \t train loss: 0.407220\n",
      "epoch: 17 \t iteration 186 \t train loss: 0.354087\n",
      "epoch: 17 \t iteration 187 \t train loss: 0.339929\n",
      "epoch: 17 \t iteration 188 \t train loss: 0.368022\n",
      "epoch: 17 \t iteration 189 \t train loss: 0.399192\n",
      "epoch: 17 \t iteration 190 \t train loss: 0.437742\n",
      "epoch: 17 \t iteration 191 \t train loss: 0.344606\n",
      "epoch: 17 \t iteration 192 \t train loss: 0.306078\n",
      "epoch: 17 \t iteration 193 \t train loss: 0.323750\n",
      "epoch: 17 \t iteration 194 \t train loss: 0.339773\n",
      "epoch: 17 \t iteration 195 \t train loss: 0.282148\n",
      "epoch: 17 \t iteration 196 \t train loss: 0.253202\n",
      "epoch: 17 \t iteration 197 \t train loss: 0.434670\n",
      "epoch: 17 \t iteration 198 \t train loss: 0.378674\n",
      "epoch: 17 \t iteration 199 \t train loss: 0.327573\n",
      "epoch:17 \t mean train loss: 0.391996 \t mean train acc: 0.854580\n",
      "epoch: 17 \t iteration 0 \t eval loss: 0.369145\n",
      "epoch: 17 \t iteration 1 \t eval loss: 0.344873\n",
      "epoch: 17 \t iteration 2 \t eval loss: 0.434170\n",
      "epoch: 17 \t iteration 3 \t eval loss: 0.390341\n",
      "epoch: 17 \t iteration 4 \t eval loss: 0.449767\n",
      "epoch: 17 \t iteration 5 \t eval loss: 0.427613\n",
      "epoch: 17 \t iteration 6 \t eval loss: 0.358153\n",
      "epoch: 17 \t iteration 7 \t eval loss: 0.365747\n",
      "epoch: 17 \t iteration 8 \t eval loss: 0.358595\n",
      "epoch: 17 \t iteration 9 \t eval loss: 0.363488\n",
      "epoch: 17 \t iteration 10 \t eval loss: 0.347505\n",
      "epoch: 17 \t iteration 11 \t eval loss: 0.376113\n",
      "epoch: 17 \t iteration 12 \t eval loss: 0.385747\n",
      "epoch: 17 \t iteration 13 \t eval loss: 0.359184\n",
      "epoch: 17 \t iteration 14 \t eval loss: 0.400441\n",
      "epoch: 17 \t iteration 15 \t eval loss: 0.358730\n",
      "epoch: 17 \t iteration 16 \t eval loss: 0.404905\n",
      "epoch: 17 \t iteration 17 \t eval loss: 0.385901\n",
      "epoch: 17 \t iteration 18 \t eval loss: 0.363647\n",
      "epoch: 17 \t iteration 19 \t eval loss: 0.389634\n",
      "epoch: 17 \t iteration 20 \t eval loss: 0.392752\n",
      "epoch: 17 \t iteration 21 \t eval loss: 0.354389\n",
      "epoch: 17 \t iteration 22 \t eval loss: 0.384565\n",
      "epoch: 17 \t iteration 23 \t eval loss: 0.360302\n",
      "epoch: 17 \t iteration 24 \t eval loss: 0.355994\n",
      "epoch: 17 \t iteration 25 \t eval loss: 0.392097\n",
      "epoch: 17 \t iteration 26 \t eval loss: 0.302677\n",
      "epoch: 17 \t iteration 27 \t eval loss: 0.460390\n",
      "epoch: 17 \t iteration 28 \t eval loss: 0.420372\n",
      "epoch: 17 \t iteration 29 \t eval loss: 0.419878\n",
      "epoch: 17 \t iteration 30 \t eval loss: 0.388720\n",
      "epoch: 17 \t iteration 31 \t eval loss: 0.430098\n",
      "epoch: 17 \t iteration 32 \t eval loss: 0.418158\n",
      "epoch: 17 \t iteration 33 \t eval loss: 0.413421\n",
      "epoch: 17 \t iteration 34 \t eval loss: 0.460059\n",
      "epoch: 17 \t iteration 35 \t eval loss: 0.430626\n",
      "epoch: 17 \t iteration 36 \t eval loss: 0.347446\n",
      "epoch: 17 \t iteration 37 \t eval loss: 0.389957\n",
      "epoch: 17 \t iteration 38 \t eval loss: 0.379739\n",
      "epoch: 17 \t iteration 39 \t eval loss: 0.331763\n",
      "epoch:17 \t mean eval loss: 0.386678 \t mean eval acc: 0.853700\n",
      "epoch: 18 \t iteration 0 \t train loss: 0.391529\n",
      "epoch: 18 \t iteration 1 \t train loss: 0.342357\n",
      "epoch: 18 \t iteration 2 \t train loss: 0.360182\n",
      "epoch: 18 \t iteration 3 \t train loss: 0.368130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 \t iteration 4 \t train loss: 0.376943\n",
      "epoch: 18 \t iteration 5 \t train loss: 0.365171\n",
      "epoch: 18 \t iteration 6 \t train loss: 0.480771\n",
      "epoch: 18 \t iteration 7 \t train loss: 0.410535\n",
      "epoch: 18 \t iteration 8 \t train loss: 0.375598\n",
      "epoch: 18 \t iteration 9 \t train loss: 0.430993\n",
      "epoch: 18 \t iteration 10 \t train loss: 0.417738\n",
      "epoch: 18 \t iteration 11 \t train loss: 0.420337\n",
      "epoch: 18 \t iteration 12 \t train loss: 0.449098\n",
      "epoch: 18 \t iteration 13 \t train loss: 0.364572\n",
      "epoch: 18 \t iteration 14 \t train loss: 0.393892\n",
      "epoch: 18 \t iteration 15 \t train loss: 0.427906\n",
      "epoch: 18 \t iteration 16 \t train loss: 0.468130\n",
      "epoch: 18 \t iteration 17 \t train loss: 0.437039\n",
      "epoch: 18 \t iteration 18 \t train loss: 0.491872\n",
      "epoch: 18 \t iteration 19 \t train loss: 0.424664\n",
      "epoch: 18 \t iteration 20 \t train loss: 0.379825\n",
      "epoch: 18 \t iteration 21 \t train loss: 0.361872\n",
      "epoch: 18 \t iteration 22 \t train loss: 0.397072\n",
      "epoch: 18 \t iteration 23 \t train loss: 0.434319\n",
      "epoch: 18 \t iteration 24 \t train loss: 0.412926\n",
      "epoch: 18 \t iteration 25 \t train loss: 0.353259\n",
      "epoch: 18 \t iteration 26 \t train loss: 0.374473\n",
      "epoch: 18 \t iteration 27 \t train loss: 0.435447\n",
      "epoch: 18 \t iteration 28 \t train loss: 0.417944\n",
      "epoch: 18 \t iteration 29 \t train loss: 0.369794\n",
      "epoch: 18 \t iteration 30 \t train loss: 0.473430\n",
      "epoch: 18 \t iteration 31 \t train loss: 0.401633\n",
      "epoch: 18 \t iteration 32 \t train loss: 0.365642\n",
      "epoch: 18 \t iteration 33 \t train loss: 0.369426\n",
      "epoch: 18 \t iteration 34 \t train loss: 0.359958\n",
      "epoch: 18 \t iteration 35 \t train loss: 0.323124\n",
      "epoch: 18 \t iteration 36 \t train loss: 0.407135\n",
      "epoch: 18 \t iteration 37 \t train loss: 0.390538\n",
      "epoch: 18 \t iteration 38 \t train loss: 0.358775\n",
      "epoch: 18 \t iteration 39 \t train loss: 0.387007\n",
      "epoch: 18 \t iteration 40 \t train loss: 0.422698\n",
      "epoch: 18 \t iteration 41 \t train loss: 0.353845\n",
      "epoch: 18 \t iteration 42 \t train loss: 0.381531\n",
      "epoch: 18 \t iteration 43 \t train loss: 0.437024\n",
      "epoch: 18 \t iteration 44 \t train loss: 0.345927\n",
      "epoch: 18 \t iteration 45 \t train loss: 0.387728\n",
      "epoch: 18 \t iteration 46 \t train loss: 0.389246\n",
      "epoch: 18 \t iteration 47 \t train loss: 0.332293\n",
      "epoch: 18 \t iteration 48 \t train loss: 0.408283\n",
      "epoch: 18 \t iteration 49 \t train loss: 0.399855\n",
      "epoch: 18 \t iteration 50 \t train loss: 0.523766\n",
      "epoch: 18 \t iteration 51 \t train loss: 0.358571\n",
      "epoch: 18 \t iteration 52 \t train loss: 0.409114\n",
      "epoch: 18 \t iteration 53 \t train loss: 0.369272\n",
      "epoch: 18 \t iteration 54 \t train loss: 0.379984\n",
      "epoch: 18 \t iteration 55 \t train loss: 0.406964\n",
      "epoch: 18 \t iteration 56 \t train loss: 0.393110\n",
      "epoch: 18 \t iteration 57 \t train loss: 0.380829\n",
      "epoch: 18 \t iteration 58 \t train loss: 0.406103\n",
      "epoch: 18 \t iteration 59 \t train loss: 0.398918\n",
      "epoch: 18 \t iteration 60 \t train loss: 0.355705\n",
      "epoch: 18 \t iteration 61 \t train loss: 0.360128\n",
      "epoch: 18 \t iteration 62 \t train loss: 0.374311\n",
      "epoch: 18 \t iteration 63 \t train loss: 0.393324\n",
      "epoch: 18 \t iteration 64 \t train loss: 0.344737\n",
      "epoch: 18 \t iteration 65 \t train loss: 0.406064\n",
      "epoch: 18 \t iteration 66 \t train loss: 0.444613\n",
      "epoch: 18 \t iteration 67 \t train loss: 0.381477\n",
      "epoch: 18 \t iteration 68 \t train loss: 0.414654\n",
      "epoch: 18 \t iteration 69 \t train loss: 0.413440\n",
      "epoch: 18 \t iteration 70 \t train loss: 0.374890\n",
      "epoch: 18 \t iteration 71 \t train loss: 0.359702\n",
      "epoch: 18 \t iteration 72 \t train loss: 0.342568\n",
      "epoch: 18 \t iteration 73 \t train loss: 0.393888\n",
      "epoch: 18 \t iteration 74 \t train loss: 0.400911\n",
      "epoch: 18 \t iteration 75 \t train loss: 0.367143\n",
      "epoch: 18 \t iteration 76 \t train loss: 0.427350\n",
      "epoch: 18 \t iteration 77 \t train loss: 0.375781\n",
      "epoch: 18 \t iteration 78 \t train loss: 0.400442\n",
      "epoch: 18 \t iteration 79 \t train loss: 0.455524\n",
      "epoch: 18 \t iteration 80 \t train loss: 0.433009\n",
      "epoch: 18 \t iteration 81 \t train loss: 0.393392\n",
      "epoch: 18 \t iteration 82 \t train loss: 0.435930\n",
      "epoch: 18 \t iteration 83 \t train loss: 0.407933\n",
      "epoch: 18 \t iteration 84 \t train loss: 0.400632\n",
      "epoch: 18 \t iteration 85 \t train loss: 0.444681\n",
      "epoch: 18 \t iteration 86 \t train loss: 0.429565\n",
      "epoch: 18 \t iteration 87 \t train loss: 0.385087\n",
      "epoch: 18 \t iteration 88 \t train loss: 0.408036\n",
      "epoch: 18 \t iteration 89 \t train loss: 0.460330\n",
      "epoch: 18 \t iteration 90 \t train loss: 0.376654\n",
      "epoch: 18 \t iteration 91 \t train loss: 0.373360\n",
      "epoch: 18 \t iteration 92 \t train loss: 0.392978\n",
      "epoch: 18 \t iteration 93 \t train loss: 0.398249\n",
      "epoch: 18 \t iteration 94 \t train loss: 0.345918\n",
      "epoch: 18 \t iteration 95 \t train loss: 0.337215\n",
      "epoch: 18 \t iteration 96 \t train loss: 0.364702\n",
      "epoch: 18 \t iteration 97 \t train loss: 0.370985\n",
      "epoch: 18 \t iteration 98 \t train loss: 0.427722\n",
      "epoch: 18 \t iteration 99 \t train loss: 0.410776\n",
      "epoch: 18 \t iteration 100 \t train loss: 0.388146\n",
      "epoch: 18 \t iteration 101 \t train loss: 0.368735\n",
      "epoch: 18 \t iteration 102 \t train loss: 0.385418\n",
      "epoch: 18 \t iteration 103 \t train loss: 0.381580\n",
      "epoch: 18 \t iteration 104 \t train loss: 0.413921\n",
      "epoch: 18 \t iteration 105 \t train loss: 0.381432\n",
      "epoch: 18 \t iteration 106 \t train loss: 0.364745\n",
      "epoch: 18 \t iteration 107 \t train loss: 0.398880\n",
      "epoch: 18 \t iteration 108 \t train loss: 0.422369\n",
      "epoch: 18 \t iteration 109 \t train loss: 0.500261\n",
      "epoch: 18 \t iteration 110 \t train loss: 0.399932\n",
      "epoch: 18 \t iteration 111 \t train loss: 0.399028\n",
      "epoch: 18 \t iteration 112 \t train loss: 0.358719\n",
      "epoch: 18 \t iteration 113 \t train loss: 0.396030\n",
      "epoch: 18 \t iteration 114 \t train loss: 0.402567\n",
      "epoch: 18 \t iteration 115 \t train loss: 0.332947\n",
      "epoch: 18 \t iteration 116 \t train loss: 0.319034\n",
      "epoch: 18 \t iteration 117 \t train loss: 0.452666\n",
      "epoch: 18 \t iteration 118 \t train loss: 0.417162\n",
      "epoch: 18 \t iteration 119 \t train loss: 0.443296\n",
      "epoch: 18 \t iteration 120 \t train loss: 0.365295\n",
      "epoch: 18 \t iteration 121 \t train loss: 0.403037\n",
      "epoch: 18 \t iteration 122 \t train loss: 0.395604\n",
      "epoch: 18 \t iteration 123 \t train loss: 0.337412\n",
      "epoch: 18 \t iteration 124 \t train loss: 0.391049\n",
      "epoch: 18 \t iteration 125 \t train loss: 0.465572\n",
      "epoch: 18 \t iteration 126 \t train loss: 0.404720\n",
      "epoch: 18 \t iteration 127 \t train loss: 0.383654\n",
      "epoch: 18 \t iteration 128 \t train loss: 0.432142\n",
      "epoch: 18 \t iteration 129 \t train loss: 0.458112\n",
      "epoch: 18 \t iteration 130 \t train loss: 0.405413\n",
      "epoch: 18 \t iteration 131 \t train loss: 0.399490\n",
      "epoch: 18 \t iteration 132 \t train loss: 0.420477\n",
      "epoch: 18 \t iteration 133 \t train loss: 0.337168\n",
      "epoch: 18 \t iteration 134 \t train loss: 0.370665\n",
      "epoch: 18 \t iteration 135 \t train loss: 0.400652\n",
      "epoch: 18 \t iteration 136 \t train loss: 0.407958\n",
      "epoch: 18 \t iteration 137 \t train loss: 0.427559\n",
      "epoch: 18 \t iteration 138 \t train loss: 0.336635\n",
      "epoch: 18 \t iteration 139 \t train loss: 0.433248\n",
      "epoch: 18 \t iteration 140 \t train loss: 0.408731\n",
      "epoch: 18 \t iteration 141 \t train loss: 0.385706\n",
      "epoch: 18 \t iteration 142 \t train loss: 0.404689\n",
      "epoch: 18 \t iteration 143 \t train loss: 0.429466\n",
      "epoch: 18 \t iteration 144 \t train loss: 0.422775\n",
      "epoch: 18 \t iteration 145 \t train loss: 0.428066\n",
      "epoch: 18 \t iteration 146 \t train loss: 0.369861\n",
      "epoch: 18 \t iteration 147 \t train loss: 0.342397\n",
      "epoch: 18 \t iteration 148 \t train loss: 0.363844\n",
      "epoch: 18 \t iteration 149 \t train loss: 0.437477\n",
      "epoch: 18 \t iteration 150 \t train loss: 0.416455\n",
      "epoch: 18 \t iteration 151 \t train loss: 0.376179\n",
      "epoch: 18 \t iteration 152 \t train loss: 0.345643\n",
      "epoch: 18 \t iteration 153 \t train loss: 0.374814\n",
      "epoch: 18 \t iteration 154 \t train loss: 0.371043\n",
      "epoch: 18 \t iteration 155 \t train loss: 0.399857\n",
      "epoch: 18 \t iteration 156 \t train loss: 0.453964\n",
      "epoch: 18 \t iteration 157 \t train loss: 0.380872\n",
      "epoch: 18 \t iteration 158 \t train loss: 0.470339\n",
      "epoch: 18 \t iteration 159 \t train loss: 0.434429\n",
      "epoch: 18 \t iteration 160 \t train loss: 0.374523\n",
      "epoch: 18 \t iteration 161 \t train loss: 0.439833\n",
      "epoch: 18 \t iteration 162 \t train loss: 0.408056\n",
      "epoch: 18 \t iteration 163 \t train loss: 0.368516\n",
      "epoch: 18 \t iteration 164 \t train loss: 0.369566\n",
      "epoch: 18 \t iteration 165 \t train loss: 0.360522\n",
      "epoch: 18 \t iteration 166 \t train loss: 0.339915\n",
      "epoch: 18 \t iteration 167 \t train loss: 0.381411\n",
      "epoch: 18 \t iteration 168 \t train loss: 0.455389\n",
      "epoch: 18 \t iteration 169 \t train loss: 0.352012\n",
      "epoch: 18 \t iteration 170 \t train loss: 0.357383\n",
      "epoch: 18 \t iteration 171 \t train loss: 0.429545\n",
      "epoch: 18 \t iteration 172 \t train loss: 0.391267\n",
      "epoch: 18 \t iteration 173 \t train loss: 0.330728\n",
      "epoch: 18 \t iteration 174 \t train loss: 0.392662\n",
      "epoch: 18 \t iteration 175 \t train loss: 0.368669\n",
      "epoch: 18 \t iteration 176 \t train loss: 0.400830\n",
      "epoch: 18 \t iteration 177 \t train loss: 0.372468\n",
      "epoch: 18 \t iteration 178 \t train loss: 0.346350\n",
      "epoch: 18 \t iteration 179 \t train loss: 0.427055\n",
      "epoch: 18 \t iteration 180 \t train loss: 0.352801\n",
      "epoch: 18 \t iteration 181 \t train loss: 0.358902\n",
      "epoch: 18 \t iteration 182 \t train loss: 0.398227\n",
      "epoch: 18 \t iteration 183 \t train loss: 0.320984\n",
      "epoch: 18 \t iteration 184 \t train loss: 0.381242\n",
      "epoch: 18 \t iteration 185 \t train loss: 0.406868\n",
      "epoch: 18 \t iteration 186 \t train loss: 0.353499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 \t iteration 187 \t train loss: 0.339598\n",
      "epoch: 18 \t iteration 188 \t train loss: 0.367714\n",
      "epoch: 18 \t iteration 189 \t train loss: 0.399063\n",
      "epoch: 18 \t iteration 190 \t train loss: 0.437540\n",
      "epoch: 18 \t iteration 191 \t train loss: 0.344303\n",
      "epoch: 18 \t iteration 192 \t train loss: 0.305874\n",
      "epoch: 18 \t iteration 193 \t train loss: 0.323392\n",
      "epoch: 18 \t iteration 194 \t train loss: 0.339491\n",
      "epoch: 18 \t iteration 195 \t train loss: 0.282174\n",
      "epoch: 18 \t iteration 196 \t train loss: 0.252893\n",
      "epoch: 18 \t iteration 197 \t train loss: 0.434404\n",
      "epoch: 18 \t iteration 198 \t train loss: 0.378415\n",
      "epoch: 18 \t iteration 199 \t train loss: 0.327181\n",
      "epoch:18 \t mean train loss: 0.391653 \t mean train acc: 0.854560\n",
      "epoch: 18 \t iteration 0 \t eval loss: 0.368940\n",
      "epoch: 18 \t iteration 1 \t eval loss: 0.344690\n",
      "epoch: 18 \t iteration 2 \t eval loss: 0.433948\n",
      "epoch: 18 \t iteration 3 \t eval loss: 0.390122\n",
      "epoch: 18 \t iteration 4 \t eval loss: 0.449635\n",
      "epoch: 18 \t iteration 5 \t eval loss: 0.427608\n",
      "epoch: 18 \t iteration 6 \t eval loss: 0.357864\n",
      "epoch: 18 \t iteration 7 \t eval loss: 0.365415\n",
      "epoch: 18 \t iteration 8 \t eval loss: 0.358619\n",
      "epoch: 18 \t iteration 9 \t eval loss: 0.363167\n",
      "epoch: 18 \t iteration 10 \t eval loss: 0.347189\n",
      "epoch: 18 \t iteration 11 \t eval loss: 0.375983\n",
      "epoch: 18 \t iteration 12 \t eval loss: 0.385519\n",
      "epoch: 18 \t iteration 13 \t eval loss: 0.358837\n",
      "epoch: 18 \t iteration 14 \t eval loss: 0.399943\n",
      "epoch: 18 \t iteration 15 \t eval loss: 0.358447\n",
      "epoch: 18 \t iteration 16 \t eval loss: 0.404817\n",
      "epoch: 18 \t iteration 17 \t eval loss: 0.385559\n",
      "epoch: 18 \t iteration 18 \t eval loss: 0.363344\n",
      "epoch: 18 \t iteration 19 \t eval loss: 0.389534\n",
      "epoch: 18 \t iteration 20 \t eval loss: 0.392558\n",
      "epoch: 18 \t iteration 21 \t eval loss: 0.354204\n",
      "epoch: 18 \t iteration 22 \t eval loss: 0.384247\n",
      "epoch: 18 \t iteration 23 \t eval loss: 0.360099\n",
      "epoch: 18 \t iteration 24 \t eval loss: 0.355769\n",
      "epoch: 18 \t iteration 25 \t eval loss: 0.392003\n",
      "epoch: 18 \t iteration 26 \t eval loss: 0.302515\n",
      "epoch: 18 \t iteration 27 \t eval loss: 0.460379\n",
      "epoch: 18 \t iteration 28 \t eval loss: 0.420005\n",
      "epoch: 18 \t iteration 29 \t eval loss: 0.419601\n",
      "epoch: 18 \t iteration 30 \t eval loss: 0.388284\n",
      "epoch: 18 \t iteration 31 \t eval loss: 0.430032\n",
      "epoch: 18 \t iteration 32 \t eval loss: 0.417892\n",
      "epoch: 18 \t iteration 33 \t eval loss: 0.413362\n",
      "epoch: 18 \t iteration 34 \t eval loss: 0.460042\n",
      "epoch: 18 \t iteration 35 \t eval loss: 0.430321\n",
      "epoch: 18 \t iteration 36 \t eval loss: 0.347193\n",
      "epoch: 18 \t iteration 37 \t eval loss: 0.389809\n",
      "epoch: 18 \t iteration 38 \t eval loss: 0.379683\n",
      "epoch: 18 \t iteration 39 \t eval loss: 0.331417\n",
      "epoch:18 \t mean eval loss: 0.386465 \t mean eval acc: 0.853600\n",
      "epoch: 19 \t iteration 0 \t train loss: 0.391267\n",
      "epoch: 19 \t iteration 1 \t train loss: 0.342064\n",
      "epoch: 19 \t iteration 2 \t train loss: 0.359800\n",
      "epoch: 19 \t iteration 3 \t train loss: 0.367798\n",
      "epoch: 19 \t iteration 4 \t train loss: 0.376751\n",
      "epoch: 19 \t iteration 5 \t train loss: 0.364996\n",
      "epoch: 19 \t iteration 6 \t train loss: 0.480572\n",
      "epoch: 19 \t iteration 7 \t train loss: 0.410441\n",
      "epoch: 19 \t iteration 8 \t train loss: 0.375561\n",
      "epoch: 19 \t iteration 9 \t train loss: 0.430755\n",
      "epoch: 19 \t iteration 10 \t train loss: 0.417476\n",
      "epoch: 19 \t iteration 11 \t train loss: 0.420047\n",
      "epoch: 19 \t iteration 12 \t train loss: 0.448812\n",
      "epoch: 19 \t iteration 13 \t train loss: 0.364194\n",
      "epoch: 19 \t iteration 14 \t train loss: 0.393621\n",
      "epoch: 19 \t iteration 15 \t train loss: 0.427358\n",
      "epoch: 19 \t iteration 16 \t train loss: 0.467732\n",
      "epoch: 19 \t iteration 17 \t train loss: 0.436681\n",
      "epoch: 19 \t iteration 18 \t train loss: 0.491483\n",
      "epoch: 19 \t iteration 19 \t train loss: 0.424409\n",
      "epoch: 19 \t iteration 20 \t train loss: 0.379590\n",
      "epoch: 19 \t iteration 21 \t train loss: 0.361508\n",
      "epoch: 19 \t iteration 22 \t train loss: 0.396785\n",
      "epoch: 19 \t iteration 23 \t train loss: 0.433729\n",
      "epoch: 19 \t iteration 24 \t train loss: 0.412424\n",
      "epoch: 19 \t iteration 25 \t train loss: 0.352867\n",
      "epoch: 19 \t iteration 26 \t train loss: 0.374359\n",
      "epoch: 19 \t iteration 27 \t train loss: 0.435131\n",
      "epoch: 19 \t iteration 28 \t train loss: 0.417516\n",
      "epoch: 19 \t iteration 29 \t train loss: 0.369454\n",
      "epoch: 19 \t iteration 30 \t train loss: 0.473233\n",
      "epoch: 19 \t iteration 31 \t train loss: 0.401293\n",
      "epoch: 19 \t iteration 32 \t train loss: 0.365275\n",
      "epoch: 19 \t iteration 33 \t train loss: 0.369136\n",
      "epoch: 19 \t iteration 34 \t train loss: 0.359556\n",
      "epoch: 19 \t iteration 35 \t train loss: 0.322741\n",
      "epoch: 19 \t iteration 36 \t train loss: 0.406604\n",
      "epoch: 19 \t iteration 37 \t train loss: 0.390211\n",
      "epoch: 19 \t iteration 38 \t train loss: 0.358461\n",
      "epoch: 19 \t iteration 39 \t train loss: 0.386491\n",
      "epoch: 19 \t iteration 40 \t train loss: 0.422356\n",
      "epoch: 19 \t iteration 41 \t train loss: 0.353442\n",
      "epoch: 19 \t iteration 42 \t train loss: 0.381220\n",
      "epoch: 19 \t iteration 43 \t train loss: 0.436593\n",
      "epoch: 19 \t iteration 44 \t train loss: 0.345622\n",
      "epoch: 19 \t iteration 45 \t train loss: 0.387473\n",
      "epoch: 19 \t iteration 46 \t train loss: 0.388768\n",
      "epoch: 19 \t iteration 47 \t train loss: 0.332051\n",
      "epoch: 19 \t iteration 48 \t train loss: 0.407704\n",
      "epoch: 19 \t iteration 49 \t train loss: 0.399817\n",
      "epoch: 19 \t iteration 50 \t train loss: 0.523282\n",
      "epoch: 19 \t iteration 51 \t train loss: 0.358352\n",
      "epoch: 19 \t iteration 52 \t train loss: 0.408773\n",
      "epoch: 19 \t iteration 53 \t train loss: 0.368760\n",
      "epoch: 19 \t iteration 54 \t train loss: 0.379525\n",
      "epoch: 19 \t iteration 55 \t train loss: 0.406898\n",
      "epoch: 19 \t iteration 56 \t train loss: 0.392814\n",
      "epoch: 19 \t iteration 57 \t train loss: 0.380480\n",
      "epoch: 19 \t iteration 58 \t train loss: 0.405824\n",
      "epoch: 19 \t iteration 59 \t train loss: 0.398482\n",
      "epoch: 19 \t iteration 60 \t train loss: 0.355326\n",
      "epoch: 19 \t iteration 61 \t train loss: 0.359789\n",
      "epoch: 19 \t iteration 62 \t train loss: 0.374183\n",
      "epoch: 19 \t iteration 63 \t train loss: 0.393314\n",
      "epoch: 19 \t iteration 64 \t train loss: 0.344379\n",
      "epoch: 19 \t iteration 65 \t train loss: 0.405581\n",
      "epoch: 19 \t iteration 66 \t train loss: 0.444285\n",
      "epoch: 19 \t iteration 67 \t train loss: 0.381073\n",
      "epoch: 19 \t iteration 68 \t train loss: 0.414378\n",
      "epoch: 19 \t iteration 69 \t train loss: 0.413116\n",
      "epoch: 19 \t iteration 70 \t train loss: 0.374486\n",
      "epoch: 19 \t iteration 71 \t train loss: 0.359424\n",
      "epoch: 19 \t iteration 72 \t train loss: 0.342417\n",
      "epoch: 19 \t iteration 73 \t train loss: 0.393502\n",
      "epoch: 19 \t iteration 74 \t train loss: 0.400699\n",
      "epoch: 19 \t iteration 75 \t train loss: 0.367059\n",
      "epoch: 19 \t iteration 76 \t train loss: 0.427006\n",
      "epoch: 19 \t iteration 77 \t train loss: 0.375740\n",
      "epoch: 19 \t iteration 78 \t train loss: 0.400004\n",
      "epoch: 19 \t iteration 79 \t train loss: 0.455198\n",
      "epoch: 19 \t iteration 80 \t train loss: 0.432535\n",
      "epoch: 19 \t iteration 81 \t train loss: 0.393059\n",
      "epoch: 19 \t iteration 82 \t train loss: 0.435766\n",
      "epoch: 19 \t iteration 83 \t train loss: 0.407713\n",
      "epoch: 19 \t iteration 84 \t train loss: 0.400350\n",
      "epoch: 19 \t iteration 85 \t train loss: 0.444137\n",
      "epoch: 19 \t iteration 86 \t train loss: 0.429172\n",
      "epoch: 19 \t iteration 87 \t train loss: 0.384757\n",
      "epoch: 19 \t iteration 88 \t train loss: 0.407472\n",
      "epoch: 19 \t iteration 89 \t train loss: 0.459922\n",
      "epoch: 19 \t iteration 90 \t train loss: 0.376193\n",
      "epoch: 19 \t iteration 91 \t train loss: 0.373075\n",
      "epoch: 19 \t iteration 92 \t train loss: 0.392278\n",
      "epoch: 19 \t iteration 93 \t train loss: 0.397959\n",
      "epoch: 19 \t iteration 94 \t train loss: 0.345603\n",
      "epoch: 19 \t iteration 95 \t train loss: 0.336981\n",
      "epoch: 19 \t iteration 96 \t train loss: 0.364401\n",
      "epoch: 19 \t iteration 97 \t train loss: 0.370650\n",
      "epoch: 19 \t iteration 98 \t train loss: 0.427307\n",
      "epoch: 19 \t iteration 99 \t train loss: 0.410370\n",
      "epoch: 19 \t iteration 100 \t train loss: 0.387931\n",
      "epoch: 19 \t iteration 101 \t train loss: 0.368438\n",
      "epoch: 19 \t iteration 102 \t train loss: 0.385221\n",
      "epoch: 19 \t iteration 103 \t train loss: 0.381080\n",
      "epoch: 19 \t iteration 104 \t train loss: 0.413549\n",
      "epoch: 19 \t iteration 105 \t train loss: 0.380948\n",
      "epoch: 19 \t iteration 106 \t train loss: 0.364610\n",
      "epoch: 19 \t iteration 107 \t train loss: 0.398648\n",
      "epoch: 19 \t iteration 108 \t train loss: 0.422157\n",
      "epoch: 19 \t iteration 109 \t train loss: 0.500373\n",
      "epoch: 19 \t iteration 110 \t train loss: 0.399437\n",
      "epoch: 19 \t iteration 111 \t train loss: 0.398796\n",
      "epoch: 19 \t iteration 112 \t train loss: 0.358246\n",
      "epoch: 19 \t iteration 113 \t train loss: 0.395636\n",
      "epoch: 19 \t iteration 114 \t train loss: 0.402207\n",
      "epoch: 19 \t iteration 115 \t train loss: 0.332666\n",
      "epoch: 19 \t iteration 116 \t train loss: 0.318763\n",
      "epoch: 19 \t iteration 117 \t train loss: 0.452271\n",
      "epoch: 19 \t iteration 118 \t train loss: 0.416746\n",
      "epoch: 19 \t iteration 119 \t train loss: 0.442958\n",
      "epoch: 19 \t iteration 120 \t train loss: 0.364919\n",
      "epoch: 19 \t iteration 121 \t train loss: 0.402846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 \t iteration 122 \t train loss: 0.395397\n",
      "epoch: 19 \t iteration 123 \t train loss: 0.336967\n",
      "epoch: 19 \t iteration 124 \t train loss: 0.390712\n",
      "epoch: 19 \t iteration 125 \t train loss: 0.465103\n",
      "epoch: 19 \t iteration 126 \t train loss: 0.404469\n",
      "epoch: 19 \t iteration 127 \t train loss: 0.383316\n",
      "epoch: 19 \t iteration 128 \t train loss: 0.431893\n",
      "epoch: 19 \t iteration 129 \t train loss: 0.457737\n",
      "epoch: 19 \t iteration 130 \t train loss: 0.405184\n",
      "epoch: 19 \t iteration 131 \t train loss: 0.399192\n",
      "epoch: 19 \t iteration 132 \t train loss: 0.420211\n",
      "epoch: 19 \t iteration 133 \t train loss: 0.336992\n",
      "epoch: 19 \t iteration 134 \t train loss: 0.370578\n",
      "epoch: 19 \t iteration 135 \t train loss: 0.400359\n",
      "epoch: 19 \t iteration 136 \t train loss: 0.407754\n",
      "epoch: 19 \t iteration 137 \t train loss: 0.427205\n",
      "epoch: 19 \t iteration 138 \t train loss: 0.336346\n",
      "epoch: 19 \t iteration 139 \t train loss: 0.433183\n",
      "epoch: 19 \t iteration 140 \t train loss: 0.408340\n",
      "epoch: 19 \t iteration 141 \t train loss: 0.385408\n",
      "epoch: 19 \t iteration 142 \t train loss: 0.404566\n",
      "epoch: 19 \t iteration 143 \t train loss: 0.429156\n",
      "epoch: 19 \t iteration 144 \t train loss: 0.422436\n",
      "epoch: 19 \t iteration 145 \t train loss: 0.427718\n",
      "epoch: 19 \t iteration 146 \t train loss: 0.369591\n",
      "epoch: 19 \t iteration 147 \t train loss: 0.342066\n",
      "epoch: 19 \t iteration 148 \t train loss: 0.363381\n",
      "epoch: 19 \t iteration 149 \t train loss: 0.437214\n",
      "epoch: 19 \t iteration 150 \t train loss: 0.416158\n",
      "epoch: 19 \t iteration 151 \t train loss: 0.375859\n",
      "epoch: 19 \t iteration 152 \t train loss: 0.345284\n",
      "epoch: 19 \t iteration 153 \t train loss: 0.374514\n",
      "epoch: 19 \t iteration 154 \t train loss: 0.370777\n",
      "epoch: 19 \t iteration 155 \t train loss: 0.399447\n",
      "epoch: 19 \t iteration 156 \t train loss: 0.453463\n",
      "epoch: 19 \t iteration 157 \t train loss: 0.380564\n",
      "epoch: 19 \t iteration 158 \t train loss: 0.469971\n",
      "epoch: 19 \t iteration 159 \t train loss: 0.434048\n",
      "epoch: 19 \t iteration 160 \t train loss: 0.374006\n",
      "epoch: 19 \t iteration 161 \t train loss: 0.439703\n",
      "epoch: 19 \t iteration 162 \t train loss: 0.407804\n",
      "epoch: 19 \t iteration 163 \t train loss: 0.368422\n",
      "epoch: 19 \t iteration 164 \t train loss: 0.369362\n",
      "epoch: 19 \t iteration 165 \t train loss: 0.360274\n",
      "epoch: 19 \t iteration 166 \t train loss: 0.339671\n",
      "epoch: 19 \t iteration 167 \t train loss: 0.381349\n",
      "epoch: 19 \t iteration 168 \t train loss: 0.454864\n",
      "epoch: 19 \t iteration 169 \t train loss: 0.351707\n",
      "epoch: 19 \t iteration 170 \t train loss: 0.357105\n",
      "epoch: 19 \t iteration 171 \t train loss: 0.429297\n",
      "epoch: 19 \t iteration 172 \t train loss: 0.390961\n",
      "epoch: 19 \t iteration 173 \t train loss: 0.330274\n",
      "epoch: 19 \t iteration 174 \t train loss: 0.392401\n",
      "epoch: 19 \t iteration 175 \t train loss: 0.368194\n",
      "epoch: 19 \t iteration 176 \t train loss: 0.400373\n",
      "epoch: 19 \t iteration 177 \t train loss: 0.372148\n",
      "epoch: 19 \t iteration 178 \t train loss: 0.346031\n",
      "epoch: 19 \t iteration 179 \t train loss: 0.426630\n",
      "epoch: 19 \t iteration 180 \t train loss: 0.352602\n",
      "epoch: 19 \t iteration 181 \t train loss: 0.358539\n",
      "epoch: 19 \t iteration 182 \t train loss: 0.397958\n",
      "epoch: 19 \t iteration 183 \t train loss: 0.320835\n",
      "epoch: 19 \t iteration 184 \t train loss: 0.381026\n",
      "epoch: 19 \t iteration 185 \t train loss: 0.406551\n",
      "epoch: 19 \t iteration 186 \t train loss: 0.352948\n",
      "epoch: 19 \t iteration 187 \t train loss: 0.339296\n",
      "epoch: 19 \t iteration 188 \t train loss: 0.367430\n",
      "epoch: 19 \t iteration 189 \t train loss: 0.398953\n",
      "epoch: 19 \t iteration 190 \t train loss: 0.437353\n",
      "epoch: 19 \t iteration 191 \t train loss: 0.344023\n",
      "epoch: 19 \t iteration 192 \t train loss: 0.305692\n",
      "epoch: 19 \t iteration 193 \t train loss: 0.323069\n",
      "epoch: 19 \t iteration 194 \t train loss: 0.339237\n",
      "epoch: 19 \t iteration 195 \t train loss: 0.282213\n",
      "epoch: 19 \t iteration 196 \t train loss: 0.252609\n",
      "epoch: 19 \t iteration 197 \t train loss: 0.434140\n",
      "epoch: 19 \t iteration 198 \t train loss: 0.378173\n",
      "epoch: 19 \t iteration 199 \t train loss: 0.326825\n",
      "epoch:19 \t mean train loss: 0.391341 \t mean train acc: 0.854520\n",
      "epoch: 19 \t iteration 0 \t eval loss: 0.368758\n",
      "epoch: 19 \t iteration 1 \t eval loss: 0.344527\n",
      "epoch: 19 \t iteration 2 \t eval loss: 0.433751\n",
      "epoch: 19 \t iteration 3 \t eval loss: 0.389933\n",
      "epoch: 19 \t iteration 4 \t eval loss: 0.449519\n",
      "epoch: 19 \t iteration 5 \t eval loss: 0.427607\n",
      "epoch: 19 \t iteration 6 \t eval loss: 0.357605\n",
      "epoch: 19 \t iteration 7 \t eval loss: 0.365116\n",
      "epoch: 19 \t iteration 8 \t eval loss: 0.358657\n",
      "epoch: 19 \t iteration 9 \t eval loss: 0.362873\n",
      "epoch: 19 \t iteration 10 \t eval loss: 0.346905\n",
      "epoch: 19 \t iteration 11 \t eval loss: 0.375876\n",
      "epoch: 19 \t iteration 12 \t eval loss: 0.385317\n",
      "epoch: 19 \t iteration 13 \t eval loss: 0.358531\n",
      "epoch: 19 \t iteration 14 \t eval loss: 0.399485\n",
      "epoch: 19 \t iteration 15 \t eval loss: 0.358195\n",
      "epoch: 19 \t iteration 16 \t eval loss: 0.404747\n",
      "epoch: 19 \t iteration 17 \t eval loss: 0.385247\n",
      "epoch: 19 \t iteration 18 \t eval loss: 0.363073\n",
      "epoch: 19 \t iteration 19 \t eval loss: 0.389454\n",
      "epoch: 19 \t iteration 20 \t eval loss: 0.392383\n",
      "epoch: 19 \t iteration 21 \t eval loss: 0.354042\n",
      "epoch: 19 \t iteration 22 \t eval loss: 0.383960\n",
      "epoch: 19 \t iteration 23 \t eval loss: 0.359926\n",
      "epoch: 19 \t iteration 24 \t eval loss: 0.355566\n",
      "epoch: 19 \t iteration 25 \t eval loss: 0.391935\n",
      "epoch: 19 \t iteration 26 \t eval loss: 0.302374\n",
      "epoch: 19 \t iteration 27 \t eval loss: 0.460369\n",
      "epoch: 19 \t iteration 28 \t eval loss: 0.419668\n",
      "epoch: 19 \t iteration 29 \t eval loss: 0.419356\n",
      "epoch: 19 \t iteration 30 \t eval loss: 0.387886\n",
      "epoch: 19 \t iteration 31 \t eval loss: 0.429997\n",
      "epoch: 19 \t iteration 32 \t eval loss: 0.417649\n",
      "epoch: 19 \t iteration 33 \t eval loss: 0.413321\n",
      "epoch: 19 \t iteration 34 \t eval loss: 0.460039\n",
      "epoch: 19 \t iteration 35 \t eval loss: 0.430052\n",
      "epoch: 19 \t iteration 36 \t eval loss: 0.346965\n",
      "epoch: 19 \t iteration 37 \t eval loss: 0.389684\n",
      "epoch: 19 \t iteration 38 \t eval loss: 0.379650\n",
      "epoch: 19 \t iteration 39 \t eval loss: 0.331103\n",
      "epoch:19 \t mean eval loss: 0.386278 \t mean eval acc: 0.853300\n"
     ]
    }
   ],
   "source": [
    "# do training and evaluation\n",
    "mean_eval_losses = []\n",
    "mean_train_losses = []\n",
    "mean_eval_accs = []\n",
    "mean_train_accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    mean_train_loss_per_epoch = 0\n",
    "    mean_train_acc_per_epoch = 0\n",
    "    for i in range(train_data_size // batch_size):\n",
    "        x, y = get_next_batch(i, batch_size, X_train, y_train)\n",
    "        y_hat = do_network_inference(x, W, b)\n",
    "        train_loss = get_loss(y_hat, y)\n",
    "        train_accuracy = get_accuracy(y_hat, y)\n",
    "        delta_w = get_delta_weights(y_hat, y, x)\n",
    "        delta_b = get_delta_biases(y_hat, y)\n",
    "        W, b = do_parameter_update(delta_w, delta_b, W, b, learning_rate)\n",
    "        mean_train_loss_per_epoch += train_loss\n",
    "        mean_train_acc_per_epoch += train_accuracy\n",
    "        print(\"epoch: {0:d} \\t iteration {1:d} \\t train loss: {2:f}\".format(epoch, i,train_loss))\n",
    "    mean_train_loss_per_epoch /= ((train_data_size // batch_size))\n",
    "    mean_train_acc_per_epoch /= ((train_data_size // batch_size))\n",
    "    print(\"epoch:{0:d} \\t mean train loss: {1:f} \\t mean train acc: {2:f}\".format(epoch,mean_train_loss_per_epoch,\n",
    "                                                                              mean_train_acc_per_epoch))\n",
    "    # evaluation:\n",
    "    mean_eval_loss_per_epoch = 0\n",
    "    mean_eval_acc_per_epoch = 0\n",
    "    # TODO calculate the evaluation loss and accuracy\n",
    "    for i in range(eval_data_size // batch_size):\n",
    "        x, y = get_next_batch(i, batch_size, X_eval, y_eval)\n",
    "        y_hat = do_network_inference(x, W, b)\n",
    "        eval_loss = get_loss(y_hat, y)\n",
    "        eval_accuracy = get_accuracy(y_hat, y)\n",
    "        mean_eval_loss_per_epoch += eval_loss\n",
    "        mean_eval_acc_per_epoch += eval_accuracy\n",
    "        print(\"epoch: {0:d} \\t iteration {1:d} \\t eval loss: {2:f}\".format(epoch, i,eval_loss))\n",
    "\n",
    "    mean_eval_loss_per_epoch /= (eval_data_size // batch_size)\n",
    "    mean_eval_acc_per_epoch /= ((eval_data_size // batch_size))\n",
    "    print(\"epoch:{0:d} \\t mean eval loss: {1:f} \\t mean eval acc: {2:f}\".format(epoch,mean_eval_loss_per_epoch,\n",
    "                                                                            mean_eval_acc_per_epoch))\n",
    "    mean_eval_losses.append(mean_eval_loss_per_epoch)\n",
    "    mean_train_losses.append(mean_train_loss_per_epoch)\n",
    "    mean_eval_accs.append(mean_eval_acc_per_epoch)\n",
    "    mean_train_accs.append(mean_train_acc_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:27:22.620074Z",
     "start_time": "2019-11-15T19:27:20.136688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test loss: 0.387359 \t final test acc: 0.858100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO calculate the test loss and accuracy\n",
    "mean_test_losses = []\n",
    "mean_test_accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    mean_test_loss_per_epoch = 0\n",
    "    mean_test_acc_per_epoch = 0\n",
    "    for i in range(test_data_size // batch_size):\n",
    "        x, y = get_next_batch(i, batch_size, X_test, y_test)\n",
    "        y_hat = do_network_inference(x, W, b)\n",
    "        test_loss = get_loss(y_hat, y)\n",
    "        test_accuracy = get_accuracy(y_hat, y)\n",
    "        mean_test_loss_per_epoch += test_loss\n",
    "        mean_test_acc_per_epoch += test_accuracy\n",
    "    mean_test_loss_per_epoch = mean_test_loss_per_epoch / ((test_data_size // batch_size))\n",
    "    mean_test_acc_per_epoch = mean_test_acc_per_epoch / ((test_data_size // batch_size))\n",
    "    mean_test_losses.append(mean_test_loss_per_epoch)\n",
    "    mean_test_accs.append(mean_test_acc_per_epoch)\n",
    "\n",
    "final_mean_test_loss = np.sum(mean_test_losses)/epochs\n",
    "final_mean_test_acc  = np.sum(mean_test_accs)/epochs\n",
    "    \n",
    "print(\"final test loss: {0:f} \\t final test acc: {1:f}\".format(final_mean_test_loss, final_mean_test_acc))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax1 = axs[0]\n",
    "ax2 = axs[1]\n",
    "\n",
    "ax1.plot(range(epochs), mean_train_losses, \"r\", label=\"train loss\")\n",
    "ax1.plot(range(epochs), mean_eval_losses, \"b\", label=\"eval loss\")\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_ylabel(\"loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(epochs), mean_train_accs, \"r\", label=\"train acc\")\n",
    "ax2.plot(range(epochs), mean_eval_accs, \"b\", label=\"eval acc\")\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.set_ylabel(\"accuracy\")\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "616.85px",
    "left": "1066px",
    "right": "20px",
    "top": "120px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
